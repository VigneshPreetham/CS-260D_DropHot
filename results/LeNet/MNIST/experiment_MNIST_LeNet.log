=============================================================================================================
Forgetting scores and baseline model not found. Computing from scratch...
Starting baseline training for 10 epochs with forgetting tracking...
Epoch [1/10] completed. Training Loss: 0.2626, Accuracy: 91.89%
Epoch [2/10] completed. Training Loss: 0.0684, Accuracy: 97.88%
Epoch [3/10] completed. Training Loss: 0.0481, Accuracy: 98.51%
Epoch [4/10] completed. Training Loss: 0.0379, Accuracy: 98.84%
Epoch [5/10] completed. Training Loss: 0.0331, Accuracy: 98.92%
Epoch [6/10] completed. Training Loss: 0.0282, Accuracy: 99.11%
Epoch [7/10] completed. Training Loss: 0.0244, Accuracy: 99.19%
Epoch [8/10] completed. Training Loss: 0.0209, Accuracy: 99.31%
Epoch [9/10] completed. Training Loss: 0.0184, Accuracy: 99.42%
Epoch [10/10] completed. Training Loss: 0.0160, Accuracy: 99.45%
Baseline training with forgetting tracking completed.
Forgetting scores and baseline model saved for future runs.
Selected top 6000 highest-forgetting and top 6000 lowest-forgetting samples.
Highest forgetting subset size: 6000, Lowest forgetting subset size: 6000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.0302, Accuracy: 71.42%
Epoch [2/10] complete: Loss: 0.2563, Accuracy: 92.32%
Epoch [3/10] complete: Loss: 0.1799, Accuracy: 94.60%
Epoch [4/10] complete: Loss: 0.1338, Accuracy: 96.05%
Epoch [5/10] complete: Loss: 0.1042, Accuracy: 96.82%
Epoch [6/10] complete: Loss: 0.0869, Accuracy: 97.37%
Epoch [7/10] complete: Loss: 0.0712, Accuracy: 97.77%
Epoch [8/10] complete: Loss: 0.0523, Accuracy: 98.53%
Epoch [9/10] complete: Loss: 0.0464, Accuracy: 98.42%
Epoch [10/10] complete: Loss: 0.0413, Accuracy: 98.60%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.2349, Accuracy: 59.58%
Epoch [2/10] complete: Loss: 0.3900, Accuracy: 87.73%
Epoch [3/10] complete: Loss: 0.2411, Accuracy: 92.53%
Epoch [4/10] complete: Loss: 0.1824, Accuracy: 94.03%
Epoch [5/10] complete: Loss: 0.1388, Accuracy: 95.50%
Epoch [6/10] complete: Loss: 0.1141, Accuracy: 96.33%
Epoch [7/10] complete: Loss: 0.0949, Accuracy: 96.83%
Epoch [8/10] complete: Loss: 0.0814, Accuracy: 97.37%
Epoch [9/10] complete: Loss: 0.0620, Accuracy: 98.00%
Epoch [10/10] complete: Loss: 0.0553, Accuracy: 98.27%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 96.55%
High Forgetting Model Accuracy: 97.56%
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.1/pr0.0/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.92%
Pruned Low Forgetting Model Accuracy: 96.55%
Pruned High Forgetting Model Accuracy: 97.56%
Post-Pruning Retraining...
Initial Test Accuracy: 98.92%
Post-Pruning Training Epoch [1/10]: Loss: 0.0162, Train Acc: 99.45%, Test Acc: 99.08%
Post-Pruning Training Epoch [2/10]: Loss: 0.0113, Train Acc: 99.62%, Test Acc: 99.02%
Post-Pruning Training Epoch [3/10]: Loss: 0.0124, Train Acc: 99.59%, Test Acc: 99.03%
Post-Pruning Training Epoch [4/10]: Loss: 0.0114, Train Acc: 99.64%, Test Acc: 99.08%
Post-Pruning Training Epoch [5/10]: Loss: 0.0097, Train Acc: 99.69%, Test Acc: 98.56%
Post-Pruning Training Epoch [6/10]: Loss: 0.0105, Train Acc: 99.64%, Test Acc: 98.98%
Post-Pruning Training Epoch [7/10]: Loss: 0.0074, Train Acc: 99.75%, Test Acc: 98.95%
Post-Pruning Training Epoch [8/10]: Loss: 0.0092, Train Acc: 99.71%, Test Acc: 99.02%
Post-Pruning Training Epoch [9/10]: Loss: 0.0067, Train Acc: 99.78%, Test Acc: 98.90%
Post-Pruning Training Epoch [10/10]: Loss: 0.0079, Train Acc: 99.73%, Test Acc: 98.90%
Initial Test Accuracy: 96.55%
Post-Pruning Training Epoch [1/10]: Loss: 0.0875, Train Acc: 97.20%, Test Acc: 98.20%
Post-Pruning Training Epoch [2/10]: Loss: 0.0578, Train Acc: 98.21%, Test Acc: 98.58%
Post-Pruning Training Epoch [3/10]: Loss: 0.0439, Train Acc: 98.60%, Test Acc: 98.39%
Post-Pruning Training Epoch [4/10]: Loss: 0.0367, Train Acc: 98.86%, Test Acc: 98.55%
Post-Pruning Training Epoch [5/10]: Loss: 0.0308, Train Acc: 99.05%, Test Acc: 98.87%
Post-Pruning Training Epoch [6/10]: Loss: 0.0261, Train Acc: 99.16%, Test Acc: 98.69%
Post-Pruning Training Epoch [7/10]: Loss: 0.0232, Train Acc: 99.24%, Test Acc: 98.94%
Post-Pruning Training Epoch [8/10]: Loss: 0.0197, Train Acc: 99.36%, Test Acc: 98.59%
Post-Pruning Training Epoch [9/10]: Loss: 0.0184, Train Acc: 99.39%, Test Acc: 98.80%
Post-Pruning Training Epoch [10/10]: Loss: 0.0151, Train Acc: 99.50%, Test Acc: 98.78%
Initial Test Accuracy: 97.56%
Post-Pruning Training Epoch [1/10]: Loss: 0.0736, Train Acc: 97.69%, Test Acc: 98.35%
Post-Pruning Training Epoch [2/10]: Loss: 0.0478, Train Acc: 98.52%, Test Acc: 98.80%
Post-Pruning Training Epoch [3/10]: Loss: 0.0364, Train Acc: 98.85%, Test Acc: 98.74%
Post-Pruning Training Epoch [4/10]: Loss: 0.0295, Train Acc: 99.08%, Test Acc: 98.78%
Post-Pruning Training Epoch [5/10]: Loss: 0.0250, Train Acc: 99.20%, Test Acc: 98.89%
Post-Pruning Training Epoch [6/10]: Loss: 0.0208, Train Acc: 99.33%, Test Acc: 98.97%
Post-Pruning Training Epoch [7/10]: Loss: 0.0173, Train Acc: 99.46%, Test Acc: 99.02%
Post-Pruning Training Epoch [8/10]: Loss: 0.0170, Train Acc: 99.46%, Test Acc: 98.93%
Post-Pruning Training Epoch [9/10]: Loss: 0.0149, Train Acc: 99.52%, Test Acc: 98.90%
Post-Pruning Training Epoch [10/10]: Loss: 0.0120, Train Acc: 99.60%, Test Acc: 98.71%
Post-Pruned Baseline Model Accuracy: 98.90%
Post-Pruned Low Forgetting Model Accuracy: 98.78%
Post-Pruned High Forgetting Model Accuracy: 98.71%
Accuracy results saved to results/LeNet/MNIST/dr0.1/pr0.0/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.1/pr0.0/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 6000 highest-forgetting and top 6000 lowest-forgetting samples.
Highest forgetting subset size: 6000, Lowest forgetting subset size: 6000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.1026, Accuracy: 69.15%
Epoch [2/10] complete: Loss: 0.2995, Accuracy: 90.93%
Epoch [3/10] complete: Loss: 0.1933, Accuracy: 94.27%
Epoch [4/10] complete: Loss: 0.1445, Accuracy: 95.68%
Epoch [5/10] complete: Loss: 0.1042, Accuracy: 97.07%
Epoch [6/10] complete: Loss: 0.0829, Accuracy: 97.72%
Epoch [7/10] complete: Loss: 0.0677, Accuracy: 97.93%
Epoch [8/10] complete: Loss: 0.0574, Accuracy: 98.27%
Epoch [9/10] complete: Loss: 0.0436, Accuracy: 98.77%
Epoch [10/10] complete: Loss: 0.0324, Accuracy: 99.00%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.2089, Accuracy: 64.57%
Epoch [2/10] complete: Loss: 0.3370, Accuracy: 89.55%
Epoch [3/10] complete: Loss: 0.2245, Accuracy: 93.25%
Epoch [4/10] complete: Loss: 0.1639, Accuracy: 94.98%
Epoch [5/10] complete: Loss: 0.1238, Accuracy: 96.33%
Epoch [6/10] complete: Loss: 0.0969, Accuracy: 97.08%
Epoch [7/10] complete: Loss: 0.0845, Accuracy: 97.28%
Epoch [8/10] complete: Loss: 0.0666, Accuracy: 98.03%
Epoch [9/10] complete: Loss: 0.0623, Accuracy: 98.08%
Epoch [10/10] complete: Loss: 0.0532, Accuracy: 98.47%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 97.10%
High Forgetting Model Accuracy: 97.44%
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.1/pr0.2/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.91%
Pruned Low Forgetting Model Accuracy: 97.09%
Pruned High Forgetting Model Accuracy: 97.10%
Post-Pruning Retraining...
Initial Test Accuracy: 98.91%
Post-Pruning Training Epoch [1/10]: Loss: 0.0160, Train Acc: 99.47%, Test Acc: 99.14%
Post-Pruning Training Epoch [2/10]: Loss: 0.0133, Train Acc: 99.55%, Test Acc: 98.81%
Post-Pruning Training Epoch [3/10]: Loss: 0.0115, Train Acc: 99.61%, Test Acc: 99.03%
Post-Pruning Training Epoch [4/10]: Loss: 0.0108, Train Acc: 99.64%, Test Acc: 98.92%
Post-Pruning Training Epoch [5/10]: Loss: 0.0092, Train Acc: 99.70%, Test Acc: 98.79%
Post-Pruning Training Epoch [6/10]: Loss: 0.0097, Train Acc: 99.67%, Test Acc: 98.70%
Post-Pruning Training Epoch [7/10]: Loss: 0.0097, Train Acc: 99.67%, Test Acc: 98.99%
Post-Pruning Training Epoch [8/10]: Loss: 0.0090, Train Acc: 99.69%, Test Acc: 99.01%
Post-Pruning Training Epoch [9/10]: Loss: 0.0072, Train Acc: 99.74%, Test Acc: 98.92%
Post-Pruning Training Epoch [10/10]: Loss: 0.0078, Train Acc: 99.72%, Test Acc: 98.89%
Initial Test Accuracy: 97.09%
Post-Pruning Training Epoch [1/10]: Loss: 0.0788, Train Acc: 97.53%, Test Acc: 98.33%
Post-Pruning Training Epoch [2/10]: Loss: 0.0522, Train Acc: 98.35%, Test Acc: 98.54%
Post-Pruning Training Epoch [3/10]: Loss: 0.0409, Train Acc: 98.72%, Test Acc: 98.86%
Post-Pruning Training Epoch [4/10]: Loss: 0.0337, Train Acc: 98.91%, Test Acc: 98.86%
Post-Pruning Training Epoch [5/10]: Loss: 0.0276, Train Acc: 99.07%, Test Acc: 98.83%
Post-Pruning Training Epoch [6/10]: Loss: 0.0241, Train Acc: 99.22%, Test Acc: 98.94%
Post-Pruning Training Epoch [7/10]: Loss: 0.0194, Train Acc: 99.35%, Test Acc: 98.84%
Post-Pruning Training Epoch [8/10]: Loss: 0.0171, Train Acc: 99.42%, Test Acc: 98.56%
Post-Pruning Training Epoch [9/10]: Loss: 0.0158, Train Acc: 99.47%, Test Acc: 98.72%
Post-Pruning Training Epoch [10/10]: Loss: 0.0149, Train Acc: 99.50%, Test Acc: 99.05%
Initial Test Accuracy: 97.10%
Post-Pruning Training Epoch [1/10]: Loss: 0.0745, Train Acc: 97.64%, Test Acc: 98.53%
Post-Pruning Training Epoch [2/10]: Loss: 0.0485, Train Acc: 98.50%, Test Acc: 98.18%
Post-Pruning Training Epoch [3/10]: Loss: 0.0374, Train Acc: 98.82%, Test Acc: 98.47%
Post-Pruning Training Epoch [4/10]: Loss: 0.0299, Train Acc: 98.97%, Test Acc: 98.74%
Post-Pruning Training Epoch [5/10]: Loss: 0.0252, Train Acc: 99.20%, Test Acc: 98.95%
Post-Pruning Training Epoch [6/10]: Loss: 0.0208, Train Acc: 99.34%, Test Acc: 98.99%
Post-Pruning Training Epoch [7/10]: Loss: 0.0192, Train Acc: 99.38%, Test Acc: 99.06%
Post-Pruning Training Epoch [8/10]: Loss: 0.0154, Train Acc: 99.47%, Test Acc: 98.79%
Post-Pruning Training Epoch [9/10]: Loss: 0.0140, Train Acc: 99.56%, Test Acc: 99.05%
Post-Pruning Training Epoch [10/10]: Loss: 0.0125, Train Acc: 99.59%, Test Acc: 98.80%
Post-Pruned Baseline Model Accuracy: 98.89%
Post-Pruned Low Forgetting Model Accuracy: 99.05%
Post-Pruned High Forgetting Model Accuracy: 98.80%
Accuracy results saved to results/LeNet/MNIST/dr0.1/pr0.2/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.1/pr0.2/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 6000 highest-forgetting and top 6000 lowest-forgetting samples.
Highest forgetting subset size: 6000, Lowest forgetting subset size: 6000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.1032, Accuracy: 69.20%
Epoch [2/10] complete: Loss: 0.3006, Accuracy: 90.87%
Epoch [3/10] complete: Loss: 0.1937, Accuracy: 94.25%
Epoch [4/10] complete: Loss: 0.1445, Accuracy: 95.82%
Epoch [5/10] complete: Loss: 0.1042, Accuracy: 97.00%
Epoch [6/10] complete: Loss: 0.0828, Accuracy: 97.65%
Epoch [7/10] complete: Loss: 0.0690, Accuracy: 97.98%
Epoch [8/10] complete: Loss: 0.0587, Accuracy: 98.20%
Epoch [9/10] complete: Loss: 0.0446, Accuracy: 98.77%
Epoch [10/10] complete: Loss: 0.0340, Accuracy: 99.02%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.2089, Accuracy: 64.57%
Epoch [2/10] complete: Loss: 0.3369, Accuracy: 89.67%
Epoch [3/10] complete: Loss: 0.2231, Accuracy: 93.45%
Epoch [4/10] complete: Loss: 0.1645, Accuracy: 94.98%
Epoch [5/10] complete: Loss: 0.1250, Accuracy: 96.27%
Epoch [6/10] complete: Loss: 0.0978, Accuracy: 97.05%
Epoch [7/10] complete: Loss: 0.0859, Accuracy: 97.28%
Epoch [8/10] complete: Loss: 0.0680, Accuracy: 97.97%
Epoch [9/10] complete: Loss: 0.0607, Accuracy: 98.07%
Epoch [10/10] complete: Loss: 0.0541, Accuracy: 98.42%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 97.13%
High Forgetting Model Accuracy: 97.39%
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.1/pr0.4/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.46%
Pruned Low Forgetting Model Accuracy: 96.78%
Pruned High Forgetting Model Accuracy: 96.99%
Post-Pruning Retraining...
Initial Test Accuracy: 98.46%
Post-Pruning Training Epoch [1/10]: Loss: 0.0182, Train Acc: 99.43%, Test Acc: 98.87%
Post-Pruning Training Epoch [2/10]: Loss: 0.0121, Train Acc: 99.59%, Test Acc: 98.63%
Post-Pruning Training Epoch [3/10]: Loss: 0.0111, Train Acc: 99.62%, Test Acc: 98.80%
Post-Pruning Training Epoch [4/10]: Loss: 0.0118, Train Acc: 99.61%, Test Acc: 98.97%
Post-Pruning Training Epoch [5/10]: Loss: 0.0104, Train Acc: 99.66%, Test Acc: 98.75%
Post-Pruning Training Epoch [6/10]: Loss: 0.0099, Train Acc: 99.67%, Test Acc: 99.05%
Post-Pruning Training Epoch [7/10]: Loss: 0.0081, Train Acc: 99.70%, Test Acc: 98.93%
Post-Pruning Training Epoch [8/10]: Loss: 0.0093, Train Acc: 99.69%, Test Acc: 98.92%
Post-Pruning Training Epoch [9/10]: Loss: 0.0074, Train Acc: 99.76%, Test Acc: 98.83%
Post-Pruning Training Epoch [10/10]: Loss: 0.0086, Train Acc: 99.72%, Test Acc: 98.71%
Initial Test Accuracy: 96.78%
Post-Pruning Training Epoch [1/10]: Loss: 0.0794, Train Acc: 97.53%, Test Acc: 98.30%
Post-Pruning Training Epoch [2/10]: Loss: 0.0529, Train Acc: 98.29%, Test Acc: 98.55%
Post-Pruning Training Epoch [3/10]: Loss: 0.0411, Train Acc: 98.69%, Test Acc: 98.75%
Post-Pruning Training Epoch [4/10]: Loss: 0.0343, Train Acc: 98.92%, Test Acc: 98.73%
Post-Pruning Training Epoch [5/10]: Loss: 0.0274, Train Acc: 99.08%, Test Acc: 98.77%
Post-Pruning Training Epoch [6/10]: Loss: 0.0242, Train Acc: 99.23%, Test Acc: 98.79%
Post-Pruning Training Epoch [7/10]: Loss: 0.0197, Train Acc: 99.34%, Test Acc: 98.89%
Post-Pruning Training Epoch [8/10]: Loss: 0.0164, Train Acc: 99.47%, Test Acc: 98.98%
Post-Pruning Training Epoch [9/10]: Loss: 0.0169, Train Acc: 99.43%, Test Acc: 98.65%
Post-Pruning Training Epoch [10/10]: Loss: 0.0143, Train Acc: 99.53%, Test Acc: 98.77%
Initial Test Accuracy: 96.99%
Post-Pruning Training Epoch [1/10]: Loss: 0.0749, Train Acc: 97.61%, Test Acc: 98.45%
Post-Pruning Training Epoch [2/10]: Loss: 0.0495, Train Acc: 98.42%, Test Acc: 98.09%
Post-Pruning Training Epoch [3/10]: Loss: 0.0371, Train Acc: 98.86%, Test Acc: 98.57%
Post-Pruning Training Epoch [4/10]: Loss: 0.0303, Train Acc: 99.01%, Test Acc: 98.68%
Post-Pruning Training Epoch [5/10]: Loss: 0.0243, Train Acc: 99.20%, Test Acc: 99.07%
Post-Pruning Training Epoch [6/10]: Loss: 0.0215, Train Acc: 99.30%, Test Acc: 98.99%
Post-Pruning Training Epoch [7/10]: Loss: 0.0175, Train Acc: 99.43%, Test Acc: 98.89%
Post-Pruning Training Epoch [8/10]: Loss: 0.0153, Train Acc: 99.49%, Test Acc: 98.93%
Post-Pruning Training Epoch [9/10]: Loss: 0.0142, Train Acc: 99.53%, Test Acc: 98.90%
Post-Pruning Training Epoch [10/10]: Loss: 0.0132, Train Acc: 99.55%, Test Acc: 99.14%
Post-Pruned Baseline Model Accuracy: 98.71%
Post-Pruned Low Forgetting Model Accuracy: 98.77%
Post-Pruned High Forgetting Model Accuracy: 99.14%
Accuracy results saved to results/LeNet/MNIST/dr0.1/pr0.4/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.1/pr0.4/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 6000 highest-forgetting and top 6000 lowest-forgetting samples.
Highest forgetting subset size: 6000, Lowest forgetting subset size: 6000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.1025, Accuracy: 69.18%
Epoch [2/10] complete: Loss: 0.2998, Accuracy: 90.93%
Epoch [3/10] complete: Loss: 0.1937, Accuracy: 94.28%
Epoch [4/10] complete: Loss: 0.1447, Accuracy: 95.73%
Epoch [5/10] complete: Loss: 0.1049, Accuracy: 97.02%
Epoch [6/10] complete: Loss: 0.0845, Accuracy: 97.65%
Epoch [7/10] complete: Loss: 0.0674, Accuracy: 97.97%
Epoch [8/10] complete: Loss: 0.0554, Accuracy: 98.35%
Epoch [9/10] complete: Loss: 0.0439, Accuracy: 98.70%
Epoch [10/10] complete: Loss: 0.0323, Accuracy: 98.95%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.2089, Accuracy: 64.53%
Epoch [2/10] complete: Loss: 0.3369, Accuracy: 89.65%
Epoch [3/10] complete: Loss: 0.2238, Accuracy: 93.40%
Epoch [4/10] complete: Loss: 0.1649, Accuracy: 94.87%
Epoch [5/10] complete: Loss: 0.1252, Accuracy: 96.28%
Epoch [6/10] complete: Loss: 0.0979, Accuracy: 97.07%
Epoch [7/10] complete: Loss: 0.0871, Accuracy: 97.28%
Epoch [8/10] complete: Loss: 0.0681, Accuracy: 98.02%
Epoch [9/10] complete: Loss: 0.0627, Accuracy: 98.08%
Epoch [10/10] complete: Loss: 0.0534, Accuracy: 98.48%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 97.21%
High Forgetting Model Accuracy: 97.40%
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.1/pr0.6/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 93.18%
Pruned Low Forgetting Model Accuracy: 86.30%
Pruned High Forgetting Model Accuracy: 96.52%
Post-Pruning Retraining...
Initial Test Accuracy: 93.18%
Post-Pruning Training Epoch [1/10]: Loss: 0.0224, Train Acc: 99.29%, Test Acc: 98.91%
Post-Pruning Training Epoch [2/10]: Loss: 0.0144, Train Acc: 99.51%, Test Acc: 98.83%
Post-Pruning Training Epoch [3/10]: Loss: 0.0133, Train Acc: 99.54%, Test Acc: 99.03%
Post-Pruning Training Epoch [4/10]: Loss: 0.0130, Train Acc: 99.55%, Test Acc: 98.99%
Post-Pruning Training Epoch [5/10]: Loss: 0.0108, Train Acc: 99.64%, Test Acc: 98.98%
Post-Pruning Training Epoch [6/10]: Loss: 0.0087, Train Acc: 99.71%, Test Acc: 99.04%
Post-Pruning Training Epoch [7/10]: Loss: 0.0092, Train Acc: 99.68%, Test Acc: 99.01%
Post-Pruning Training Epoch [8/10]: Loss: 0.0091, Train Acc: 99.67%, Test Acc: 98.89%
Post-Pruning Training Epoch [9/10]: Loss: 0.0073, Train Acc: 99.75%, Test Acc: 99.04%
Post-Pruning Training Epoch [10/10]: Loss: 0.0078, Train Acc: 99.72%, Test Acc: 98.83%
Initial Test Accuracy: 86.30%
Post-Pruning Training Epoch [1/10]: Loss: 0.0840, Train Acc: 97.43%, Test Acc: 98.20%
Post-Pruning Training Epoch [2/10]: Loss: 0.0535, Train Acc: 98.28%, Test Acc: 98.49%
Post-Pruning Training Epoch [3/10]: Loss: 0.0421, Train Acc: 98.66%, Test Acc: 98.52%
Post-Pruning Training Epoch [4/10]: Loss: 0.0340, Train Acc: 98.95%, Test Acc: 98.75%
Post-Pruning Training Epoch [5/10]: Loss: 0.0279, Train Acc: 99.11%, Test Acc: 98.92%
Post-Pruning Training Epoch [6/10]: Loss: 0.0251, Train Acc: 99.21%, Test Acc: 98.84%
Post-Pruning Training Epoch [7/10]: Loss: 0.0204, Train Acc: 99.31%, Test Acc: 98.96%
Post-Pruning Training Epoch [8/10]: Loss: 0.0164, Train Acc: 99.44%, Test Acc: 98.95%
Post-Pruning Training Epoch [9/10]: Loss: 0.0165, Train Acc: 99.45%, Test Acc: 98.98%
Post-Pruning Training Epoch [10/10]: Loss: 0.0144, Train Acc: 99.53%, Test Acc: 99.09%
Initial Test Accuracy: 96.52%
Post-Pruning Training Epoch [1/10]: Loss: 0.0763, Train Acc: 97.61%, Test Acc: 98.48%
Post-Pruning Training Epoch [2/10]: Loss: 0.0491, Train Acc: 98.46%, Test Acc: 98.29%
Post-Pruning Training Epoch [3/10]: Loss: 0.0365, Train Acc: 98.88%, Test Acc: 98.78%
Post-Pruning Training Epoch [4/10]: Loss: 0.0296, Train Acc: 99.02%, Test Acc: 98.78%
Post-Pruning Training Epoch [5/10]: Loss: 0.0248, Train Acc: 99.23%, Test Acc: 99.07%
Post-Pruning Training Epoch [6/10]: Loss: 0.0220, Train Acc: 99.33%, Test Acc: 99.17%
Post-Pruning Training Epoch [7/10]: Loss: 0.0192, Train Acc: 99.37%, Test Acc: 98.99%
Post-Pruning Training Epoch [8/10]: Loss: 0.0158, Train Acc: 99.49%, Test Acc: 98.93%
Post-Pruning Training Epoch [9/10]: Loss: 0.0142, Train Acc: 99.52%, Test Acc: 98.94%
Post-Pruning Training Epoch [10/10]: Loss: 0.0142, Train Acc: 99.52%, Test Acc: 99.02%
Post-Pruned Baseline Model Accuracy: 98.83%
Post-Pruned Low Forgetting Model Accuracy: 99.09%
Post-Pruned High Forgetting Model Accuracy: 99.02%
Accuracy results saved to results/LeNet/MNIST/dr0.1/pr0.6/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.1/pr0.6/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 6000 highest-forgetting and top 6000 lowest-forgetting samples.
Highest forgetting subset size: 6000, Lowest forgetting subset size: 6000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.1030, Accuracy: 69.13%
Epoch [2/10] complete: Loss: 0.3009, Accuracy: 90.82%
Epoch [3/10] complete: Loss: 0.1937, Accuracy: 94.32%
Epoch [4/10] complete: Loss: 0.1443, Accuracy: 95.88%
Epoch [5/10] complete: Loss: 0.1034, Accuracy: 97.12%
Epoch [6/10] complete: Loss: 0.0830, Accuracy: 97.70%
Epoch [7/10] complete: Loss: 0.0680, Accuracy: 97.97%
Epoch [8/10] complete: Loss: 0.0576, Accuracy: 98.20%
Epoch [9/10] complete: Loss: 0.0443, Accuracy: 98.68%
Epoch [10/10] complete: Loss: 0.0332, Accuracy: 99.02%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.2086, Accuracy: 64.60%
Epoch [2/10] complete: Loss: 0.3369, Accuracy: 89.55%
Epoch [3/10] complete: Loss: 0.2229, Accuracy: 93.30%
Epoch [4/10] complete: Loss: 0.1640, Accuracy: 95.00%
Epoch [5/10] complete: Loss: 0.1237, Accuracy: 96.38%
Epoch [6/10] complete: Loss: 0.0967, Accuracy: 97.18%
Epoch [7/10] complete: Loss: 0.0849, Accuracy: 97.28%
Epoch [8/10] complete: Loss: 0.0658, Accuracy: 98.03%
Epoch [9/10] complete: Loss: 0.0606, Accuracy: 98.13%
Epoch [10/10] complete: Loss: 0.0518, Accuracy: 98.47%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 97.15%
High Forgetting Model Accuracy: 97.37%
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.1/pr0.8/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 43.24%
Pruned Low Forgetting Model Accuracy: 38.29%
Pruned High Forgetting Model Accuracy: 59.00%
Post-Pruning Retraining...
Initial Test Accuracy: 43.24%
Post-Pruning Training Epoch [1/10]: Loss: 0.0513, Train Acc: 98.52%, Test Acc: 99.03%
Post-Pruning Training Epoch [2/10]: Loss: 0.0219, Train Acc: 99.29%, Test Acc: 98.86%
Post-Pruning Training Epoch [3/10]: Loss: 0.0175, Train Acc: 99.40%, Test Acc: 99.13%
Post-Pruning Training Epoch [4/10]: Loss: 0.0152, Train Acc: 99.50%, Test Acc: 98.98%
Post-Pruning Training Epoch [5/10]: Loss: 0.0128, Train Acc: 99.56%, Test Acc: 98.89%
Post-Pruning Training Epoch [6/10]: Loss: 0.0114, Train Acc: 99.61%, Test Acc: 98.91%
Post-Pruning Training Epoch [7/10]: Loss: 0.0118, Train Acc: 99.59%, Test Acc: 98.96%
Post-Pruning Training Epoch [8/10]: Loss: 0.0107, Train Acc: 99.65%, Test Acc: 98.99%
Post-Pruning Training Epoch [9/10]: Loss: 0.0092, Train Acc: 99.70%, Test Acc: 99.02%
Post-Pruning Training Epoch [10/10]: Loss: 0.0090, Train Acc: 99.69%, Test Acc: 99.06%
Initial Test Accuracy: 38.29%
Post-Pruning Training Epoch [1/10]: Loss: 0.1108, Train Acc: 96.81%, Test Acc: 98.14%
Post-Pruning Training Epoch [2/10]: Loss: 0.0579, Train Acc: 98.21%, Test Acc: 98.49%
Post-Pruning Training Epoch [3/10]: Loss: 0.0442, Train Acc: 98.60%, Test Acc: 98.60%
Post-Pruning Training Epoch [4/10]: Loss: 0.0360, Train Acc: 98.89%, Test Acc: 98.81%
Post-Pruning Training Epoch [5/10]: Loss: 0.0292, Train Acc: 99.06%, Test Acc: 98.99%
Post-Pruning Training Epoch [6/10]: Loss: 0.0261, Train Acc: 99.16%, Test Acc: 98.77%
Post-Pruning Training Epoch [7/10]: Loss: 0.0224, Train Acc: 99.23%, Test Acc: 99.02%
Post-Pruning Training Epoch [8/10]: Loss: 0.0173, Train Acc: 99.40%, Test Acc: 98.84%
Post-Pruning Training Epoch [9/10]: Loss: 0.0178, Train Acc: 99.42%, Test Acc: 98.99%
Post-Pruning Training Epoch [10/10]: Loss: 0.0155, Train Acc: 99.51%, Test Acc: 99.00%
Initial Test Accuracy: 59.00%
Post-Pruning Training Epoch [1/10]: Loss: 0.1009, Train Acc: 97.08%, Test Acc: 98.47%
Post-Pruning Training Epoch [2/10]: Loss: 0.0532, Train Acc: 98.35%, Test Acc: 98.22%
Post-Pruning Training Epoch [3/10]: Loss: 0.0388, Train Acc: 98.78%, Test Acc: 98.42%
Post-Pruning Training Epoch [4/10]: Loss: 0.0315, Train Acc: 98.97%, Test Acc: 98.78%
Post-Pruning Training Epoch [5/10]: Loss: 0.0263, Train Acc: 99.16%, Test Acc: 99.08%
Post-Pruning Training Epoch [6/10]: Loss: 0.0218, Train Acc: 99.28%, Test Acc: 98.98%
Post-Pruning Training Epoch [7/10]: Loss: 0.0197, Train Acc: 99.36%, Test Acc: 98.88%
Post-Pruning Training Epoch [8/10]: Loss: 0.0162, Train Acc: 99.49%, Test Acc: 99.00%
Post-Pruning Training Epoch [9/10]: Loss: 0.0143, Train Acc: 99.53%, Test Acc: 99.12%
Post-Pruning Training Epoch [10/10]: Loss: 0.0143, Train Acc: 99.51%, Test Acc: 99.04%
Post-Pruned Baseline Model Accuracy: 99.06%
Post-Pruned Low Forgetting Model Accuracy: 99.00%
Post-Pruned High Forgetting Model Accuracy: 99.04%
Accuracy results saved to results/LeNet/MNIST/dr0.1/pr0.8/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.1/pr0.8/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 12000 highest-forgetting and top 12000 lowest-forgetting samples.
Highest forgetting subset size: 12000, Lowest forgetting subset size: 12000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.7316, Accuracy: 78.08%
Epoch [2/10] complete: Loss: 0.1785, Accuracy: 94.59%
Epoch [3/10] complete: Loss: 0.1151, Accuracy: 96.45%
Epoch [4/10] complete: Loss: 0.0865, Accuracy: 97.21%
Epoch [5/10] complete: Loss: 0.0626, Accuracy: 98.09%
Epoch [6/10] complete: Loss: 0.0527, Accuracy: 98.23%
Epoch [7/10] complete: Loss: 0.0421, Accuracy: 98.66%
Epoch [8/10] complete: Loss: 0.0375, Accuracy: 98.75%
Epoch [9/10] complete: Loss: 0.0297, Accuracy: 99.11%
Epoch [10/10] complete: Loss: 0.0225, Accuracy: 99.25%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.7761, Accuracy: 76.87%
Epoch [2/10] complete: Loss: 0.1952, Accuracy: 94.03%
Epoch [3/10] complete: Loss: 0.1256, Accuracy: 96.11%
Epoch [4/10] complete: Loss: 0.0973, Accuracy: 96.95%
Epoch [5/10] complete: Loss: 0.0770, Accuracy: 97.49%
Epoch [6/10] complete: Loss: 0.0642, Accuracy: 97.99%
Epoch [7/10] complete: Loss: 0.0488, Accuracy: 98.42%
Epoch [8/10] complete: Loss: 0.0438, Accuracy: 98.62%
Epoch [9/10] complete: Loss: 0.0364, Accuracy: 98.83%
Epoch [10/10] complete: Loss: 0.0298, Accuracy: 99.04%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 97.91%
High Forgetting Model Accuracy: 98.65%
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.2/pr0.0/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.92%
Pruned Low Forgetting Model Accuracy: 97.91%
Pruned High Forgetting Model Accuracy: 98.65%
Post-Pruning Retraining...
Initial Test Accuracy: 98.92%
Post-Pruning Training Epoch [1/10]: Loss: 0.0163, Train Acc: 99.47%, Test Acc: 98.90%
Post-Pruning Training Epoch [2/10]: Loss: 0.0137, Train Acc: 99.54%, Test Acc: 98.85%
Post-Pruning Training Epoch [3/10]: Loss: 0.0111, Train Acc: 99.65%, Test Acc: 98.92%
Post-Pruning Training Epoch [4/10]: Loss: 0.0116, Train Acc: 99.61%, Test Acc: 98.85%
Post-Pruning Training Epoch [5/10]: Loss: 0.0097, Train Acc: 99.68%, Test Acc: 98.96%
Post-Pruning Training Epoch [6/10]: Loss: 0.0097, Train Acc: 99.67%, Test Acc: 99.04%
Post-Pruning Training Epoch [7/10]: Loss: 0.0085, Train Acc: 99.71%, Test Acc: 98.79%
Post-Pruning Training Epoch [8/10]: Loss: 0.0078, Train Acc: 99.73%, Test Acc: 98.62%
Post-Pruning Training Epoch [9/10]: Loss: 0.0084, Train Acc: 99.75%, Test Acc: 98.91%
Post-Pruning Training Epoch [10/10]: Loss: 0.0078, Train Acc: 99.77%, Test Acc: 99.04%
Initial Test Accuracy: 97.91%
Post-Pruning Training Epoch [1/10]: Loss: 0.0618, Train Acc: 98.07%, Test Acc: 98.37%
Post-Pruning Training Epoch [2/10]: Loss: 0.0445, Train Acc: 98.63%, Test Acc: 98.75%
Post-Pruning Training Epoch [3/10]: Loss: 0.0352, Train Acc: 98.89%, Test Acc: 98.76%
Post-Pruning Training Epoch [4/10]: Loss: 0.0284, Train Acc: 99.10%, Test Acc: 98.98%
Post-Pruning Training Epoch [5/10]: Loss: 0.0232, Train Acc: 99.23%, Test Acc: 98.92%
Post-Pruning Training Epoch [6/10]: Loss: 0.0217, Train Acc: 99.30%, Test Acc: 98.83%
Post-Pruning Training Epoch [7/10]: Loss: 0.0181, Train Acc: 99.42%, Test Acc: 98.93%
Post-Pruning Training Epoch [8/10]: Loss: 0.0143, Train Acc: 99.55%, Test Acc: 98.81%
Post-Pruning Training Epoch [9/10]: Loss: 0.0142, Train Acc: 99.54%, Test Acc: 98.59%
Post-Pruning Training Epoch [10/10]: Loss: 0.0126, Train Acc: 99.59%, Test Acc: 99.08%
Initial Test Accuracy: 98.65%
Post-Pruning Training Epoch [1/10]: Loss: 0.0582, Train Acc: 98.20%, Test Acc: 98.71%
Post-Pruning Training Epoch [2/10]: Loss: 0.0402, Train Acc: 98.80%, Test Acc: 98.40%
Post-Pruning Training Epoch [3/10]: Loss: 0.0321, Train Acc: 98.98%, Test Acc: 98.85%
Post-Pruning Training Epoch [4/10]: Loss: 0.0260, Train Acc: 99.16%, Test Acc: 98.97%
Post-Pruning Training Epoch [5/10]: Loss: 0.0230, Train Acc: 99.23%, Test Acc: 98.93%
Post-Pruning Training Epoch [6/10]: Loss: 0.0185, Train Acc: 99.41%, Test Acc: 98.87%
Post-Pruning Training Epoch [7/10]: Loss: 0.0176, Train Acc: 99.41%, Test Acc: 99.02%
Post-Pruning Training Epoch [8/10]: Loss: 0.0136, Train Acc: 99.58%, Test Acc: 99.08%
Post-Pruning Training Epoch [9/10]: Loss: 0.0139, Train Acc: 99.56%, Test Acc: 99.10%
Post-Pruning Training Epoch [10/10]: Loss: 0.0125, Train Acc: 99.59%, Test Acc: 99.16%
Post-Pruned Baseline Model Accuracy: 99.04%
Post-Pruned Low Forgetting Model Accuracy: 99.08%
Post-Pruned High Forgetting Model Accuracy: 99.16%
Accuracy results saved to results/LeNet/MNIST/dr0.2/pr0.0/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.2/pr0.0/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 12000 highest-forgetting and top 12000 lowest-forgetting samples.
Highest forgetting subset size: 12000, Lowest forgetting subset size: 12000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.7313, Accuracy: 78.09%
Epoch [2/10] complete: Loss: 0.1793, Accuracy: 94.58%
Epoch [3/10] complete: Loss: 0.1151, Accuracy: 96.39%
Epoch [4/10] complete: Loss: 0.0851, Accuracy: 97.25%
Epoch [5/10] complete: Loss: 0.0621, Accuracy: 98.01%
Epoch [6/10] complete: Loss: 0.0525, Accuracy: 98.24%
Epoch [7/10] complete: Loss: 0.0410, Accuracy: 98.72%
Epoch [8/10] complete: Loss: 0.0360, Accuracy: 98.78%
Epoch [9/10] complete: Loss: 0.0307, Accuracy: 99.05%
Epoch [10/10] complete: Loss: 0.0242, Accuracy: 99.16%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.7766, Accuracy: 76.92%
Epoch [2/10] complete: Loss: 0.1958, Accuracy: 93.98%
Epoch [3/10] complete: Loss: 0.1247, Accuracy: 96.03%
Epoch [4/10] complete: Loss: 0.0960, Accuracy: 97.05%
Epoch [5/10] complete: Loss: 0.0737, Accuracy: 97.61%
Epoch [6/10] complete: Loss: 0.0626, Accuracy: 98.00%
Epoch [7/10] complete: Loss: 0.0471, Accuracy: 98.45%
Epoch [8/10] complete: Loss: 0.0432, Accuracy: 98.61%
Epoch [9/10] complete: Loss: 0.0317, Accuracy: 99.02%
Epoch [10/10] complete: Loss: 0.0279, Accuracy: 99.08%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 97.89%
High Forgetting Model Accuracy: 98.56%
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.2/pr0.2/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.91%
Pruned Low Forgetting Model Accuracy: 98.00%
Pruned High Forgetting Model Accuracy: 98.56%
Post-Pruning Retraining...
Initial Test Accuracy: 98.91%
Post-Pruning Training Epoch [1/10]: Loss: 0.0168, Train Acc: 99.44%, Test Acc: 98.99%
Post-Pruning Training Epoch [2/10]: Loss: 0.0131, Train Acc: 99.57%, Test Acc: 99.14%
Post-Pruning Training Epoch [3/10]: Loss: 0.0114, Train Acc: 99.62%, Test Acc: 98.91%
Post-Pruning Training Epoch [4/10]: Loss: 0.0109, Train Acc: 99.62%, Test Acc: 98.92%
Post-Pruning Training Epoch [5/10]: Loss: 0.0097, Train Acc: 99.67%, Test Acc: 98.94%
Post-Pruning Training Epoch [6/10]: Loss: 0.0082, Train Acc: 99.74%, Test Acc: 98.69%
Post-Pruning Training Epoch [7/10]: Loss: 0.0099, Train Acc: 99.65%, Test Acc: 98.72%
Post-Pruning Training Epoch [8/10]: Loss: 0.0074, Train Acc: 99.77%, Test Acc: 99.08%
Post-Pruning Training Epoch [9/10]: Loss: 0.0092, Train Acc: 99.70%, Test Acc: 98.88%
Post-Pruning Training Epoch [10/10]: Loss: 0.0083, Train Acc: 99.75%, Test Acc: 98.85%
Initial Test Accuracy: 98.00%
Post-Pruning Training Epoch [1/10]: Loss: 0.0615, Train Acc: 98.06%, Test Acc: 98.54%
Post-Pruning Training Epoch [2/10]: Loss: 0.0444, Train Acc: 98.60%, Test Acc: 98.68%
Post-Pruning Training Epoch [3/10]: Loss: 0.0347, Train Acc: 98.87%, Test Acc: 98.77%
Post-Pruning Training Epoch [4/10]: Loss: 0.0284, Train Acc: 99.09%, Test Acc: 98.81%
Post-Pruning Training Epoch [5/10]: Loss: 0.0239, Train Acc: 99.21%, Test Acc: 98.84%
Post-Pruning Training Epoch [6/10]: Loss: 0.0214, Train Acc: 99.31%, Test Acc: 98.72%
Post-Pruning Training Epoch [7/10]: Loss: 0.0188, Train Acc: 99.37%, Test Acc: 98.92%
Post-Pruning Training Epoch [8/10]: Loss: 0.0140, Train Acc: 99.52%, Test Acc: 98.73%
Post-Pruning Training Epoch [9/10]: Loss: 0.0147, Train Acc: 99.49%, Test Acc: 98.84%
Post-Pruning Training Epoch [10/10]: Loss: 0.0126, Train Acc: 99.59%, Test Acc: 98.66%
Initial Test Accuracy: 98.56%
Post-Pruning Training Epoch [1/10]: Loss: 0.0579, Train Acc: 98.21%, Test Acc: 98.73%
Post-Pruning Training Epoch [2/10]: Loss: 0.0400, Train Acc: 98.74%, Test Acc: 98.47%
Post-Pruning Training Epoch [3/10]: Loss: 0.0322, Train Acc: 99.01%, Test Acc: 98.89%
Post-Pruning Training Epoch [4/10]: Loss: 0.0257, Train Acc: 99.15%, Test Acc: 98.86%
Post-Pruning Training Epoch [5/10]: Loss: 0.0233, Train Acc: 99.23%, Test Acc: 98.99%
Post-Pruning Training Epoch [6/10]: Loss: 0.0179, Train Acc: 99.40%, Test Acc: 98.91%
Post-Pruning Training Epoch [7/10]: Loss: 0.0164, Train Acc: 99.44%, Test Acc: 99.07%
Post-Pruning Training Epoch [8/10]: Loss: 0.0150, Train Acc: 99.52%, Test Acc: 98.87%
Post-Pruning Training Epoch [9/10]: Loss: 0.0147, Train Acc: 99.48%, Test Acc: 98.77%
Post-Pruning Training Epoch [10/10]: Loss: 0.0115, Train Acc: 99.60%, Test Acc: 98.96%
Post-Pruned Baseline Model Accuracy: 98.85%
Post-Pruned Low Forgetting Model Accuracy: 98.66%
Post-Pruned High Forgetting Model Accuracy: 98.96%
Accuracy results saved to results/LeNet/MNIST/dr0.2/pr0.2/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.2/pr0.2/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 12000 highest-forgetting and top 12000 lowest-forgetting samples.
Highest forgetting subset size: 12000, Lowest forgetting subset size: 12000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.7319, Accuracy: 78.13%
Epoch [2/10] complete: Loss: 0.1798, Accuracy: 94.63%
Epoch [3/10] complete: Loss: 0.1163, Accuracy: 96.45%
Epoch [4/10] complete: Loss: 0.0859, Accuracy: 97.18%
Epoch [5/10] complete: Loss: 0.0629, Accuracy: 98.05%
Epoch [6/10] complete: Loss: 0.0537, Accuracy: 98.23%
Epoch [7/10] complete: Loss: 0.0416, Accuracy: 98.75%
Epoch [8/10] complete: Loss: 0.0366, Accuracy: 98.80%
Epoch [9/10] complete: Loss: 0.0293, Accuracy: 99.10%
Epoch [10/10] complete: Loss: 0.0254, Accuracy: 99.15%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.7767, Accuracy: 76.88%
Epoch [2/10] complete: Loss: 0.1970, Accuracy: 93.91%
Epoch [3/10] complete: Loss: 0.1260, Accuracy: 95.96%
Epoch [4/10] complete: Loss: 0.0974, Accuracy: 96.96%
Epoch [5/10] complete: Loss: 0.0757, Accuracy: 97.54%
Epoch [6/10] complete: Loss: 0.0634, Accuracy: 97.97%
Epoch [7/10] complete: Loss: 0.0482, Accuracy: 98.40%
Epoch [8/10] complete: Loss: 0.0435, Accuracy: 98.59%
Epoch [9/10] complete: Loss: 0.0334, Accuracy: 98.88%
Epoch [10/10] complete: Loss: 0.0276, Accuracy: 99.13%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.15%
High Forgetting Model Accuracy: 98.51%
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.2/pr0.4/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.46%
Pruned Low Forgetting Model Accuracy: 96.49%
Pruned High Forgetting Model Accuracy: 98.34%
Post-Pruning Retraining...
Initial Test Accuracy: 98.46%
Post-Pruning Training Epoch [1/10]: Loss: 0.0179, Train Acc: 99.44%, Test Acc: 98.94%
Post-Pruning Training Epoch [2/10]: Loss: 0.0131, Train Acc: 99.55%, Test Acc: 98.76%
Post-Pruning Training Epoch [3/10]: Loss: 0.0116, Train Acc: 99.61%, Test Acc: 99.05%
Post-Pruning Training Epoch [4/10]: Loss: 0.0116, Train Acc: 99.58%, Test Acc: 98.92%
Post-Pruning Training Epoch [5/10]: Loss: 0.0092, Train Acc: 99.68%, Test Acc: 98.91%
Post-Pruning Training Epoch [6/10]: Loss: 0.0097, Train Acc: 99.69%, Test Acc: 98.76%
Post-Pruning Training Epoch [7/10]: Loss: 0.0097, Train Acc: 99.67%, Test Acc: 98.96%
Post-Pruning Training Epoch [8/10]: Loss: 0.0090, Train Acc: 99.69%, Test Acc: 99.13%
Post-Pruning Training Epoch [9/10]: Loss: 0.0068, Train Acc: 99.78%, Test Acc: 98.95%
Post-Pruning Training Epoch [10/10]: Loss: 0.0063, Train Acc: 99.78%, Test Acc: 99.03%
Initial Test Accuracy: 96.49%
Post-Pruning Training Epoch [1/10]: Loss: 0.0625, Train Acc: 98.03%, Test Acc: 98.45%
Post-Pruning Training Epoch [2/10]: Loss: 0.0448, Train Acc: 98.56%, Test Acc: 98.71%
Post-Pruning Training Epoch [3/10]: Loss: 0.0350, Train Acc: 98.87%, Test Acc: 98.60%
Post-Pruning Training Epoch [4/10]: Loss: 0.0287, Train Acc: 99.12%, Test Acc: 98.99%
Post-Pruning Training Epoch [5/10]: Loss: 0.0240, Train Acc: 99.19%, Test Acc: 98.90%
Post-Pruning Training Epoch [6/10]: Loss: 0.0213, Train Acc: 99.29%, Test Acc: 98.65%
Post-Pruning Training Epoch [7/10]: Loss: 0.0184, Train Acc: 99.39%, Test Acc: 98.91%
Post-Pruning Training Epoch [8/10]: Loss: 0.0159, Train Acc: 99.47%, Test Acc: 98.95%
Post-Pruning Training Epoch [9/10]: Loss: 0.0143, Train Acc: 99.54%, Test Acc: 98.84%
Post-Pruning Training Epoch [10/10]: Loss: 0.0129, Train Acc: 99.55%, Test Acc: 98.95%
Initial Test Accuracy: 98.34%
Post-Pruning Training Epoch [1/10]: Loss: 0.0579, Train Acc: 98.20%, Test Acc: 98.56%
Post-Pruning Training Epoch [2/10]: Loss: 0.0401, Train Acc: 98.73%, Test Acc: 98.46%
Post-Pruning Training Epoch [3/10]: Loss: 0.0319, Train Acc: 99.00%, Test Acc: 98.95%
Post-Pruning Training Epoch [4/10]: Loss: 0.0253, Train Acc: 99.17%, Test Acc: 99.02%
Post-Pruning Training Epoch [5/10]: Loss: 0.0218, Train Acc: 99.26%, Test Acc: 99.09%
Post-Pruning Training Epoch [6/10]: Loss: 0.0180, Train Acc: 99.39%, Test Acc: 98.98%
Post-Pruning Training Epoch [7/10]: Loss: 0.0168, Train Acc: 99.43%, Test Acc: 99.05%
Post-Pruning Training Epoch [8/10]: Loss: 0.0142, Train Acc: 99.53%, Test Acc: 99.03%
Post-Pruning Training Epoch [9/10]: Loss: 0.0137, Train Acc: 99.53%, Test Acc: 99.10%
Post-Pruning Training Epoch [10/10]: Loss: 0.0118, Train Acc: 99.61%, Test Acc: 98.98%
Post-Pruned Baseline Model Accuracy: 99.03%
Post-Pruned Low Forgetting Model Accuracy: 98.95%
Post-Pruned High Forgetting Model Accuracy: 98.98%
Accuracy results saved to results/LeNet/MNIST/dr0.2/pr0.4/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.2/pr0.4/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 12000 highest-forgetting and top 12000 lowest-forgetting samples.
Highest forgetting subset size: 12000, Lowest forgetting subset size: 12000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.7330, Accuracy: 78.11%
Epoch [2/10] complete: Loss: 0.1796, Accuracy: 94.53%
Epoch [3/10] complete: Loss: 0.1147, Accuracy: 96.52%
Epoch [4/10] complete: Loss: 0.0840, Accuracy: 97.30%
Epoch [5/10] complete: Loss: 0.0607, Accuracy: 98.19%
Epoch [6/10] complete: Loss: 0.0524, Accuracy: 98.22%
Epoch [7/10] complete: Loss: 0.0409, Accuracy: 98.72%
Epoch [8/10] complete: Loss: 0.0351, Accuracy: 98.80%
Epoch [9/10] complete: Loss: 0.0298, Accuracy: 99.05%
Epoch [10/10] complete: Loss: 0.0218, Accuracy: 99.32%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.7764, Accuracy: 76.90%
Epoch [2/10] complete: Loss: 0.1970, Accuracy: 93.88%
Epoch [3/10] complete: Loss: 0.1265, Accuracy: 95.98%
Epoch [4/10] complete: Loss: 0.0975, Accuracy: 96.98%
Epoch [5/10] complete: Loss: 0.0757, Accuracy: 97.55%
Epoch [6/10] complete: Loss: 0.0652, Accuracy: 97.88%
Epoch [7/10] complete: Loss: 0.0495, Accuracy: 98.28%
Epoch [8/10] complete: Loss: 0.0437, Accuracy: 98.58%
Epoch [9/10] complete: Loss: 0.0351, Accuracy: 98.90%
Epoch [10/10] complete: Loss: 0.0293, Accuracy: 99.08%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 97.97%
High Forgetting Model Accuracy: 98.56%
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.2/pr0.6/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 93.18%
Pruned Low Forgetting Model Accuracy: 93.53%
Pruned High Forgetting Model Accuracy: 97.88%
Post-Pruning Retraining...
Initial Test Accuracy: 93.18%
Post-Pruning Training Epoch [1/10]: Loss: 0.0220, Train Acc: 99.28%, Test Acc: 99.00%
Post-Pruning Training Epoch [2/10]: Loss: 0.0156, Train Acc: 99.50%, Test Acc: 98.89%
Post-Pruning Training Epoch [3/10]: Loss: 0.0125, Train Acc: 99.57%, Test Acc: 98.59%
Post-Pruning Training Epoch [4/10]: Loss: 0.0121, Train Acc: 99.58%, Test Acc: 99.01%
Post-Pruning Training Epoch [5/10]: Loss: 0.0104, Train Acc: 99.70%, Test Acc: 98.96%
Post-Pruning Training Epoch [6/10]: Loss: 0.0091, Train Acc: 99.68%, Test Acc: 98.64%
Post-Pruning Training Epoch [7/10]: Loss: 0.0094, Train Acc: 99.68%, Test Acc: 98.97%
Post-Pruning Training Epoch [8/10]: Loss: 0.0087, Train Acc: 99.70%, Test Acc: 98.84%
Post-Pruning Training Epoch [9/10]: Loss: 0.0084, Train Acc: 99.71%, Test Acc: 98.98%
Post-Pruning Training Epoch [10/10]: Loss: 0.0074, Train Acc: 99.76%, Test Acc: 98.71%
Initial Test Accuracy: 93.53%
Post-Pruning Training Epoch [1/10]: Loss: 0.0651, Train Acc: 97.96%, Test Acc: 98.29%
Post-Pruning Training Epoch [2/10]: Loss: 0.0456, Train Acc: 98.53%, Test Acc: 98.80%
Post-Pruning Training Epoch [3/10]: Loss: 0.0368, Train Acc: 98.80%, Test Acc: 98.64%
Post-Pruning Training Epoch [4/10]: Loss: 0.0301, Train Acc: 99.03%, Test Acc: 98.88%
Post-Pruning Training Epoch [5/10]: Loss: 0.0237, Train Acc: 99.25%, Test Acc: 98.66%
Post-Pruning Training Epoch [6/10]: Loss: 0.0229, Train Acc: 99.23%, Test Acc: 98.76%
Post-Pruning Training Epoch [7/10]: Loss: 0.0190, Train Acc: 99.39%, Test Acc: 98.89%
Post-Pruning Training Epoch [8/10]: Loss: 0.0158, Train Acc: 99.46%, Test Acc: 98.95%
Post-Pruning Training Epoch [9/10]: Loss: 0.0142, Train Acc: 99.52%, Test Acc: 98.76%
Post-Pruning Training Epoch [10/10]: Loss: 0.0130, Train Acc: 99.56%, Test Acc: 98.84%
Initial Test Accuracy: 97.88%
Post-Pruning Training Epoch [1/10]: Loss: 0.0613, Train Acc: 98.08%, Test Acc: 98.69%
Post-Pruning Training Epoch [2/10]: Loss: 0.0413, Train Acc: 98.73%, Test Acc: 98.48%
Post-Pruning Training Epoch [3/10]: Loss: 0.0332, Train Acc: 98.92%, Test Acc: 98.86%
Post-Pruning Training Epoch [4/10]: Loss: 0.0255, Train Acc: 99.16%, Test Acc: 98.96%
Post-Pruning Training Epoch [5/10]: Loss: 0.0223, Train Acc: 99.27%, Test Acc: 98.96%
Post-Pruning Training Epoch [6/10]: Loss: 0.0194, Train Acc: 99.37%, Test Acc: 99.08%
Post-Pruning Training Epoch [7/10]: Loss: 0.0157, Train Acc: 99.49%, Test Acc: 99.15%
Post-Pruning Training Epoch [8/10]: Loss: 0.0142, Train Acc: 99.54%, Test Acc: 99.12%
Post-Pruning Training Epoch [9/10]: Loss: 0.0141, Train Acc: 99.55%, Test Acc: 99.14%
Post-Pruning Training Epoch [10/10]: Loss: 0.0124, Train Acc: 99.58%, Test Acc: 99.05%
Post-Pruned Baseline Model Accuracy: 98.71%
Post-Pruned Low Forgetting Model Accuracy: 98.84%
Post-Pruned High Forgetting Model Accuracy: 99.05%
Accuracy results saved to results/LeNet/MNIST/dr0.2/pr0.6/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.2/pr0.6/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 12000 highest-forgetting and top 12000 lowest-forgetting samples.
Highest forgetting subset size: 12000, Lowest forgetting subset size: 12000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.7312, Accuracy: 78.12%
Epoch [2/10] complete: Loss: 0.1791, Accuracy: 94.61%
Epoch [3/10] complete: Loss: 0.1144, Accuracy: 96.51%
Epoch [4/10] complete: Loss: 0.0843, Accuracy: 97.25%
Epoch [5/10] complete: Loss: 0.0605, Accuracy: 98.12%
Epoch [6/10] complete: Loss: 0.0521, Accuracy: 98.30%
Epoch [7/10] complete: Loss: 0.0409, Accuracy: 98.72%
Epoch [8/10] complete: Loss: 0.0375, Accuracy: 98.75%
Epoch [9/10] complete: Loss: 0.0288, Accuracy: 99.08%
Epoch [10/10] complete: Loss: 0.0250, Accuracy: 99.17%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.7754, Accuracy: 76.89%
Epoch [2/10] complete: Loss: 0.1968, Accuracy: 93.93%
Epoch [3/10] complete: Loss: 0.1268, Accuracy: 96.06%
Epoch [4/10] complete: Loss: 0.0977, Accuracy: 97.02%
Epoch [5/10] complete: Loss: 0.0773, Accuracy: 97.46%
Epoch [6/10] complete: Loss: 0.0654, Accuracy: 97.93%
Epoch [7/10] complete: Loss: 0.0497, Accuracy: 98.33%
Epoch [8/10] complete: Loss: 0.0448, Accuracy: 98.53%
Epoch [9/10] complete: Loss: 0.0366, Accuracy: 98.81%
Epoch [10/10] complete: Loss: 0.0291, Accuracy: 99.13%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 97.79%
High Forgetting Model Accuracy: 98.52%
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.2/pr0.8/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 43.24%
Pruned Low Forgetting Model Accuracy: 39.06%
Pruned High Forgetting Model Accuracy: 43.95%
Post-Pruning Retraining...
Initial Test Accuracy: 43.24%
Post-Pruning Training Epoch [1/10]: Loss: 0.0511, Train Acc: 98.53%, Test Acc: 99.15%
Post-Pruning Training Epoch [2/10]: Loss: 0.0219, Train Acc: 99.31%, Test Acc: 98.93%
Post-Pruning Training Epoch [3/10]: Loss: 0.0179, Train Acc: 99.41%, Test Acc: 99.09%
Post-Pruning Training Epoch [4/10]: Loss: 0.0146, Train Acc: 99.52%, Test Acc: 98.95%
Post-Pruning Training Epoch [5/10]: Loss: 0.0130, Train Acc: 99.54%, Test Acc: 98.44%
Post-Pruning Training Epoch [6/10]: Loss: 0.0122, Train Acc: 99.59%, Test Acc: 98.88%
Post-Pruning Training Epoch [7/10]: Loss: 0.0116, Train Acc: 99.61%, Test Acc: 99.00%
Post-Pruning Training Epoch [8/10]: Loss: 0.0114, Train Acc: 99.63%, Test Acc: 98.97%
Post-Pruning Training Epoch [9/10]: Loss: 0.0084, Train Acc: 99.72%, Test Acc: 98.86%
Post-Pruning Training Epoch [10/10]: Loss: 0.0084, Train Acc: 99.72%, Test Acc: 99.01%
Initial Test Accuracy: 39.06%
Post-Pruning Training Epoch [1/10]: Loss: 0.0879, Train Acc: 97.43%, Test Acc: 98.30%
Post-Pruning Training Epoch [2/10]: Loss: 0.0500, Train Acc: 98.42%, Test Acc: 98.58%
Post-Pruning Training Epoch [3/10]: Loss: 0.0396, Train Acc: 98.75%, Test Acc: 98.62%
Post-Pruning Training Epoch [4/10]: Loss: 0.0335, Train Acc: 98.94%, Test Acc: 99.05%
Post-Pruning Training Epoch [5/10]: Loss: 0.0270, Train Acc: 99.17%, Test Acc: 99.00%
Post-Pruning Training Epoch [6/10]: Loss: 0.0243, Train Acc: 99.22%, Test Acc: 98.73%
Post-Pruning Training Epoch [7/10]: Loss: 0.0204, Train Acc: 99.34%, Test Acc: 98.64%
Post-Pruning Training Epoch [8/10]: Loss: 0.0177, Train Acc: 99.40%, Test Acc: 98.69%
Post-Pruning Training Epoch [9/10]: Loss: 0.0155, Train Acc: 99.49%, Test Acc: 98.71%
Post-Pruning Training Epoch [10/10]: Loss: 0.0163, Train Acc: 99.45%, Test Acc: 98.82%
Initial Test Accuracy: 43.95%
Post-Pruning Training Epoch [1/10]: Loss: 0.0862, Train Acc: 97.51%, Test Acc: 98.73%
Post-Pruning Training Epoch [2/10]: Loss: 0.0464, Train Acc: 98.53%, Test Acc: 98.42%
Post-Pruning Training Epoch [3/10]: Loss: 0.0360, Train Acc: 98.88%, Test Acc: 98.60%
Post-Pruning Training Epoch [4/10]: Loss: 0.0299, Train Acc: 99.03%, Test Acc: 98.95%
Post-Pruning Training Epoch [5/10]: Loss: 0.0254, Train Acc: 99.17%, Test Acc: 99.05%
Post-Pruning Training Epoch [6/10]: Loss: 0.0197, Train Acc: 99.33%, Test Acc: 98.93%
Post-Pruning Training Epoch [7/10]: Loss: 0.0189, Train Acc: 99.36%, Test Acc: 98.95%
Post-Pruning Training Epoch [8/10]: Loss: 0.0157, Train Acc: 99.47%, Test Acc: 99.00%
Post-Pruning Training Epoch [9/10]: Loss: 0.0137, Train Acc: 99.53%, Test Acc: 98.91%
Post-Pruning Training Epoch [10/10]: Loss: 0.0120, Train Acc: 99.61%, Test Acc: 99.01%
Post-Pruned Baseline Model Accuracy: 99.01%
Post-Pruned Low Forgetting Model Accuracy: 98.82%
Post-Pruned High Forgetting Model Accuracy: 99.01%
Accuracy results saved to results/LeNet/MNIST/dr0.2/pr0.8/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.2/pr0.8/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 18000 highest-forgetting and top 18000 lowest-forgetting samples.
Highest forgetting subset size: 18000, Lowest forgetting subset size: 18000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.5440, Accuracy: 83.91%
Epoch [2/10] complete: Loss: 0.1360, Accuracy: 95.96%
Epoch [3/10] complete: Loss: 0.0856, Accuracy: 97.34%
Epoch [4/10] complete: Loss: 0.0651, Accuracy: 98.02%
Epoch [5/10] complete: Loss: 0.0498, Accuracy: 98.41%
Epoch [6/10] complete: Loss: 0.0410, Accuracy: 98.62%
Epoch [7/10] complete: Loss: 0.0327, Accuracy: 98.96%
Epoch [8/10] complete: Loss: 0.0288, Accuracy: 99.01%
Epoch [9/10] complete: Loss: 0.0238, Accuracy: 99.24%
Epoch [10/10] complete: Loss: 0.0187, Accuracy: 99.33%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.6193, Accuracy: 81.11%
Epoch [2/10] complete: Loss: 0.1518, Accuracy: 95.33%
Epoch [3/10] complete: Loss: 0.0997, Accuracy: 96.82%
Epoch [4/10] complete: Loss: 0.0757, Accuracy: 97.72%
Epoch [5/10] complete: Loss: 0.0654, Accuracy: 98.01%
Epoch [6/10] complete: Loss: 0.0515, Accuracy: 98.24%
Epoch [7/10] complete: Loss: 0.0435, Accuracy: 98.61%
Epoch [8/10] complete: Loss: 0.0367, Accuracy: 98.82%
Epoch [9/10] complete: Loss: 0.0330, Accuracy: 98.94%
Epoch [10/10] complete: Loss: 0.0289, Accuracy: 99.12%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.25%
High Forgetting Model Accuracy: 98.36%
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.3/pr0.0/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.92%
Pruned Low Forgetting Model Accuracy: 98.25%
Pruned High Forgetting Model Accuracy: 98.36%
Post-Pruning Retraining...
Initial Test Accuracy: 98.92%
Post-Pruning Training Epoch [1/10]: Loss: 0.0164, Train Acc: 99.44%, Test Acc: 98.95%
Post-Pruning Training Epoch [2/10]: Loss: 0.0138, Train Acc: 99.54%, Test Acc: 98.99%
Post-Pruning Training Epoch [3/10]: Loss: 0.0110, Train Acc: 99.62%, Test Acc: 99.03%
Post-Pruning Training Epoch [4/10]: Loss: 0.0106, Train Acc: 99.66%, Test Acc: 99.04%
Post-Pruning Training Epoch [5/10]: Loss: 0.0091, Train Acc: 99.69%, Test Acc: 98.77%
Post-Pruning Training Epoch [6/10]: Loss: 0.0101, Train Acc: 99.68%, Test Acc: 98.99%
Post-Pruning Training Epoch [7/10]: Loss: 0.0090, Train Acc: 99.69%, Test Acc: 99.12%
Post-Pruning Training Epoch [8/10]: Loss: 0.0081, Train Acc: 99.72%, Test Acc: 98.95%
Post-Pruning Training Epoch [9/10]: Loss: 0.0079, Train Acc: 99.73%, Test Acc: 99.09%
Post-Pruning Training Epoch [10/10]: Loss: 0.0076, Train Acc: 99.74%, Test Acc: 98.89%
Initial Test Accuracy: 98.25%
Post-Pruning Training Epoch [1/10]: Loss: 0.0523, Train Acc: 98.43%, Test Acc: 98.60%
Post-Pruning Training Epoch [2/10]: Loss: 0.0387, Train Acc: 98.82%, Test Acc: 98.64%
Post-Pruning Training Epoch [3/10]: Loss: 0.0327, Train Acc: 98.94%, Test Acc: 98.87%
Post-Pruning Training Epoch [4/10]: Loss: 0.0271, Train Acc: 99.16%, Test Acc: 98.56%
Post-Pruning Training Epoch [5/10]: Loss: 0.0213, Train Acc: 99.30%, Test Acc: 98.89%
Post-Pruning Training Epoch [6/10]: Loss: 0.0211, Train Acc: 99.29%, Test Acc: 98.84%
Post-Pruning Training Epoch [7/10]: Loss: 0.0183, Train Acc: 99.38%, Test Acc: 98.91%
Post-Pruning Training Epoch [8/10]: Loss: 0.0137, Train Acc: 99.54%, Test Acc: 98.77%
Post-Pruning Training Epoch [9/10]: Loss: 0.0144, Train Acc: 99.54%, Test Acc: 98.91%
Post-Pruning Training Epoch [10/10]: Loss: 0.0140, Train Acc: 99.53%, Test Acc: 98.89%
Initial Test Accuracy: 98.36%
Post-Pruning Training Epoch [1/10]: Loss: 0.0459, Train Acc: 98.63%, Test Acc: 98.76%
Post-Pruning Training Epoch [2/10]: Loss: 0.0332, Train Acc: 98.97%, Test Acc: 98.79%
Post-Pruning Training Epoch [3/10]: Loss: 0.0266, Train Acc: 99.18%, Test Acc: 98.73%
Post-Pruning Training Epoch [4/10]: Loss: 0.0216, Train Acc: 99.31%, Test Acc: 98.56%
Post-Pruning Training Epoch [5/10]: Loss: 0.0198, Train Acc: 99.38%, Test Acc: 98.85%
Post-Pruning Training Epoch [6/10]: Loss: 0.0170, Train Acc: 99.43%, Test Acc: 98.93%
Post-Pruning Training Epoch [7/10]: Loss: 0.0135, Train Acc: 99.57%, Test Acc: 98.93%
Post-Pruning Training Epoch [8/10]: Loss: 0.0124, Train Acc: 99.59%, Test Acc: 98.85%
Post-Pruning Training Epoch [9/10]: Loss: 0.0121, Train Acc: 99.60%, Test Acc: 99.08%
Post-Pruning Training Epoch [10/10]: Loss: 0.0111, Train Acc: 99.61%, Test Acc: 98.88%
Post-Pruned Baseline Model Accuracy: 98.89%
Post-Pruned Low Forgetting Model Accuracy: 98.89%
Post-Pruned High Forgetting Model Accuracy: 98.88%
Accuracy results saved to results/LeNet/MNIST/dr0.3/pr0.0/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.3/pr0.0/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 18000 highest-forgetting and top 18000 lowest-forgetting samples.
Highest forgetting subset size: 18000, Lowest forgetting subset size: 18000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.5434, Accuracy: 83.92%
Epoch [2/10] complete: Loss: 0.1354, Accuracy: 95.97%
Epoch [3/10] complete: Loss: 0.0859, Accuracy: 97.31%
Epoch [4/10] complete: Loss: 0.0657, Accuracy: 98.04%
Epoch [5/10] complete: Loss: 0.0515, Accuracy: 98.36%
Epoch [6/10] complete: Loss: 0.0414, Accuracy: 98.57%
Epoch [7/10] complete: Loss: 0.0324, Accuracy: 98.95%
Epoch [8/10] complete: Loss: 0.0272, Accuracy: 99.09%
Epoch [9/10] complete: Loss: 0.0233, Accuracy: 99.23%
Epoch [10/10] complete: Loss: 0.0195, Accuracy: 99.27%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.6194, Accuracy: 81.05%
Epoch [2/10] complete: Loss: 0.1514, Accuracy: 95.34%
Epoch [3/10] complete: Loss: 0.0994, Accuracy: 96.86%
Epoch [4/10] complete: Loss: 0.0747, Accuracy: 97.71%
Epoch [5/10] complete: Loss: 0.0645, Accuracy: 98.06%
Epoch [6/10] complete: Loss: 0.0503, Accuracy: 98.36%
Epoch [7/10] complete: Loss: 0.0430, Accuracy: 98.62%
Epoch [8/10] complete: Loss: 0.0348, Accuracy: 98.87%
Epoch [9/10] complete: Loss: 0.0316, Accuracy: 99.01%
Epoch [10/10] complete: Loss: 0.0296, Accuracy: 99.01%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.27%
High Forgetting Model Accuracy: 98.10%
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.3/pr0.2/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.91%
Pruned Low Forgetting Model Accuracy: 98.23%
Pruned High Forgetting Model Accuracy: 98.01%
Post-Pruning Retraining...
Initial Test Accuracy: 98.91%
Post-Pruning Training Epoch [1/10]: Loss: 0.0166, Train Acc: 99.45%, Test Acc: 98.98%
Post-Pruning Training Epoch [2/10]: Loss: 0.0125, Train Acc: 99.60%, Test Acc: 98.98%
Post-Pruning Training Epoch [3/10]: Loss: 0.0108, Train Acc: 99.64%, Test Acc: 98.69%
Post-Pruning Training Epoch [4/10]: Loss: 0.0121, Train Acc: 99.59%, Test Acc: 99.02%
Post-Pruning Training Epoch [5/10]: Loss: 0.0095, Train Acc: 99.69%, Test Acc: 98.95%
Post-Pruning Training Epoch [6/10]: Loss: 0.0091, Train Acc: 99.67%, Test Acc: 98.92%
Post-Pruning Training Epoch [7/10]: Loss: 0.0080, Train Acc: 99.72%, Test Acc: 98.75%
Post-Pruning Training Epoch [8/10]: Loss: 0.0088, Train Acc: 99.72%, Test Acc: 99.00%
Post-Pruning Training Epoch [9/10]: Loss: 0.0082, Train Acc: 99.73%, Test Acc: 98.83%
Post-Pruning Training Epoch [10/10]: Loss: 0.0073, Train Acc: 99.76%, Test Acc: 98.60%
Initial Test Accuracy: 98.23%
Post-Pruning Training Epoch [1/10]: Loss: 0.0521, Train Acc: 98.47%, Test Acc: 98.65%
Post-Pruning Training Epoch [2/10]: Loss: 0.0390, Train Acc: 98.78%, Test Acc: 98.67%
Post-Pruning Training Epoch [3/10]: Loss: 0.0322, Train Acc: 98.96%, Test Acc: 98.97%
Post-Pruning Training Epoch [4/10]: Loss: 0.0268, Train Acc: 99.15%, Test Acc: 98.63%
Post-Pruning Training Epoch [5/10]: Loss: 0.0213, Train Acc: 99.32%, Test Acc: 98.98%
Post-Pruning Training Epoch [6/10]: Loss: 0.0201, Train Acc: 99.31%, Test Acc: 98.62%
Post-Pruning Training Epoch [7/10]: Loss: 0.0169, Train Acc: 99.41%, Test Acc: 98.82%
Post-Pruning Training Epoch [8/10]: Loss: 0.0138, Train Acc: 99.53%, Test Acc: 98.77%
Post-Pruning Training Epoch [9/10]: Loss: 0.0147, Train Acc: 99.49%, Test Acc: 98.70%
Post-Pruning Training Epoch [10/10]: Loss: 0.0124, Train Acc: 99.58%, Test Acc: 98.77%
Initial Test Accuracy: 98.01%
Post-Pruning Training Epoch [1/10]: Loss: 0.0457, Train Acc: 98.63%, Test Acc: 98.75%
Post-Pruning Training Epoch [2/10]: Loss: 0.0337, Train Acc: 98.96%, Test Acc: 98.93%
Post-Pruning Training Epoch [3/10]: Loss: 0.0261, Train Acc: 99.19%, Test Acc: 98.81%
Post-Pruning Training Epoch [4/10]: Loss: 0.0214, Train Acc: 99.29%, Test Acc: 98.45%
Post-Pruning Training Epoch [5/10]: Loss: 0.0200, Train Acc: 99.35%, Test Acc: 98.82%
Post-Pruning Training Epoch [6/10]: Loss: 0.0165, Train Acc: 99.46%, Test Acc: 98.97%
Post-Pruning Training Epoch [7/10]: Loss: 0.0159, Train Acc: 99.50%, Test Acc: 98.99%
Post-Pruning Training Epoch [8/10]: Loss: 0.0127, Train Acc: 99.57%, Test Acc: 99.11%
Post-Pruning Training Epoch [9/10]: Loss: 0.0120, Train Acc: 99.61%, Test Acc: 98.81%
Post-Pruning Training Epoch [10/10]: Loss: 0.0115, Train Acc: 99.60%, Test Acc: 98.92%
Post-Pruned Baseline Model Accuracy: 98.60%
Post-Pruned Low Forgetting Model Accuracy: 98.77%
Post-Pruned High Forgetting Model Accuracy: 98.92%
Accuracy results saved to results/LeNet/MNIST/dr0.3/pr0.2/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.3/pr0.2/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 18000 highest-forgetting and top 18000 lowest-forgetting samples.
Highest forgetting subset size: 18000, Lowest forgetting subset size: 18000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.5436, Accuracy: 83.86%
Epoch [2/10] complete: Loss: 0.1343, Accuracy: 95.96%
Epoch [3/10] complete: Loss: 0.0852, Accuracy: 97.29%
Epoch [4/10] complete: Loss: 0.0645, Accuracy: 98.08%
Epoch [5/10] complete: Loss: 0.0504, Accuracy: 98.39%
Epoch [6/10] complete: Loss: 0.0399, Accuracy: 98.66%
Epoch [7/10] complete: Loss: 0.0316, Accuracy: 98.97%
Epoch [8/10] complete: Loss: 0.0277, Accuracy: 99.04%
Epoch [9/10] complete: Loss: 0.0225, Accuracy: 99.28%
Epoch [10/10] complete: Loss: 0.0210, Accuracy: 99.23%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.6194, Accuracy: 81.08%
Epoch [2/10] complete: Loss: 0.1507, Accuracy: 95.33%
Epoch [3/10] complete: Loss: 0.0987, Accuracy: 96.84%
Epoch [4/10] complete: Loss: 0.0737, Accuracy: 97.78%
Epoch [5/10] complete: Loss: 0.0633, Accuracy: 98.08%
Epoch [6/10] complete: Loss: 0.0498, Accuracy: 98.39%
Epoch [7/10] complete: Loss: 0.0430, Accuracy: 98.61%
Epoch [8/10] complete: Loss: 0.0357, Accuracy: 98.83%
Epoch [9/10] complete: Loss: 0.0331, Accuracy: 98.94%
Epoch [10/10] complete: Loss: 0.0283, Accuracy: 99.09%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.29%
High Forgetting Model Accuracy: 98.57%
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.3/pr0.4/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.46%
Pruned Low Forgetting Model Accuracy: 97.76%
Pruned High Forgetting Model Accuracy: 98.16%
Post-Pruning Retraining...
Initial Test Accuracy: 98.46%
Post-Pruning Training Epoch [1/10]: Loss: 0.0179, Train Acc: 99.44%, Test Acc: 98.97%
Post-Pruning Training Epoch [2/10]: Loss: 0.0130, Train Acc: 99.57%, Test Acc: 98.91%
Post-Pruning Training Epoch [3/10]: Loss: 0.0117, Train Acc: 99.61%, Test Acc: 98.99%
Post-Pruning Training Epoch [4/10]: Loss: 0.0111, Train Acc: 99.62%, Test Acc: 98.88%
Post-Pruning Training Epoch [5/10]: Loss: 0.0091, Train Acc: 99.71%, Test Acc: 99.13%
Post-Pruning Training Epoch [6/10]: Loss: 0.0098, Train Acc: 99.66%, Test Acc: 98.99%
Post-Pruning Training Epoch [7/10]: Loss: 0.0104, Train Acc: 99.62%, Test Acc: 99.12%
Post-Pruning Training Epoch [8/10]: Loss: 0.0068, Train Acc: 99.78%, Test Acc: 98.88%
Post-Pruning Training Epoch [9/10]: Loss: 0.0087, Train Acc: 99.70%, Test Acc: 98.77%
Post-Pruning Training Epoch [10/10]: Loss: 0.0081, Train Acc: 99.74%, Test Acc: 98.94%
Initial Test Accuracy: 97.76%
Post-Pruning Training Epoch [1/10]: Loss: 0.0526, Train Acc: 98.42%, Test Acc: 98.70%
Post-Pruning Training Epoch [2/10]: Loss: 0.0392, Train Acc: 98.76%, Test Acc: 98.49%
Post-Pruning Training Epoch [3/10]: Loss: 0.0321, Train Acc: 98.96%, Test Acc: 98.93%
Post-Pruning Training Epoch [4/10]: Loss: 0.0276, Train Acc: 99.14%, Test Acc: 98.67%
Post-Pruning Training Epoch [5/10]: Loss: 0.0217, Train Acc: 99.33%, Test Acc: 98.92%
Post-Pruning Training Epoch [6/10]: Loss: 0.0216, Train Acc: 99.26%, Test Acc: 98.97%
Post-Pruning Training Epoch [7/10]: Loss: 0.0169, Train Acc: 99.45%, Test Acc: 99.02%
Post-Pruning Training Epoch [8/10]: Loss: 0.0151, Train Acc: 99.47%, Test Acc: 98.89%
Post-Pruning Training Epoch [9/10]: Loss: 0.0148, Train Acc: 99.52%, Test Acc: 98.92%
Post-Pruning Training Epoch [10/10]: Loss: 0.0139, Train Acc: 99.53%, Test Acc: 98.75%
Initial Test Accuracy: 98.16%
Post-Pruning Training Epoch [1/10]: Loss: 0.0463, Train Acc: 98.58%, Test Acc: 98.77%
Post-Pruning Training Epoch [2/10]: Loss: 0.0334, Train Acc: 98.98%, Test Acc: 98.70%
Post-Pruning Training Epoch [3/10]: Loss: 0.0263, Train Acc: 99.17%, Test Acc: 98.89%
Post-Pruning Training Epoch [4/10]: Loss: 0.0208, Train Acc: 99.32%, Test Acc: 98.68%
Post-Pruning Training Epoch [5/10]: Loss: 0.0196, Train Acc: 99.36%, Test Acc: 99.09%
Post-Pruning Training Epoch [6/10]: Loss: 0.0164, Train Acc: 99.43%, Test Acc: 98.95%
Post-Pruning Training Epoch [7/10]: Loss: 0.0157, Train Acc: 99.51%, Test Acc: 98.87%
Post-Pruning Training Epoch [8/10]: Loss: 0.0125, Train Acc: 99.60%, Test Acc: 99.11%
Post-Pruning Training Epoch [9/10]: Loss: 0.0107, Train Acc: 99.66%, Test Acc: 99.04%
Post-Pruning Training Epoch [10/10]: Loss: 0.0110, Train Acc: 99.65%, Test Acc: 98.95%
Post-Pruned Baseline Model Accuracy: 98.94%
Post-Pruned Low Forgetting Model Accuracy: 98.75%
Post-Pruned High Forgetting Model Accuracy: 98.95%
Accuracy results saved to results/LeNet/MNIST/dr0.3/pr0.4/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.3/pr0.4/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 18000 highest-forgetting and top 18000 lowest-forgetting samples.
Highest forgetting subset size: 18000, Lowest forgetting subset size: 18000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.5439, Accuracy: 83.88%
Epoch [2/10] complete: Loss: 0.1345, Accuracy: 96.01%
Epoch [3/10] complete: Loss: 0.0856, Accuracy: 97.32%
Epoch [4/10] complete: Loss: 0.0651, Accuracy: 98.07%
Epoch [5/10] complete: Loss: 0.0511, Accuracy: 98.36%
Epoch [6/10] complete: Loss: 0.0413, Accuracy: 98.59%
Epoch [7/10] complete: Loss: 0.0325, Accuracy: 98.96%
Epoch [8/10] complete: Loss: 0.0278, Accuracy: 99.08%
Epoch [9/10] complete: Loss: 0.0237, Accuracy: 99.25%
Epoch [10/10] complete: Loss: 0.0203, Accuracy: 99.27%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.6195, Accuracy: 81.06%
Epoch [2/10] complete: Loss: 0.1504, Accuracy: 95.34%
Epoch [3/10] complete: Loss: 0.0994, Accuracy: 96.91%
Epoch [4/10] complete: Loss: 0.0756, Accuracy: 97.76%
Epoch [5/10] complete: Loss: 0.0666, Accuracy: 97.99%
Epoch [6/10] complete: Loss: 0.0528, Accuracy: 98.29%
Epoch [7/10] complete: Loss: 0.0441, Accuracy: 98.56%
Epoch [8/10] complete: Loss: 0.0380, Accuracy: 98.74%
Epoch [9/10] complete: Loss: 0.0327, Accuracy: 98.96%
Epoch [10/10] complete: Loss: 0.0288, Accuracy: 99.07%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.35%
High Forgetting Model Accuracy: 98.23%
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.3/pr0.6/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 93.18%
Pruned Low Forgetting Model Accuracy: 95.91%
Pruned High Forgetting Model Accuracy: 95.52%
Post-Pruning Retraining...
Initial Test Accuracy: 93.18%
Post-Pruning Training Epoch [1/10]: Loss: 0.0224, Train Acc: 99.27%, Test Acc: 99.04%
Post-Pruning Training Epoch [2/10]: Loss: 0.0148, Train Acc: 99.50%, Test Acc: 98.80%
Post-Pruning Training Epoch [3/10]: Loss: 0.0131, Train Acc: 99.57%, Test Acc: 99.03%
Post-Pruning Training Epoch [4/10]: Loss: 0.0120, Train Acc: 99.61%, Test Acc: 98.98%
Post-Pruning Training Epoch [5/10]: Loss: 0.0102, Train Acc: 99.66%, Test Acc: 98.94%
Post-Pruning Training Epoch [6/10]: Loss: 0.0097, Train Acc: 99.69%, Test Acc: 98.77%
Post-Pruning Training Epoch [7/10]: Loss: 0.0105, Train Acc: 99.63%, Test Acc: 98.79%
Post-Pruning Training Epoch [8/10]: Loss: 0.0085, Train Acc: 99.72%, Test Acc: 98.92%
Post-Pruning Training Epoch [9/10]: Loss: 0.0080, Train Acc: 99.75%, Test Acc: 98.80%
Post-Pruning Training Epoch [10/10]: Loss: 0.0077, Train Acc: 99.74%, Test Acc: 98.92%
Initial Test Accuracy: 95.91%
Post-Pruning Training Epoch [1/10]: Loss: 0.0561, Train Acc: 98.28%, Test Acc: 98.48%
Post-Pruning Training Epoch [2/10]: Loss: 0.0408, Train Acc: 98.70%, Test Acc: 98.49%
Post-Pruning Training Epoch [3/10]: Loss: 0.0334, Train Acc: 98.92%, Test Acc: 98.85%
Post-Pruning Training Epoch [4/10]: Loss: 0.0282, Train Acc: 99.12%, Test Acc: 98.59%
Post-Pruning Training Epoch [5/10]: Loss: 0.0225, Train Acc: 99.28%, Test Acc: 98.97%
Post-Pruning Training Epoch [6/10]: Loss: 0.0219, Train Acc: 99.27%, Test Acc: 98.73%
Post-Pruning Training Epoch [7/10]: Loss: 0.0178, Train Acc: 99.37%, Test Acc: 99.01%
Post-Pruning Training Epoch [8/10]: Loss: 0.0150, Train Acc: 99.48%, Test Acc: 98.72%
Post-Pruning Training Epoch [9/10]: Loss: 0.0145, Train Acc: 99.51%, Test Acc: 98.93%
Post-Pruning Training Epoch [10/10]: Loss: 0.0126, Train Acc: 99.58%, Test Acc: 98.75%
Initial Test Accuracy: 95.52%
Post-Pruning Training Epoch [1/10]: Loss: 0.0496, Train Acc: 98.45%, Test Acc: 98.86%
Post-Pruning Training Epoch [2/10]: Loss: 0.0350, Train Acc: 98.91%, Test Acc: 98.83%
Post-Pruning Training Epoch [3/10]: Loss: 0.0288, Train Acc: 99.09%, Test Acc: 98.88%
Post-Pruning Training Epoch [4/10]: Loss: 0.0223, Train Acc: 99.28%, Test Acc: 98.90%
Post-Pruning Training Epoch [5/10]: Loss: 0.0194, Train Acc: 99.37%, Test Acc: 98.90%
Post-Pruning Training Epoch [6/10]: Loss: 0.0167, Train Acc: 99.43%, Test Acc: 98.80%
Post-Pruning Training Epoch [7/10]: Loss: 0.0157, Train Acc: 99.51%, Test Acc: 99.09%
Post-Pruning Training Epoch [8/10]: Loss: 0.0123, Train Acc: 99.58%, Test Acc: 99.14%
Post-Pruning Training Epoch [9/10]: Loss: 0.0124, Train Acc: 99.60%, Test Acc: 99.05%
Post-Pruning Training Epoch [10/10]: Loss: 0.0116, Train Acc: 99.61%, Test Acc: 98.94%
Post-Pruned Baseline Model Accuracy: 98.92%
Post-Pruned Low Forgetting Model Accuracy: 98.75%
Post-Pruned High Forgetting Model Accuracy: 98.94%
Accuracy results saved to results/LeNet/MNIST/dr0.3/pr0.6/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.3/pr0.6/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 18000 highest-forgetting and top 18000 lowest-forgetting samples.
Highest forgetting subset size: 18000, Lowest forgetting subset size: 18000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.5437, Accuracy: 83.86%
Epoch [2/10] complete: Loss: 0.1345, Accuracy: 96.01%
Epoch [3/10] complete: Loss: 0.0859, Accuracy: 97.33%
Epoch [4/10] complete: Loss: 0.0656, Accuracy: 98.04%
Epoch [5/10] complete: Loss: 0.0505, Accuracy: 98.36%
Epoch [6/10] complete: Loss: 0.0409, Accuracy: 98.63%
Epoch [7/10] complete: Loss: 0.0324, Accuracy: 98.96%
Epoch [8/10] complete: Loss: 0.0283, Accuracy: 99.04%
Epoch [9/10] complete: Loss: 0.0233, Accuracy: 99.23%
Epoch [10/10] complete: Loss: 0.0171, Accuracy: 99.42%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.6198, Accuracy: 81.07%
Epoch [2/10] complete: Loss: 0.1510, Accuracy: 95.35%
Epoch [3/10] complete: Loss: 0.0988, Accuracy: 96.83%
Epoch [4/10] complete: Loss: 0.0743, Accuracy: 97.73%
Epoch [5/10] complete: Loss: 0.0653, Accuracy: 98.01%
Epoch [6/10] complete: Loss: 0.0506, Accuracy: 98.36%
Epoch [7/10] complete: Loss: 0.0447, Accuracy: 98.52%
Epoch [8/10] complete: Loss: 0.0353, Accuracy: 98.92%
Epoch [9/10] complete: Loss: 0.0321, Accuracy: 98.95%
Epoch [10/10] complete: Loss: 0.0283, Accuracy: 99.07%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.06%
High Forgetting Model Accuracy: 98.30%
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.3/pr0.8/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 43.24%
Pruned Low Forgetting Model Accuracy: 65.68%
Pruned High Forgetting Model Accuracy: 34.91%
Post-Pruning Retraining...
Initial Test Accuracy: 43.24%
Post-Pruning Training Epoch [1/10]: Loss: 0.0513, Train Acc: 98.50%, Test Acc: 99.13%
Post-Pruning Training Epoch [2/10]: Loss: 0.0218, Train Acc: 99.30%, Test Acc: 98.81%
Post-Pruning Training Epoch [3/10]: Loss: 0.0177, Train Acc: 99.38%, Test Acc: 99.06%
Post-Pruning Training Epoch [4/10]: Loss: 0.0149, Train Acc: 99.52%, Test Acc: 98.93%
Post-Pruning Training Epoch [5/10]: Loss: 0.0130, Train Acc: 99.55%, Test Acc: 99.06%
Post-Pruning Training Epoch [6/10]: Loss: 0.0126, Train Acc: 99.57%, Test Acc: 98.96%
Post-Pruning Training Epoch [7/10]: Loss: 0.0103, Train Acc: 99.67%, Test Acc: 98.94%
Post-Pruning Training Epoch [8/10]: Loss: 0.0121, Train Acc: 99.59%, Test Acc: 98.95%
Post-Pruning Training Epoch [9/10]: Loss: 0.0101, Train Acc: 99.64%, Test Acc: 99.10%
Post-Pruning Training Epoch [10/10]: Loss: 0.0087, Train Acc: 99.71%, Test Acc: 99.06%
Initial Test Accuracy: 65.68%
Post-Pruning Training Epoch [1/10]: Loss: 0.0733, Train Acc: 97.88%, Test Acc: 98.37%
Post-Pruning Training Epoch [2/10]: Loss: 0.0452, Train Acc: 98.61%, Test Acc: 98.45%
Post-Pruning Training Epoch [3/10]: Loss: 0.0373, Train Acc: 98.78%, Test Acc: 98.84%
Post-Pruning Training Epoch [4/10]: Loss: 0.0318, Train Acc: 99.03%, Test Acc: 98.81%
Post-Pruning Training Epoch [5/10]: Loss: 0.0254, Train Acc: 99.17%, Test Acc: 98.86%
Post-Pruning Training Epoch [6/10]: Loss: 0.0223, Train Acc: 99.25%, Test Acc: 98.76%
Post-Pruning Training Epoch [7/10]: Loss: 0.0187, Train Acc: 99.39%, Test Acc: 98.83%
Post-Pruning Training Epoch [8/10]: Loss: 0.0163, Train Acc: 99.46%, Test Acc: 98.90%
Post-Pruning Training Epoch [9/10]: Loss: 0.0174, Train Acc: 99.41%, Test Acc: 98.74%
Post-Pruning Training Epoch [10/10]: Loss: 0.0131, Train Acc: 99.54%, Test Acc: 98.88%
Initial Test Accuracy: 34.91%
Post-Pruning Training Epoch [1/10]: Loss: 0.0761, Train Acc: 97.84%, Test Acc: 98.78%
Post-Pruning Training Epoch [2/10]: Loss: 0.0399, Train Acc: 98.76%, Test Acc: 98.31%
Post-Pruning Training Epoch [3/10]: Loss: 0.0320, Train Acc: 98.97%, Test Acc: 98.94%
Post-Pruning Training Epoch [4/10]: Loss: 0.0253, Train Acc: 99.14%, Test Acc: 98.64%
Post-Pruning Training Epoch [5/10]: Loss: 0.0218, Train Acc: 99.30%, Test Acc: 98.99%
Post-Pruning Training Epoch [6/10]: Loss: 0.0189, Train Acc: 99.38%, Test Acc: 98.83%
Post-Pruning Training Epoch [7/10]: Loss: 0.0159, Train Acc: 99.47%, Test Acc: 98.97%
Post-Pruning Training Epoch [8/10]: Loss: 0.0135, Train Acc: 99.54%, Test Acc: 99.01%
Post-Pruning Training Epoch [9/10]: Loss: 0.0118, Train Acc: 99.63%, Test Acc: 99.05%
Post-Pruning Training Epoch [10/10]: Loss: 0.0128, Train Acc: 99.56%, Test Acc: 99.03%
Post-Pruned Baseline Model Accuracy: 99.06%
Post-Pruned Low Forgetting Model Accuracy: 98.88%
Post-Pruned High Forgetting Model Accuracy: 99.03%
Accuracy results saved to results/LeNet/MNIST/dr0.3/pr0.8/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.3/pr0.8/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 24000 highest-forgetting and top 24000 lowest-forgetting samples.
Highest forgetting subset size: 24000, Lowest forgetting subset size: 24000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4518, Accuracy: 86.07%
Epoch [2/10] complete: Loss: 0.1093, Accuracy: 96.77%
Epoch [3/10] complete: Loss: 0.0769, Accuracy: 97.67%
Epoch [4/10] complete: Loss: 0.0582, Accuracy: 98.16%
Epoch [5/10] complete: Loss: 0.0457, Accuracy: 98.50%
Epoch [6/10] complete: Loss: 0.0360, Accuracy: 98.85%
Epoch [7/10] complete: Loss: 0.0304, Accuracy: 98.98%
Epoch [8/10] complete: Loss: 0.0252, Accuracy: 99.18%
Epoch [9/10] complete: Loss: 0.0189, Accuracy: 99.38%
Epoch [10/10] complete: Loss: 0.0180, Accuracy: 99.40%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4946, Accuracy: 84.74%
Epoch [2/10] complete: Loss: 0.1270, Accuracy: 96.14%
Epoch [3/10] complete: Loss: 0.0847, Accuracy: 97.25%
Epoch [4/10] complete: Loss: 0.0645, Accuracy: 97.85%
Epoch [5/10] complete: Loss: 0.0518, Accuracy: 98.42%
Epoch [6/10] complete: Loss: 0.0440, Accuracy: 98.57%
Epoch [7/10] complete: Loss: 0.0378, Accuracy: 98.81%
Epoch [8/10] complete: Loss: 0.0322, Accuracy: 98.99%
Epoch [9/10] complete: Loss: 0.0267, Accuracy: 99.10%
Epoch [10/10] complete: Loss: 0.0211, Accuracy: 99.31%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.21%
High Forgetting Model Accuracy: 98.54%
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.4/pr0.0/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.92%
Pruned Low Forgetting Model Accuracy: 98.21%
Pruned High Forgetting Model Accuracy: 98.54%
Post-Pruning Retraining...
Initial Test Accuracy: 98.92%
Post-Pruning Training Epoch [1/10]: Loss: 0.0166, Train Acc: 99.47%, Test Acc: 99.00%
Post-Pruning Training Epoch [2/10]: Loss: 0.0136, Train Acc: 99.56%, Test Acc: 99.04%
Post-Pruning Training Epoch [3/10]: Loss: 0.0107, Train Acc: 99.65%, Test Acc: 98.87%
Post-Pruning Training Epoch [4/10]: Loss: 0.0110, Train Acc: 99.63%, Test Acc: 98.97%
Post-Pruning Training Epoch [5/10]: Loss: 0.0112, Train Acc: 99.63%, Test Acc: 99.03%
Post-Pruning Training Epoch [6/10]: Loss: 0.0090, Train Acc: 99.70%, Test Acc: 98.95%
Post-Pruning Training Epoch [7/10]: Loss: 0.0084, Train Acc: 99.71%, Test Acc: 99.06%
Post-Pruning Training Epoch [8/10]: Loss: 0.0078, Train Acc: 99.73%, Test Acc: 98.72%
Post-Pruning Training Epoch [9/10]: Loss: 0.0070, Train Acc: 99.76%, Test Acc: 98.81%
Post-Pruning Training Epoch [10/10]: Loss: 0.0082, Train Acc: 99.74%, Test Acc: 99.17%
Initial Test Accuracy: 98.21%
Post-Pruning Training Epoch [1/10]: Loss: 0.0442, Train Acc: 98.70%, Test Acc: 98.77%
Post-Pruning Training Epoch [2/10]: Loss: 0.0347, Train Acc: 98.86%, Test Acc: 98.55%
Post-Pruning Training Epoch [3/10]: Loss: 0.0273, Train Acc: 99.13%, Test Acc: 98.91%
Post-Pruning Training Epoch [4/10]: Loss: 0.0235, Train Acc: 99.23%, Test Acc: 98.84%
Post-Pruning Training Epoch [5/10]: Loss: 0.0191, Train Acc: 99.36%, Test Acc: 98.96%
Post-Pruning Training Epoch [6/10]: Loss: 0.0188, Train Acc: 99.36%, Test Acc: 98.81%
Post-Pruning Training Epoch [7/10]: Loss: 0.0145, Train Acc: 99.53%, Test Acc: 98.84%
Post-Pruning Training Epoch [8/10]: Loss: 0.0123, Train Acc: 99.57%, Test Acc: 98.78%
Post-Pruning Training Epoch [9/10]: Loss: 0.0136, Train Acc: 99.56%, Test Acc: 98.79%
Post-Pruning Training Epoch [10/10]: Loss: 0.0111, Train Acc: 99.64%, Test Acc: 98.97%
Initial Test Accuracy: 98.54%
Post-Pruning Training Epoch [1/10]: Loss: 0.0410, Train Acc: 98.75%, Test Acc: 98.88%
Post-Pruning Training Epoch [2/10]: Loss: 0.0291, Train Acc: 99.06%, Test Acc: 98.63%
Post-Pruning Training Epoch [3/10]: Loss: 0.0240, Train Acc: 99.27%, Test Acc: 98.91%
Post-Pruning Training Epoch [4/10]: Loss: 0.0189, Train Acc: 99.38%, Test Acc: 98.85%
Post-Pruning Training Epoch [5/10]: Loss: 0.0181, Train Acc: 99.39%, Test Acc: 98.94%
Post-Pruning Training Epoch [6/10]: Loss: 0.0154, Train Acc: 99.49%, Test Acc: 98.96%
Post-Pruning Training Epoch [7/10]: Loss: 0.0134, Train Acc: 99.55%, Test Acc: 99.01%
Post-Pruning Training Epoch [8/10]: Loss: 0.0121, Train Acc: 99.61%, Test Acc: 98.94%
Post-Pruning Training Epoch [9/10]: Loss: 0.0114, Train Acc: 99.63%, Test Acc: 99.08%
Post-Pruning Training Epoch [10/10]: Loss: 0.0098, Train Acc: 99.64%, Test Acc: 99.05%
Post-Pruned Baseline Model Accuracy: 99.17%
Post-Pruned Low Forgetting Model Accuracy: 98.97%
Post-Pruned High Forgetting Model Accuracy: 99.05%
Accuracy results saved to results/LeNet/MNIST/dr0.4/pr0.0/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.4/pr0.0/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 24000 highest-forgetting and top 24000 lowest-forgetting samples.
Highest forgetting subset size: 24000, Lowest forgetting subset size: 24000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4532, Accuracy: 86.02%
Epoch [2/10] complete: Loss: 0.1110, Accuracy: 96.68%
Epoch [3/10] complete: Loss: 0.0775, Accuracy: 97.61%
Epoch [4/10] complete: Loss: 0.0595, Accuracy: 98.08%
Epoch [5/10] complete: Loss: 0.0454, Accuracy: 98.63%
Epoch [6/10] complete: Loss: 0.0370, Accuracy: 98.83%
Epoch [7/10] complete: Loss: 0.0298, Accuracy: 99.01%
Epoch [8/10] complete: Loss: 0.0253, Accuracy: 99.17%
Epoch [9/10] complete: Loss: 0.0213, Accuracy: 99.25%
Epoch [10/10] complete: Loss: 0.0164, Accuracy: 99.46%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4944, Accuracy: 84.76%
Epoch [2/10] complete: Loss: 0.1283, Accuracy: 96.05%
Epoch [3/10] complete: Loss: 0.0852, Accuracy: 97.25%
Epoch [4/10] complete: Loss: 0.0648, Accuracy: 97.95%
Epoch [5/10] complete: Loss: 0.0532, Accuracy: 98.29%
Epoch [6/10] complete: Loss: 0.0449, Accuracy: 98.51%
Epoch [7/10] complete: Loss: 0.0388, Accuracy: 98.78%
Epoch [8/10] complete: Loss: 0.0320, Accuracy: 98.99%
Epoch [9/10] complete: Loss: 0.0263, Accuracy: 99.10%
Epoch [10/10] complete: Loss: 0.0205, Accuracy: 99.32%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.23%
High Forgetting Model Accuracy: 98.60%
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.4/pr0.2/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.91%
Pruned Low Forgetting Model Accuracy: 98.11%
Pruned High Forgetting Model Accuracy: 98.54%
Post-Pruning Retraining...
Initial Test Accuracy: 98.91%
Post-Pruning Training Epoch [1/10]: Loss: 0.0167, Train Acc: 99.45%, Test Acc: 99.03%
Post-Pruning Training Epoch [2/10]: Loss: 0.0138, Train Acc: 99.54%, Test Acc: 99.03%
Post-Pruning Training Epoch [3/10]: Loss: 0.0112, Train Acc: 99.62%, Test Acc: 98.90%
Post-Pruning Training Epoch [4/10]: Loss: 0.0107, Train Acc: 99.60%, Test Acc: 98.99%
Post-Pruning Training Epoch [5/10]: Loss: 0.0079, Train Acc: 99.75%, Test Acc: 98.75%
Post-Pruning Training Epoch [6/10]: Loss: 0.0106, Train Acc: 99.63%, Test Acc: 98.65%
Post-Pruning Training Epoch [7/10]: Loss: 0.0094, Train Acc: 99.68%, Test Acc: 98.95%
Post-Pruning Training Epoch [8/10]: Loss: 0.0084, Train Acc: 99.73%, Test Acc: 98.42%
Post-Pruning Training Epoch [9/10]: Loss: 0.0079, Train Acc: 99.75%, Test Acc: 98.74%
Post-Pruning Training Epoch [10/10]: Loss: 0.0078, Train Acc: 99.75%, Test Acc: 98.88%
Initial Test Accuracy: 98.11%
Post-Pruning Training Epoch [1/10]: Loss: 0.0446, Train Acc: 98.66%, Test Acc: 98.62%
Post-Pruning Training Epoch [2/10]: Loss: 0.0344, Train Acc: 98.90%, Test Acc: 98.47%
Post-Pruning Training Epoch [3/10]: Loss: 0.0274, Train Acc: 99.13%, Test Acc: 98.88%
Post-Pruning Training Epoch [4/10]: Loss: 0.0232, Train Acc: 99.22%, Test Acc: 98.69%
Post-Pruning Training Epoch [5/10]: Loss: 0.0199, Train Acc: 99.37%, Test Acc: 98.99%
Post-Pruning Training Epoch [6/10]: Loss: 0.0192, Train Acc: 99.40%, Test Acc: 99.00%
Post-Pruning Training Epoch [7/10]: Loss: 0.0158, Train Acc: 99.47%, Test Acc: 99.07%
Post-Pruning Training Epoch [8/10]: Loss: 0.0144, Train Acc: 99.51%, Test Acc: 98.97%
Post-Pruning Training Epoch [9/10]: Loss: 0.0139, Train Acc: 99.56%, Test Acc: 98.58%
Post-Pruning Training Epoch [10/10]: Loss: 0.0124, Train Acc: 99.58%, Test Acc: 98.75%
Initial Test Accuracy: 98.54%
Post-Pruning Training Epoch [1/10]: Loss: 0.0411, Train Acc: 98.78%, Test Acc: 98.91%
Post-Pruning Training Epoch [2/10]: Loss: 0.0298, Train Acc: 99.04%, Test Acc: 98.79%
Post-Pruning Training Epoch [3/10]: Loss: 0.0249, Train Acc: 99.21%, Test Acc: 98.97%
Post-Pruning Training Epoch [4/10]: Loss: 0.0191, Train Acc: 99.34%, Test Acc: 98.81%
Post-Pruning Training Epoch [5/10]: Loss: 0.0182, Train Acc: 99.43%, Test Acc: 98.78%
Post-Pruning Training Epoch [6/10]: Loss: 0.0166, Train Acc: 99.44%, Test Acc: 98.94%
Post-Pruning Training Epoch [7/10]: Loss: 0.0133, Train Acc: 99.55%, Test Acc: 98.87%
Post-Pruning Training Epoch [8/10]: Loss: 0.0112, Train Acc: 99.60%, Test Acc: 98.77%
Post-Pruning Training Epoch [9/10]: Loss: 0.0110, Train Acc: 99.64%, Test Acc: 98.98%
Post-Pruning Training Epoch [10/10]: Loss: 0.0093, Train Acc: 99.68%, Test Acc: 98.89%
Post-Pruned Baseline Model Accuracy: 98.88%
Post-Pruned Low Forgetting Model Accuracy: 98.75%
Post-Pruned High Forgetting Model Accuracy: 98.89%
Accuracy results saved to results/LeNet/MNIST/dr0.4/pr0.2/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.4/pr0.2/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 24000 highest-forgetting and top 24000 lowest-forgetting samples.
Highest forgetting subset size: 24000, Lowest forgetting subset size: 24000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4525, Accuracy: 85.99%
Epoch [2/10] complete: Loss: 0.1097, Accuracy: 96.80%
Epoch [3/10] complete: Loss: 0.0772, Accuracy: 97.65%
Epoch [4/10] complete: Loss: 0.0588, Accuracy: 98.12%
Epoch [5/10] complete: Loss: 0.0445, Accuracy: 98.61%
Epoch [6/10] complete: Loss: 0.0366, Accuracy: 98.80%
Epoch [7/10] complete: Loss: 0.0292, Accuracy: 99.08%
Epoch [8/10] complete: Loss: 0.0256, Accuracy: 99.13%
Epoch [9/10] complete: Loss: 0.0199, Accuracy: 99.36%
Epoch [10/10] complete: Loss: 0.0173, Accuracy: 99.39%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4937, Accuracy: 84.80%
Epoch [2/10] complete: Loss: 0.1263, Accuracy: 96.15%
Epoch [3/10] complete: Loss: 0.0841, Accuracy: 97.34%
Epoch [4/10] complete: Loss: 0.0628, Accuracy: 98.03%
Epoch [5/10] complete: Loss: 0.0516, Accuracy: 98.35%
Epoch [6/10] complete: Loss: 0.0427, Accuracy: 98.60%
Epoch [7/10] complete: Loss: 0.0358, Accuracy: 98.88%
Epoch [8/10] complete: Loss: 0.0311, Accuracy: 98.99%
Epoch [9/10] complete: Loss: 0.0253, Accuracy: 99.17%
Epoch [10/10] complete: Loss: 0.0188, Accuracy: 99.34%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.29%
High Forgetting Model Accuracy: 98.69%
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.4/pr0.4/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.46%
Pruned Low Forgetting Model Accuracy: 98.12%
Pruned High Forgetting Model Accuracy: 98.31%
Post-Pruning Retraining...
Initial Test Accuracy: 98.46%
Post-Pruning Training Epoch [1/10]: Loss: 0.0175, Train Acc: 99.45%, Test Acc: 99.09%
Post-Pruning Training Epoch [2/10]: Loss: 0.0131, Train Acc: 99.55%, Test Acc: 98.84%
Post-Pruning Training Epoch [3/10]: Loss: 0.0116, Train Acc: 99.60%, Test Acc: 98.88%
Post-Pruning Training Epoch [4/10]: Loss: 0.0117, Train Acc: 99.59%, Test Acc: 99.05%
Post-Pruning Training Epoch [5/10]: Loss: 0.0102, Train Acc: 99.67%, Test Acc: 98.89%
Post-Pruning Training Epoch [6/10]: Loss: 0.0094, Train Acc: 99.68%, Test Acc: 99.05%
Post-Pruning Training Epoch [7/10]: Loss: 0.0087, Train Acc: 99.69%, Test Acc: 98.90%
Post-Pruning Training Epoch [8/10]: Loss: 0.0081, Train Acc: 99.76%, Test Acc: 98.82%
Post-Pruning Training Epoch [9/10]: Loss: 0.0085, Train Acc: 99.70%, Test Acc: 98.61%
Post-Pruning Training Epoch [10/10]: Loss: 0.0076, Train Acc: 99.74%, Test Acc: 98.88%
Initial Test Accuracy: 98.12%
Post-Pruning Training Epoch [1/10]: Loss: 0.0455, Train Acc: 98.60%, Test Acc: 98.77%
Post-Pruning Training Epoch [2/10]: Loss: 0.0348, Train Acc: 98.90%, Test Acc: 98.68%
Post-Pruning Training Epoch [3/10]: Loss: 0.0274, Train Acc: 99.14%, Test Acc: 98.84%
Post-Pruning Training Epoch [4/10]: Loss: 0.0233, Train Acc: 99.24%, Test Acc: 98.77%
Post-Pruning Training Epoch [5/10]: Loss: 0.0205, Train Acc: 99.33%, Test Acc: 98.95%
Post-Pruning Training Epoch [6/10]: Loss: 0.0193, Train Acc: 99.35%, Test Acc: 98.92%
Post-Pruning Training Epoch [7/10]: Loss: 0.0157, Train Acc: 99.48%, Test Acc: 98.91%
Post-Pruning Training Epoch [8/10]: Loss: 0.0134, Train Acc: 99.58%, Test Acc: 99.04%
Post-Pruning Training Epoch [9/10]: Loss: 0.0139, Train Acc: 99.54%, Test Acc: 98.73%
Post-Pruning Training Epoch [10/10]: Loss: 0.0122, Train Acc: 99.61%, Test Acc: 98.88%
Initial Test Accuracy: 98.31%
Post-Pruning Training Epoch [1/10]: Loss: 0.0418, Train Acc: 98.75%, Test Acc: 98.92%
Post-Pruning Training Epoch [2/10]: Loss: 0.0301, Train Acc: 99.09%, Test Acc: 98.75%
Post-Pruning Training Epoch [3/10]: Loss: 0.0252, Train Acc: 99.21%, Test Acc: 99.12%
Post-Pruning Training Epoch [4/10]: Loss: 0.0203, Train Acc: 99.33%, Test Acc: 98.88%
Post-Pruning Training Epoch [5/10]: Loss: 0.0190, Train Acc: 99.38%, Test Acc: 98.91%
Post-Pruning Training Epoch [6/10]: Loss: 0.0166, Train Acc: 99.47%, Test Acc: 98.89%
Post-Pruning Training Epoch [7/10]: Loss: 0.0134, Train Acc: 99.56%, Test Acc: 98.92%
Post-Pruning Training Epoch [8/10]: Loss: 0.0114, Train Acc: 99.62%, Test Acc: 98.89%
Post-Pruning Training Epoch [9/10]: Loss: 0.0108, Train Acc: 99.64%, Test Acc: 98.94%
Post-Pruning Training Epoch [10/10]: Loss: 0.0107, Train Acc: 99.64%, Test Acc: 98.56%
Post-Pruned Baseline Model Accuracy: 98.88%
Post-Pruned Low Forgetting Model Accuracy: 98.88%
Post-Pruned High Forgetting Model Accuracy: 98.56%
Accuracy results saved to results/LeNet/MNIST/dr0.4/pr0.4/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.4/pr0.4/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 24000 highest-forgetting and top 24000 lowest-forgetting samples.
Highest forgetting subset size: 24000, Lowest forgetting subset size: 24000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4533, Accuracy: 85.97%
Epoch [2/10] complete: Loss: 0.1102, Accuracy: 96.77%
Epoch [3/10] complete: Loss: 0.0774, Accuracy: 97.61%
Epoch [4/10] complete: Loss: 0.0594, Accuracy: 98.12%
Epoch [5/10] complete: Loss: 0.0459, Accuracy: 98.62%
Epoch [6/10] complete: Loss: 0.0367, Accuracy: 98.83%
Epoch [7/10] complete: Loss: 0.0308, Accuracy: 98.99%
Epoch [8/10] complete: Loss: 0.0261, Accuracy: 99.15%
Epoch [9/10] complete: Loss: 0.0199, Accuracy: 99.35%
Epoch [10/10] complete: Loss: 0.0180, Accuracy: 99.39%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4933, Accuracy: 84.80%
Epoch [2/10] complete: Loss: 0.1278, Accuracy: 96.08%
Epoch [3/10] complete: Loss: 0.0841, Accuracy: 97.33%
Epoch [4/10] complete: Loss: 0.0642, Accuracy: 97.97%
Epoch [5/10] complete: Loss: 0.0522, Accuracy: 98.34%
Epoch [6/10] complete: Loss: 0.0431, Accuracy: 98.61%
Epoch [7/10] complete: Loss: 0.0368, Accuracy: 98.85%
Epoch [8/10] complete: Loss: 0.0318, Accuracy: 99.00%
Epoch [9/10] complete: Loss: 0.0254, Accuracy: 99.14%
Epoch [10/10] complete: Loss: 0.0225, Accuracy: 99.25%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.33%
High Forgetting Model Accuracy: 98.78%
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.4/pr0.6/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 93.18%
Pruned Low Forgetting Model Accuracy: 96.86%
Pruned High Forgetting Model Accuracy: 96.78%
Post-Pruning Retraining...
Initial Test Accuracy: 93.18%
Post-Pruning Training Epoch [1/10]: Loss: 0.0223, Train Acc: 99.27%, Test Acc: 98.90%
Post-Pruning Training Epoch [2/10]: Loss: 0.0154, Train Acc: 99.47%, Test Acc: 98.83%
Post-Pruning Training Epoch [3/10]: Loss: 0.0126, Train Acc: 99.58%, Test Acc: 98.76%
Post-Pruning Training Epoch [4/10]: Loss: 0.0123, Train Acc: 99.57%, Test Acc: 99.02%
Post-Pruning Training Epoch [5/10]: Loss: 0.0104, Train Acc: 99.65%, Test Acc: 98.83%
Post-Pruning Training Epoch [6/10]: Loss: 0.0090, Train Acc: 99.70%, Test Acc: 98.87%
Post-Pruning Training Epoch [7/10]: Loss: 0.0105, Train Acc: 99.63%, Test Acc: 98.94%
Post-Pruning Training Epoch [8/10]: Loss: 0.0073, Train Acc: 99.72%, Test Acc: 98.76%
Post-Pruning Training Epoch [9/10]: Loss: 0.0084, Train Acc: 99.72%, Test Acc: 98.37%
Post-Pruning Training Epoch [10/10]: Loss: 0.0080, Train Acc: 99.75%, Test Acc: 98.72%
Initial Test Accuracy: 96.86%
Post-Pruning Training Epoch [1/10]: Loss: 0.0466, Train Acc: 98.57%, Test Acc: 98.72%
Post-Pruning Training Epoch [2/10]: Loss: 0.0358, Train Acc: 98.85%, Test Acc: 98.52%
Post-Pruning Training Epoch [3/10]: Loss: 0.0278, Train Acc: 99.14%, Test Acc: 98.74%
Post-Pruning Training Epoch [4/10]: Loss: 0.0237, Train Acc: 99.25%, Test Acc: 99.07%
Post-Pruning Training Epoch [5/10]: Loss: 0.0203, Train Acc: 99.34%, Test Acc: 98.86%
Post-Pruning Training Epoch [6/10]: Loss: 0.0181, Train Acc: 99.40%, Test Acc: 98.89%
Post-Pruning Training Epoch [7/10]: Loss: 0.0159, Train Acc: 99.48%, Test Acc: 98.83%
Post-Pruning Training Epoch [8/10]: Loss: 0.0133, Train Acc: 99.54%, Test Acc: 98.74%
Post-Pruning Training Epoch [9/10]: Loss: 0.0139, Train Acc: 99.57%, Test Acc: 98.91%
Post-Pruning Training Epoch [10/10]: Loss: 0.0097, Train Acc: 99.67%, Test Acc: 98.84%
Initial Test Accuracy: 96.78%
Post-Pruning Training Epoch [1/10]: Loss: 0.0431, Train Acc: 98.70%, Test Acc: 98.87%
Post-Pruning Training Epoch [2/10]: Loss: 0.0318, Train Acc: 99.03%, Test Acc: 98.38%
Post-Pruning Training Epoch [3/10]: Loss: 0.0252, Train Acc: 99.19%, Test Acc: 98.81%
Post-Pruning Training Epoch [4/10]: Loss: 0.0212, Train Acc: 99.31%, Test Acc: 98.81%
Post-Pruning Training Epoch [5/10]: Loss: 0.0189, Train Acc: 99.37%, Test Acc: 98.92%
Post-Pruning Training Epoch [6/10]: Loss: 0.0161, Train Acc: 99.47%, Test Acc: 98.76%
Post-Pruning Training Epoch [7/10]: Loss: 0.0144, Train Acc: 99.56%, Test Acc: 98.96%
Post-Pruning Training Epoch [8/10]: Loss: 0.0118, Train Acc: 99.59%, Test Acc: 98.89%
Post-Pruning Training Epoch [9/10]: Loss: 0.0128, Train Acc: 99.57%, Test Acc: 98.80%
Post-Pruning Training Epoch [10/10]: Loss: 0.0120, Train Acc: 99.60%, Test Acc: 98.88%
Post-Pruned Baseline Model Accuracy: 98.72%
Post-Pruned Low Forgetting Model Accuracy: 98.84%
Post-Pruned High Forgetting Model Accuracy: 98.88%
Accuracy results saved to results/LeNet/MNIST/dr0.4/pr0.6/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.4/pr0.6/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 24000 highest-forgetting and top 24000 lowest-forgetting samples.
Highest forgetting subset size: 24000, Lowest forgetting subset size: 24000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4507, Accuracy: 86.02%
Epoch [2/10] complete: Loss: 0.1090, Accuracy: 96.72%
Epoch [3/10] complete: Loss: 0.0762, Accuracy: 97.70%
Epoch [4/10] complete: Loss: 0.0593, Accuracy: 98.15%
Epoch [5/10] complete: Loss: 0.0451, Accuracy: 98.57%
Epoch [6/10] complete: Loss: 0.0360, Accuracy: 98.86%
Epoch [7/10] complete: Loss: 0.0308, Accuracy: 99.01%
Epoch [8/10] complete: Loss: 0.0253, Accuracy: 99.24%
Epoch [9/10] complete: Loss: 0.0196, Accuracy: 99.40%
Epoch [10/10] complete: Loss: 0.0168, Accuracy: 99.45%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4947, Accuracy: 84.72%
Epoch [2/10] complete: Loss: 0.1279, Accuracy: 96.08%
Epoch [3/10] complete: Loss: 0.0851, Accuracy: 97.22%
Epoch [4/10] complete: Loss: 0.0638, Accuracy: 97.95%
Epoch [5/10] complete: Loss: 0.0528, Accuracy: 98.33%
Epoch [6/10] complete: Loss: 0.0437, Accuracy: 98.58%
Epoch [7/10] complete: Loss: 0.0362, Accuracy: 98.92%
Epoch [8/10] complete: Loss: 0.0318, Accuracy: 98.97%
Epoch [9/10] complete: Loss: 0.0258, Accuracy: 99.10%
Epoch [10/10] complete: Loss: 0.0191, Accuracy: 99.35%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.14%
High Forgetting Model Accuracy: 98.76%
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.4/pr0.8/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 43.24%
Pruned Low Forgetting Model Accuracy: 75.89%
Pruned High Forgetting Model Accuracy: 43.18%
Post-Pruning Retraining...
Initial Test Accuracy: 43.24%
Post-Pruning Training Epoch [1/10]: Loss: 0.0512, Train Acc: 98.52%, Test Acc: 99.00%
Post-Pruning Training Epoch [2/10]: Loss: 0.0214, Train Acc: 99.31%, Test Acc: 98.92%
Post-Pruning Training Epoch [3/10]: Loss: 0.0181, Train Acc: 99.42%, Test Acc: 99.01%
Post-Pruning Training Epoch [4/10]: Loss: 0.0156, Train Acc: 99.47%, Test Acc: 99.01%
Post-Pruning Training Epoch [5/10]: Loss: 0.0132, Train Acc: 99.55%, Test Acc: 98.81%
Post-Pruning Training Epoch [6/10]: Loss: 0.0115, Train Acc: 99.61%, Test Acc: 98.94%
Post-Pruning Training Epoch [7/10]: Loss: 0.0115, Train Acc: 99.61%, Test Acc: 99.13%
Post-Pruning Training Epoch [8/10]: Loss: 0.0099, Train Acc: 99.68%, Test Acc: 98.89%
Post-Pruning Training Epoch [9/10]: Loss: 0.0103, Train Acc: 99.66%, Test Acc: 98.89%
Post-Pruning Training Epoch [10/10]: Loss: 0.0072, Train Acc: 99.77%, Test Acc: 98.91%
Initial Test Accuracy: 75.89%
Post-Pruning Training Epoch [1/10]: Loss: 0.0631, Train Acc: 98.15%, Test Acc: 98.42%
Post-Pruning Training Epoch [2/10]: Loss: 0.0417, Train Acc: 98.68%, Test Acc: 98.37%
Post-Pruning Training Epoch [3/10]: Loss: 0.0327, Train Acc: 98.97%, Test Acc: 98.96%
Post-Pruning Training Epoch [4/10]: Loss: 0.0272, Train Acc: 99.16%, Test Acc: 98.92%
Post-Pruning Training Epoch [5/10]: Loss: 0.0224, Train Acc: 99.27%, Test Acc: 98.98%
Post-Pruning Training Epoch [6/10]: Loss: 0.0205, Train Acc: 99.29%, Test Acc: 98.99%
Post-Pruning Training Epoch [7/10]: Loss: 0.0182, Train Acc: 99.38%, Test Acc: 98.82%
Post-Pruning Training Epoch [8/10]: Loss: 0.0150, Train Acc: 99.50%, Test Acc: 98.62%
Post-Pruning Training Epoch [9/10]: Loss: 0.0145, Train Acc: 99.52%, Test Acc: 98.93%
Post-Pruning Training Epoch [10/10]: Loss: 0.0124, Train Acc: 99.58%, Test Acc: 98.79%
Initial Test Accuracy: 43.18%
Post-Pruning Training Epoch [1/10]: Loss: 0.0695, Train Acc: 98.01%, Test Acc: 98.93%
Post-Pruning Training Epoch [2/10]: Loss: 0.0358, Train Acc: 98.87%, Test Acc: 98.29%
Post-Pruning Training Epoch [3/10]: Loss: 0.0291, Train Acc: 99.07%, Test Acc: 98.98%
Post-Pruning Training Epoch [4/10]: Loss: 0.0232, Train Acc: 99.22%, Test Acc: 98.71%
Post-Pruning Training Epoch [5/10]: Loss: 0.0201, Train Acc: 99.36%, Test Acc: 98.97%
Post-Pruning Training Epoch [6/10]: Loss: 0.0171, Train Acc: 99.43%, Test Acc: 99.03%
Post-Pruning Training Epoch [7/10]: Loss: 0.0164, Train Acc: 99.47%, Test Acc: 99.13%
Post-Pruning Training Epoch [8/10]: Loss: 0.0120, Train Acc: 99.59%, Test Acc: 99.15%
Post-Pruning Training Epoch [9/10]: Loss: 0.0147, Train Acc: 99.51%, Test Acc: 98.90%
Post-Pruning Training Epoch [10/10]: Loss: 0.0107, Train Acc: 99.63%, Test Acc: 98.87%
Post-Pruned Baseline Model Accuracy: 98.91%
Post-Pruned Low Forgetting Model Accuracy: 98.79%
Post-Pruned High Forgetting Model Accuracy: 98.87%
Accuracy results saved to results/LeNet/MNIST/dr0.4/pr0.8/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.4/pr0.8/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 30000 highest-forgetting and top 30000 lowest-forgetting samples.
Highest forgetting subset size: 30000, Lowest forgetting subset size: 30000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.3783, Accuracy: 88.80%
Epoch [2/10] complete: Loss: 0.0952, Accuracy: 97.02%
Epoch [3/10] complete: Loss: 0.0644, Accuracy: 97.98%
Epoch [4/10] complete: Loss: 0.0497, Accuracy: 98.35%
Epoch [5/10] complete: Loss: 0.0390, Accuracy: 98.74%
Epoch [6/10] complete: Loss: 0.0351, Accuracy: 98.84%
Epoch [7/10] complete: Loss: 0.0287, Accuracy: 99.12%
Epoch [8/10] complete: Loss: 0.0217, Accuracy: 99.25%
Epoch [9/10] complete: Loss: 0.0226, Accuracy: 99.26%
Epoch [10/10] complete: Loss: 0.0156, Accuracy: 99.48%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4188, Accuracy: 86.94%
Epoch [2/10] complete: Loss: 0.1098, Accuracy: 96.60%
Epoch [3/10] complete: Loss: 0.0767, Accuracy: 97.69%
Epoch [4/10] complete: Loss: 0.0616, Accuracy: 98.06%
Epoch [5/10] complete: Loss: 0.0468, Accuracy: 98.50%
Epoch [6/10] complete: Loss: 0.0395, Accuracy: 98.77%
Epoch [7/10] complete: Loss: 0.0328, Accuracy: 98.89%
Epoch [8/10] complete: Loss: 0.0278, Accuracy: 99.04%
Epoch [9/10] complete: Loss: 0.0269, Accuracy: 99.07%
Epoch [10/10] complete: Loss: 0.0212, Accuracy: 99.28%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.47%
High Forgetting Model Accuracy: 98.77%
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.5/pr0.0/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.92%
Pruned Low Forgetting Model Accuracy: 98.47%
Pruned High Forgetting Model Accuracy: 98.77%
Post-Pruning Retraining...
Initial Test Accuracy: 98.92%
Post-Pruning Training Epoch [1/10]: Loss: 0.0164, Train Acc: 99.47%, Test Acc: 98.98%
Post-Pruning Training Epoch [2/10]: Loss: 0.0133, Train Acc: 99.57%, Test Acc: 98.91%
Post-Pruning Training Epoch [3/10]: Loss: 0.0113, Train Acc: 99.60%, Test Acc: 99.05%
Post-Pruning Training Epoch [4/10]: Loss: 0.0105, Train Acc: 99.64%, Test Acc: 99.07%
Post-Pruning Training Epoch [5/10]: Loss: 0.0096, Train Acc: 99.71%, Test Acc: 98.93%
Post-Pruning Training Epoch [6/10]: Loss: 0.0103, Train Acc: 99.64%, Test Acc: 98.83%
Post-Pruning Training Epoch [7/10]: Loss: 0.0084, Train Acc: 99.72%, Test Acc: 98.80%
Post-Pruning Training Epoch [8/10]: Loss: 0.0076, Train Acc: 99.74%, Test Acc: 98.62%
Post-Pruning Training Epoch [9/10]: Loss: 0.0075, Train Acc: 99.74%, Test Acc: 99.03%
Post-Pruning Training Epoch [10/10]: Loss: 0.0081, Train Acc: 99.73%, Test Acc: 98.88%
Initial Test Accuracy: 98.47%
Post-Pruning Training Epoch [1/10]: Loss: 0.0389, Train Acc: 98.80%, Test Acc: 98.82%
Post-Pruning Training Epoch [2/10]: Loss: 0.0286, Train Acc: 99.09%, Test Acc: 98.93%
Post-Pruning Training Epoch [3/10]: Loss: 0.0246, Train Acc: 99.22%, Test Acc: 98.88%
Post-Pruning Training Epoch [4/10]: Loss: 0.0207, Train Acc: 99.36%, Test Acc: 98.81%
Post-Pruning Training Epoch [5/10]: Loss: 0.0166, Train Acc: 99.44%, Test Acc: 98.86%
Post-Pruning Training Epoch [6/10]: Loss: 0.0163, Train Acc: 99.45%, Test Acc: 99.00%
Post-Pruning Training Epoch [7/10]: Loss: 0.0140, Train Acc: 99.53%, Test Acc: 98.85%
Post-Pruning Training Epoch [8/10]: Loss: 0.0115, Train Acc: 99.62%, Test Acc: 98.97%
Post-Pruning Training Epoch [9/10]: Loss: 0.0122, Train Acc: 99.61%, Test Acc: 99.05%
Post-Pruning Training Epoch [10/10]: Loss: 0.0099, Train Acc: 99.66%, Test Acc: 98.89%
Initial Test Accuracy: 98.77%
Post-Pruning Training Epoch [1/10]: Loss: 0.0341, Train Acc: 98.96%, Test Acc: 98.42%
Post-Pruning Training Epoch [2/10]: Loss: 0.0246, Train Acc: 99.20%, Test Acc: 98.89%
Post-Pruning Training Epoch [3/10]: Loss: 0.0203, Train Acc: 99.34%, Test Acc: 98.72%
Post-Pruning Training Epoch [4/10]: Loss: 0.0170, Train Acc: 99.43%, Test Acc: 98.77%
Post-Pruning Training Epoch [5/10]: Loss: 0.0157, Train Acc: 99.47%, Test Acc: 98.93%
Post-Pruning Training Epoch [6/10]: Loss: 0.0139, Train Acc: 99.53%, Test Acc: 99.00%
Post-Pruning Training Epoch [7/10]: Loss: 0.0130, Train Acc: 99.56%, Test Acc: 98.92%
Post-Pruning Training Epoch [8/10]: Loss: 0.0105, Train Acc: 99.67%, Test Acc: 99.06%
Post-Pruning Training Epoch [9/10]: Loss: 0.0108, Train Acc: 99.67%, Test Acc: 99.04%
Post-Pruning Training Epoch [10/10]: Loss: 0.0093, Train Acc: 99.69%, Test Acc: 98.63%
Post-Pruned Baseline Model Accuracy: 98.88%
Post-Pruned Low Forgetting Model Accuracy: 98.89%
Post-Pruned High Forgetting Model Accuracy: 98.63%
Accuracy results saved to results/LeNet/MNIST/dr0.5/pr0.0/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.5/pr0.0/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 30000 highest-forgetting and top 30000 lowest-forgetting samples.
Highest forgetting subset size: 30000, Lowest forgetting subset size: 30000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.3780, Accuracy: 88.78%
Epoch [2/10] complete: Loss: 0.0948, Accuracy: 97.02%
Epoch [3/10] complete: Loss: 0.0630, Accuracy: 98.01%
Epoch [4/10] complete: Loss: 0.0488, Accuracy: 98.42%
Epoch [5/10] complete: Loss: 0.0387, Accuracy: 98.79%
Epoch [6/10] complete: Loss: 0.0344, Accuracy: 98.90%
Epoch [7/10] complete: Loss: 0.0275, Accuracy: 99.18%
Epoch [8/10] complete: Loss: 0.0217, Accuracy: 99.27%
Epoch [9/10] complete: Loss: 0.0214, Accuracy: 99.28%
Epoch [10/10] complete: Loss: 0.0176, Accuracy: 99.42%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4178, Accuracy: 86.93%
Epoch [2/10] complete: Loss: 0.1097, Accuracy: 96.65%
Epoch [3/10] complete: Loss: 0.0765, Accuracy: 97.62%
Epoch [4/10] complete: Loss: 0.0616, Accuracy: 98.07%
Epoch [5/10] complete: Loss: 0.0471, Accuracy: 98.52%
Epoch [6/10] complete: Loss: 0.0403, Accuracy: 98.71%
Epoch [7/10] complete: Loss: 0.0341, Accuracy: 98.90%
Epoch [8/10] complete: Loss: 0.0297, Accuracy: 99.03%
Epoch [9/10] complete: Loss: 0.0275, Accuracy: 99.07%
Epoch [10/10] complete: Loss: 0.0231, Accuracy: 99.19%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.38%
High Forgetting Model Accuracy: 98.52%
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.5/pr0.2/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.91%
Pruned Low Forgetting Model Accuracy: 98.30%
Pruned High Forgetting Model Accuracy: 98.37%
Post-Pruning Retraining...
Initial Test Accuracy: 98.91%
Post-Pruning Training Epoch [1/10]: Loss: 0.0163, Train Acc: 99.49%, Test Acc: 99.09%
Post-Pruning Training Epoch [2/10]: Loss: 0.0131, Train Acc: 99.58%, Test Acc: 98.91%
Post-Pruning Training Epoch [3/10]: Loss: 0.0112, Train Acc: 99.64%, Test Acc: 99.02%
Post-Pruning Training Epoch [4/10]: Loss: 0.0111, Train Acc: 99.61%, Test Acc: 98.97%
Post-Pruning Training Epoch [5/10]: Loss: 0.0085, Train Acc: 99.75%, Test Acc: 98.90%
Post-Pruning Training Epoch [6/10]: Loss: 0.0094, Train Acc: 99.67%, Test Acc: 98.89%
Post-Pruning Training Epoch [7/10]: Loss: 0.0098, Train Acc: 99.67%, Test Acc: 98.86%
Post-Pruning Training Epoch [8/10]: Loss: 0.0077, Train Acc: 99.72%, Test Acc: 99.04%
Post-Pruning Training Epoch [9/10]: Loss: 0.0091, Train Acc: 99.71%, Test Acc: 99.01%
Post-Pruning Training Epoch [10/10]: Loss: 0.0069, Train Acc: 99.80%, Test Acc: 98.93%
Initial Test Accuracy: 98.30%
Post-Pruning Training Epoch [1/10]: Loss: 0.0381, Train Acc: 98.85%, Test Acc: 98.84%
Post-Pruning Training Epoch [2/10]: Loss: 0.0287, Train Acc: 99.08%, Test Acc: 98.83%
Post-Pruning Training Epoch [3/10]: Loss: 0.0243, Train Acc: 99.22%, Test Acc: 99.07%
Post-Pruning Training Epoch [4/10]: Loss: 0.0201, Train Acc: 99.36%, Test Acc: 98.95%
Post-Pruning Training Epoch [5/10]: Loss: 0.0162, Train Acc: 99.49%, Test Acc: 98.95%
Post-Pruning Training Epoch [6/10]: Loss: 0.0163, Train Acc: 99.47%, Test Acc: 98.93%
Post-Pruning Training Epoch [7/10]: Loss: 0.0141, Train Acc: 99.53%, Test Acc: 98.82%
Post-Pruning Training Epoch [8/10]: Loss: 0.0114, Train Acc: 99.61%, Test Acc: 98.84%
Post-Pruning Training Epoch [9/10]: Loss: 0.0120, Train Acc: 99.58%, Test Acc: 98.70%
Post-Pruning Training Epoch [10/10]: Loss: 0.0109, Train Acc: 99.62%, Test Acc: 98.43%
Initial Test Accuracy: 98.37%
Post-Pruning Training Epoch [1/10]: Loss: 0.0340, Train Acc: 98.95%, Test Acc: 98.62%
Post-Pruning Training Epoch [2/10]: Loss: 0.0244, Train Acc: 99.21%, Test Acc: 98.44%
Post-Pruning Training Epoch [3/10]: Loss: 0.0204, Train Acc: 99.37%, Test Acc: 98.97%
Post-Pruning Training Epoch [4/10]: Loss: 0.0169, Train Acc: 99.43%, Test Acc: 98.74%
Post-Pruning Training Epoch [5/10]: Loss: 0.0168, Train Acc: 99.47%, Test Acc: 98.79%
Post-Pruning Training Epoch [6/10]: Loss: 0.0136, Train Acc: 99.57%, Test Acc: 99.00%
Post-Pruning Training Epoch [7/10]: Loss: 0.0138, Train Acc: 99.56%, Test Acc: 98.91%
Post-Pruning Training Epoch [8/10]: Loss: 0.0101, Train Acc: 99.70%, Test Acc: 98.96%
Post-Pruning Training Epoch [9/10]: Loss: 0.0110, Train Acc: 99.67%, Test Acc: 98.96%
Post-Pruning Training Epoch [10/10]: Loss: 0.0097, Train Acc: 99.66%, Test Acc: 99.17%
Post-Pruned Baseline Model Accuracy: 98.93%
Post-Pruned Low Forgetting Model Accuracy: 98.43%
Post-Pruned High Forgetting Model Accuracy: 99.17%
Accuracy results saved to results/LeNet/MNIST/dr0.5/pr0.2/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.5/pr0.2/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 30000 highest-forgetting and top 30000 lowest-forgetting samples.
Highest forgetting subset size: 30000, Lowest forgetting subset size: 30000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.3781, Accuracy: 88.74%
Epoch [2/10] complete: Loss: 0.0952, Accuracy: 96.99%
Epoch [3/10] complete: Loss: 0.0637, Accuracy: 98.04%
Epoch [4/10] complete: Loss: 0.0494, Accuracy: 98.39%
Epoch [5/10] complete: Loss: 0.0390, Accuracy: 98.77%
Epoch [6/10] complete: Loss: 0.0342, Accuracy: 98.91%
Epoch [7/10] complete: Loss: 0.0268, Accuracy: 99.15%
Epoch [8/10] complete: Loss: 0.0205, Accuracy: 99.32%
Epoch [9/10] complete: Loss: 0.0218, Accuracy: 99.31%
Epoch [10/10] complete: Loss: 0.0171, Accuracy: 99.38%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4179, Accuracy: 86.97%
Epoch [2/10] complete: Loss: 0.1092, Accuracy: 96.67%
Epoch [3/10] complete: Loss: 0.0762, Accuracy: 97.63%
Epoch [4/10] complete: Loss: 0.0605, Accuracy: 98.07%
Epoch [5/10] complete: Loss: 0.0464, Accuracy: 98.59%
Epoch [6/10] complete: Loss: 0.0396, Accuracy: 98.76%
Epoch [7/10] complete: Loss: 0.0327, Accuracy: 98.90%
Epoch [8/10] complete: Loss: 0.0282, Accuracy: 99.07%
Epoch [9/10] complete: Loss: 0.0265, Accuracy: 99.10%
Epoch [10/10] complete: Loss: 0.0207, Accuracy: 99.32%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.28%
High Forgetting Model Accuracy: 98.82%
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.5/pr0.4/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 98.46%
Pruned Low Forgetting Model Accuracy: 98.11%
Pruned High Forgetting Model Accuracy: 98.83%
Post-Pruning Retraining...
Initial Test Accuracy: 98.46%
Post-Pruning Training Epoch [1/10]: Loss: 0.0175, Train Acc: 99.42%, Test Acc: 99.01%
Post-Pruning Training Epoch [2/10]: Loss: 0.0139, Train Acc: 99.53%, Test Acc: 98.86%
Post-Pruning Training Epoch [3/10]: Loss: 0.0108, Train Acc: 99.62%, Test Acc: 99.12%
Post-Pruning Training Epoch [4/10]: Loss: 0.0117, Train Acc: 99.60%, Test Acc: 98.92%
Post-Pruning Training Epoch [5/10]: Loss: 0.0097, Train Acc: 99.68%, Test Acc: 98.79%
Post-Pruning Training Epoch [6/10]: Loss: 0.0104, Train Acc: 99.64%, Test Acc: 99.05%
Post-Pruning Training Epoch [7/10]: Loss: 0.0089, Train Acc: 99.71%, Test Acc: 98.84%
Post-Pruning Training Epoch [8/10]: Loss: 0.0083, Train Acc: 99.71%, Test Acc: 98.96%
Post-Pruning Training Epoch [9/10]: Loss: 0.0080, Train Acc: 99.71%, Test Acc: 98.78%
Post-Pruning Training Epoch [10/10]: Loss: 0.0095, Train Acc: 99.69%, Test Acc: 99.04%
Initial Test Accuracy: 98.11%
Post-Pruning Training Epoch [1/10]: Loss: 0.0399, Train Acc: 98.83%, Test Acc: 98.85%
Post-Pruning Training Epoch [2/10]: Loss: 0.0291, Train Acc: 99.11%, Test Acc: 98.80%
Post-Pruning Training Epoch [3/10]: Loss: 0.0246, Train Acc: 99.21%, Test Acc: 99.00%
Post-Pruning Training Epoch [4/10]: Loss: 0.0221, Train Acc: 99.26%, Test Acc: 99.05%
Post-Pruning Training Epoch [5/10]: Loss: 0.0164, Train Acc: 99.46%, Test Acc: 98.96%
Post-Pruning Training Epoch [6/10]: Loss: 0.0161, Train Acc: 99.49%, Test Acc: 98.89%
Post-Pruning Training Epoch [7/10]: Loss: 0.0152, Train Acc: 99.49%, Test Acc: 98.77%
Post-Pruning Training Epoch [8/10]: Loss: 0.0121, Train Acc: 99.59%, Test Acc: 99.05%
Post-Pruning Training Epoch [9/10]: Loss: 0.0122, Train Acc: 99.58%, Test Acc: 98.86%
Post-Pruning Training Epoch [10/10]: Loss: 0.0115, Train Acc: 99.61%, Test Acc: 98.72%
Initial Test Accuracy: 98.83%
Post-Pruning Training Epoch [1/10]: Loss: 0.0348, Train Acc: 98.97%, Test Acc: 98.25%
Post-Pruning Training Epoch [2/10]: Loss: 0.0255, Train Acc: 99.18%, Test Acc: 98.55%
Post-Pruning Training Epoch [3/10]: Loss: 0.0209, Train Acc: 99.35%, Test Acc: 98.96%
Post-Pruning Training Epoch [4/10]: Loss: 0.0169, Train Acc: 99.45%, Test Acc: 98.99%
Post-Pruning Training Epoch [5/10]: Loss: 0.0161, Train Acc: 99.51%, Test Acc: 99.08%
Post-Pruning Training Epoch [6/10]: Loss: 0.0143, Train Acc: 99.52%, Test Acc: 98.64%
Post-Pruning Training Epoch [7/10]: Loss: 0.0133, Train Acc: 99.54%, Test Acc: 98.92%
Post-Pruning Training Epoch [8/10]: Loss: 0.0102, Train Acc: 99.67%, Test Acc: 98.87%
Post-Pruning Training Epoch [9/10]: Loss: 0.0117, Train Acc: 99.64%, Test Acc: 99.01%
Post-Pruning Training Epoch [10/10]: Loss: 0.0092, Train Acc: 99.72%, Test Acc: 98.87%
Post-Pruned Baseline Model Accuracy: 99.04%
Post-Pruned Low Forgetting Model Accuracy: 98.72%
Post-Pruned High Forgetting Model Accuracy: 98.87%
Accuracy results saved to results/LeNet/MNIST/dr0.5/pr0.4/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.5/pr0.4/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 30000 highest-forgetting and top 30000 lowest-forgetting samples.
Highest forgetting subset size: 30000, Lowest forgetting subset size: 30000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.3775, Accuracy: 88.81%
Epoch [2/10] complete: Loss: 0.0944, Accuracy: 97.09%
Epoch [3/10] complete: Loss: 0.0640, Accuracy: 97.98%
Epoch [4/10] complete: Loss: 0.0484, Accuracy: 98.42%
Epoch [5/10] complete: Loss: 0.0386, Accuracy: 98.76%
Epoch [6/10] complete: Loss: 0.0336, Accuracy: 98.94%
Epoch [7/10] complete: Loss: 0.0276, Accuracy: 99.12%
Epoch [8/10] complete: Loss: 0.0211, Accuracy: 99.30%
Epoch [9/10] complete: Loss: 0.0202, Accuracy: 99.32%
Epoch [10/10] complete: Loss: 0.0162, Accuracy: 99.43%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4175, Accuracy: 86.96%
Epoch [2/10] complete: Loss: 0.1096, Accuracy: 96.61%
Epoch [3/10] complete: Loss: 0.0764, Accuracy: 97.66%
Epoch [4/10] complete: Loss: 0.0607, Accuracy: 98.11%
Epoch [5/10] complete: Loss: 0.0464, Accuracy: 98.55%
Epoch [6/10] complete: Loss: 0.0400, Accuracy: 98.72%
Epoch [7/10] complete: Loss: 0.0343, Accuracy: 98.82%
Epoch [8/10] complete: Loss: 0.0287, Accuracy: 99.09%
Epoch [9/10] complete: Loss: 0.0278, Accuracy: 99.08%
Epoch [10/10] complete: Loss: 0.0219, Accuracy: 99.30%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.67%
High Forgetting Model Accuracy: 98.80%
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.5/pr0.6/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 93.18%
Pruned Low Forgetting Model Accuracy: 97.97%
Pruned High Forgetting Model Accuracy: 96.70%
Post-Pruning Retraining...
Initial Test Accuracy: 93.18%
Post-Pruning Training Epoch [1/10]: Loss: 0.0223, Train Acc: 99.27%, Test Acc: 99.04%
Post-Pruning Training Epoch [2/10]: Loss: 0.0153, Train Acc: 99.51%, Test Acc: 99.04%
Post-Pruning Training Epoch [3/10]: Loss: 0.0126, Train Acc: 99.58%, Test Acc: 98.97%
Post-Pruning Training Epoch [4/10]: Loss: 0.0122, Train Acc: 99.57%, Test Acc: 98.92%
Post-Pruning Training Epoch [5/10]: Loss: 0.0112, Train Acc: 99.61%, Test Acc: 98.98%
Post-Pruning Training Epoch [6/10]: Loss: 0.0099, Train Acc: 99.67%, Test Acc: 98.83%
Post-Pruning Training Epoch [7/10]: Loss: 0.0087, Train Acc: 99.71%, Test Acc: 99.00%
Post-Pruning Training Epoch [8/10]: Loss: 0.0096, Train Acc: 99.68%, Test Acc: 98.88%
Post-Pruning Training Epoch [9/10]: Loss: 0.0085, Train Acc: 99.70%, Test Acc: 99.03%
Post-Pruning Training Epoch [10/10]: Loss: 0.0075, Train Acc: 99.74%, Test Acc: 98.89%
Initial Test Accuracy: 97.97%
Post-Pruning Training Epoch [1/10]: Loss: 0.0411, Train Acc: 98.75%, Test Acc: 98.80%
Post-Pruning Training Epoch [2/10]: Loss: 0.0306, Train Acc: 99.02%, Test Acc: 98.71%
Post-Pruning Training Epoch [3/10]: Loss: 0.0256, Train Acc: 99.17%, Test Acc: 99.13%
Post-Pruning Training Epoch [4/10]: Loss: 0.0216, Train Acc: 99.30%, Test Acc: 98.87%
Post-Pruning Training Epoch [5/10]: Loss: 0.0163, Train Acc: 99.45%, Test Acc: 99.01%
Post-Pruning Training Epoch [6/10]: Loss: 0.0162, Train Acc: 99.46%, Test Acc: 98.98%
Post-Pruning Training Epoch [7/10]: Loss: 0.0143, Train Acc: 99.51%, Test Acc: 98.98%
Post-Pruning Training Epoch [8/10]: Loss: 0.0109, Train Acc: 99.64%, Test Acc: 98.71%
Post-Pruning Training Epoch [9/10]: Loss: 0.0134, Train Acc: 99.56%, Test Acc: 98.79%
Post-Pruning Training Epoch [10/10]: Loss: 0.0107, Train Acc: 99.67%, Test Acc: 98.99%
Initial Test Accuracy: 96.70%
Post-Pruning Training Epoch [1/10]: Loss: 0.0389, Train Acc: 98.79%, Test Acc: 98.48%
Post-Pruning Training Epoch [2/10]: Loss: 0.0278, Train Acc: 99.15%, Test Acc: 98.79%
Post-Pruning Training Epoch [3/10]: Loss: 0.0220, Train Acc: 99.32%, Test Acc: 99.00%
Post-Pruning Training Epoch [4/10]: Loss: 0.0185, Train Acc: 99.37%, Test Acc: 98.81%
Post-Pruning Training Epoch [5/10]: Loss: 0.0182, Train Acc: 99.42%, Test Acc: 98.97%
Post-Pruning Training Epoch [6/10]: Loss: 0.0140, Train Acc: 99.55%, Test Acc: 98.74%
Post-Pruning Training Epoch [7/10]: Loss: 0.0125, Train Acc: 99.60%, Test Acc: 98.78%
Post-Pruning Training Epoch [8/10]: Loss: 0.0109, Train Acc: 99.67%, Test Acc: 98.99%
Post-Pruning Training Epoch [9/10]: Loss: 0.0103, Train Acc: 99.67%, Test Acc: 98.66%
Post-Pruning Training Epoch [10/10]: Loss: 0.0094, Train Acc: 99.68%, Test Acc: 98.91%
Post-Pruned Baseline Model Accuracy: 98.89%
Post-Pruned Low Forgetting Model Accuracy: 98.99%
Post-Pruned High Forgetting Model Accuracy: 98.91%
Accuracy results saved to results/LeNet/MNIST/dr0.5/pr0.6/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.5/pr0.6/post_pruning_accuracy.png.
=============================================================================================================
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 30000 highest-forgetting and top 30000 lowest-forgetting samples.
Highest forgetting subset size: 30000, Lowest forgetting subset size: 30000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.3779, Accuracy: 88.81%
Epoch [2/10] complete: Loss: 0.0952, Accuracy: 97.07%
Epoch [3/10] complete: Loss: 0.0640, Accuracy: 98.01%
Epoch [4/10] complete: Loss: 0.0490, Accuracy: 98.41%
Epoch [5/10] complete: Loss: 0.0389, Accuracy: 98.75%
Epoch [6/10] complete: Loss: 0.0341, Accuracy: 98.89%
Epoch [7/10] complete: Loss: 0.0285, Accuracy: 99.12%
Epoch [8/10] complete: Loss: 0.0220, Accuracy: 99.24%
Epoch [9/10] complete: Loss: 0.0213, Accuracy: 99.34%
Epoch [10/10] complete: Loss: 0.0163, Accuracy: 99.47%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 0.4179, Accuracy: 86.97%
Epoch [2/10] complete: Loss: 0.1097, Accuracy: 96.61%
Epoch [3/10] complete: Loss: 0.0767, Accuracy: 97.63%
Epoch [4/10] complete: Loss: 0.0618, Accuracy: 98.04%
Epoch [5/10] complete: Loss: 0.0469, Accuracy: 98.55%
Epoch [6/10] complete: Loss: 0.0402, Accuracy: 98.74%
Epoch [7/10] complete: Loss: 0.0343, Accuracy: 98.86%
Epoch [8/10] complete: Loss: 0.0294, Accuracy: 99.01%
Epoch [9/10] complete: Loss: 0.0275, Accuracy: 99.11%
Epoch [10/10] complete: Loss: 0.0239, Accuracy: 99.22%
Training completed.
Baseline Model Accuracy: 98.92%
Low Forgetting Model Accuracy: 98.13%
High Forgetting Model Accuracy: 98.85%
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/LeNet/MNIST/dr0.5/pr0.8/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 43.24%
Pruned Low Forgetting Model Accuracy: 72.63%
Pruned High Forgetting Model Accuracy: 42.10%
Post-Pruning Retraining...
Initial Test Accuracy: 43.24%
Post-Pruning Training Epoch [1/10]: Loss: 0.0514, Train Acc: 98.49%, Test Acc: 99.06%
Post-Pruning Training Epoch [2/10]: Loss: 0.0217, Train Acc: 99.32%, Test Acc: 98.83%
Post-Pruning Training Epoch [3/10]: Loss: 0.0178, Train Acc: 99.42%, Test Acc: 99.07%
Post-Pruning Training Epoch [4/10]: Loss: 0.0146, Train Acc: 99.53%, Test Acc: 98.89%
Post-Pruning Training Epoch [5/10]: Loss: 0.0128, Train Acc: 99.56%, Test Acc: 98.87%
Post-Pruning Training Epoch [6/10]: Loss: 0.0117, Train Acc: 99.61%, Test Acc: 98.86%
Post-Pruning Training Epoch [7/10]: Loss: 0.0115, Train Acc: 99.61%, Test Acc: 99.05%
Post-Pruning Training Epoch [8/10]: Loss: 0.0105, Train Acc: 99.64%, Test Acc: 98.98%
Post-Pruning Training Epoch [9/10]: Loss: 0.0084, Train Acc: 99.72%, Test Acc: 99.00%
Post-Pruning Training Epoch [10/10]: Loss: 0.0087, Train Acc: 99.73%, Test Acc: 98.89%
Initial Test Accuracy: 72.63%
Post-Pruning Training Epoch [1/10]: Loss: 0.0613, Train Acc: 98.26%, Test Acc: 98.76%
Post-Pruning Training Epoch [2/10]: Loss: 0.0369, Train Acc: 98.80%, Test Acc: 98.77%
Post-Pruning Training Epoch [3/10]: Loss: 0.0303, Train Acc: 99.06%, Test Acc: 98.97%
Post-Pruning Training Epoch [4/10]: Loss: 0.0248, Train Acc: 99.21%, Test Acc: 99.02%
Post-Pruning Training Epoch [5/10]: Loss: 0.0196, Train Acc: 99.36%, Test Acc: 98.82%
Post-Pruning Training Epoch [6/10]: Loss: 0.0186, Train Acc: 99.38%, Test Acc: 98.96%
Post-Pruning Training Epoch [7/10]: Loss: 0.0150, Train Acc: 99.50%, Test Acc: 98.89%
Post-Pruning Training Epoch [8/10]: Loss: 0.0127, Train Acc: 99.56%, Test Acc: 98.96%
Post-Pruning Training Epoch [9/10]: Loss: 0.0140, Train Acc: 99.53%, Test Acc: 98.70%
Post-Pruning Training Epoch [10/10]: Loss: 0.0106, Train Acc: 99.66%, Test Acc: 98.63%
Initial Test Accuracy: 42.10%
Post-Pruning Training Epoch [1/10]: Loss: 0.0616, Train Acc: 98.22%, Test Acc: 98.85%
Post-Pruning Training Epoch [2/10]: Loss: 0.0325, Train Acc: 98.99%, Test Acc: 98.68%
Post-Pruning Training Epoch [3/10]: Loss: 0.0255, Train Acc: 99.20%, Test Acc: 98.96%
Post-Pruning Training Epoch [4/10]: Loss: 0.0216, Train Acc: 99.28%, Test Acc: 98.56%
Post-Pruning Training Epoch [5/10]: Loss: 0.0189, Train Acc: 99.40%, Test Acc: 98.84%
Post-Pruning Training Epoch [6/10]: Loss: 0.0166, Train Acc: 99.48%, Test Acc: 98.89%
Post-Pruning Training Epoch [7/10]: Loss: 0.0143, Train Acc: 99.53%, Test Acc: 99.01%
Post-Pruning Training Epoch [8/10]: Loss: 0.0118, Train Acc: 99.60%, Test Acc: 99.03%
Post-Pruning Training Epoch [9/10]: Loss: 0.0126, Train Acc: 99.57%, Test Acc: 99.04%
Post-Pruning Training Epoch [10/10]: Loss: 0.0108, Train Acc: 99.63%, Test Acc: 99.04%
Post-Pruned Baseline Model Accuracy: 98.89%
Post-Pruned Low Forgetting Model Accuracy: 98.63%
Post-Pruned High Forgetting Model Accuracy: 99.04%
Accuracy results saved to results/LeNet/MNIST/dr0.5/pr0.8/accuracies.csv.
Post-pruning accuracy plot saved to results/LeNet/MNIST/dr0.5/pr0.8/post_pruning_accuracy.png.
