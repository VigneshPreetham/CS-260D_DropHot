=============================================================================================================
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz
Extracting data/cifar-10-python.tar.gz to data
Files already downloaded and verified
Forgetting scores and baseline model not found. Computing from scratch...
Starting baseline training for 10 epochs with forgetting tracking...
Epoch [1/10] completed. Training Loss: 1.5649, Accuracy: 42.30%
Epoch [2/10] completed. Training Loss: 1.1389, Accuracy: 59.38%
Epoch [3/10] completed. Training Loss: 0.9286, Accuracy: 67.31%
Epoch [4/10] completed. Training Loss: 0.7810, Accuracy: 72.69%
Epoch [5/10] completed. Training Loss: 0.6603, Accuracy: 76.60%
Epoch [6/10] completed. Training Loss: 0.5484, Accuracy: 80.63%
Epoch [7/10] completed. Training Loss: 0.4571, Accuracy: 83.98%
Epoch [8/10] completed. Training Loss: 0.3707, Accuracy: 86.97%
Epoch [9/10] completed. Training Loss: 0.3071, Accuracy: 89.36%
Epoch [10/10] completed. Training Loss: 0.2581, Accuracy: 90.93%
Baseline training with forgetting tracking completed.
Forgetting scores and baseline model saved for future runs.
Selected top 5000 highest-forgetting and top 5000 lowest-forgetting samples.
Highest forgetting subset size: 5000, Lowest forgetting subset size: 5000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.8980, Accuracy: 31.72%
Epoch [2/10] complete: Loss: 1.5341, Accuracy: 44.52%
Epoch [3/10] complete: Loss: 1.3345, Accuracy: 52.12%
Epoch [4/10] complete: Loss: 1.1305, Accuracy: 59.60%
Epoch [5/10] complete: Loss: 0.9747, Accuracy: 66.26%
Epoch [6/10] complete: Loss: 0.7841, Accuracy: 72.68%
Epoch [7/10] complete: Loss: 0.6320, Accuracy: 77.24%
Epoch [8/10] complete: Loss: 0.5567, Accuracy: 80.64%
Epoch [9/10] complete: Loss: 0.4867, Accuracy: 82.74%
Epoch [10/10] complete: Loss: 0.3877, Accuracy: 86.86%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.8960, Accuracy: 32.70%
Epoch [2/10] complete: Loss: 1.4983, Accuracy: 46.06%
Epoch [3/10] complete: Loss: 1.3189, Accuracy: 52.12%
Epoch [4/10] complete: Loss: 1.1493, Accuracy: 59.38%
Epoch [5/10] complete: Loss: 0.9726, Accuracy: 65.52%
Epoch [6/10] complete: Loss: 0.8445, Accuracy: 71.46%
Epoch [7/10] complete: Loss: 0.7697, Accuracy: 72.92%
Epoch [8/10] complete: Loss: 0.6602, Accuracy: 77.14%
Epoch [9/10] complete: Loss: 0.4582, Accuracy: 83.26%
Epoch [10/10] complete: Loss: 0.3293, Accuracy: 88.58%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 52.91%
High Forgetting Model Accuracy: 51.82%
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.1/pr0.0/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 70.69%
Pruned Low Forgetting Model Accuracy: 52.91%
Pruned High Forgetting Model Accuracy: 51.82%
Post-Pruning Retraining...
Initial Test Accuracy: 70.69%
Post-Pruning Training Epoch [1/10]: Loss: 0.8815, Train Acc: 69.55%, Test Acc: 71.24%
Post-Pruning Training Epoch [2/10]: Loss: 0.6161, Train Acc: 78.48%, Test Acc: 73.72%
Post-Pruning Training Epoch [3/10]: Loss: 0.4774, Train Acc: 83.31%, Test Acc: 75.74%
Post-Pruning Training Epoch [4/10]: Loss: 0.3658, Train Acc: 87.06%, Test Acc: 75.15%
Post-Pruning Training Epoch [5/10]: Loss: 0.2768, Train Acc: 90.26%, Test Acc: 74.58%
Post-Pruning Training Epoch [6/10]: Loss: 0.2113, Train Acc: 92.59%, Test Acc: 74.93%
Post-Pruning Training Epoch [7/10]: Loss: 0.1678, Train Acc: 94.14%, Test Acc: 74.86%
Post-Pruning Training Epoch [8/10]: Loss: 0.1369, Train Acc: 95.26%, Test Acc: 75.01%
Post-Pruning Training Epoch [9/10]: Loss: 0.1202, Train Acc: 95.82%, Test Acc: 75.91%
Post-Pruning Training Epoch [10/10]: Loss: 0.0966, Train Acc: 96.69%, Test Acc: 75.55%
Initial Test Accuracy: 52.91%
Post-Pruning Training Epoch [1/10]: Loss: 1.0886, Train Acc: 61.82%, Test Acc: 62.61%
Post-Pruning Training Epoch [2/10]: Loss: 0.8274, Train Acc: 71.36%, Test Acc: 69.12%
Post-Pruning Training Epoch [3/10]: Loss: 0.6828, Train Acc: 76.18%, Test Acc: 71.35%
Post-Pruning Training Epoch [4/10]: Loss: 0.5696, Train Acc: 80.14%, Test Acc: 73.77%
Post-Pruning Training Epoch [5/10]: Loss: 0.4728, Train Acc: 83.56%, Test Acc: 72.37%
Post-Pruning Training Epoch [6/10]: Loss: 0.3746, Train Acc: 86.76%, Test Acc: 74.94%
Post-Pruning Training Epoch [7/10]: Loss: 0.3016, Train Acc: 89.51%, Test Acc: 76.02%
Post-Pruning Training Epoch [8/10]: Loss: 0.2431, Train Acc: 91.48%, Test Acc: 75.02%
Post-Pruning Training Epoch [9/10]: Loss: 0.2087, Train Acc: 92.70%, Test Acc: 74.62%
Post-Pruning Training Epoch [10/10]: Loss: 0.1600, Train Acc: 94.36%, Test Acc: 74.65%
Initial Test Accuracy: 51.82%
Post-Pruning Training Epoch [1/10]: Loss: 1.0808, Train Acc: 62.29%, Test Acc: 63.52%
Post-Pruning Training Epoch [2/10]: Loss: 0.8268, Train Acc: 71.12%, Test Acc: 69.56%
Post-Pruning Training Epoch [3/10]: Loss: 0.6807, Train Acc: 76.41%, Test Acc: 71.73%
Post-Pruning Training Epoch [4/10]: Loss: 0.5643, Train Acc: 80.36%, Test Acc: 73.92%
Post-Pruning Training Epoch [5/10]: Loss: 0.4632, Train Acc: 83.84%, Test Acc: 73.58%
Post-Pruning Training Epoch [6/10]: Loss: 0.3733, Train Acc: 87.11%, Test Acc: 75.13%
Post-Pruning Training Epoch [7/10]: Loss: 0.2904, Train Acc: 89.74%, Test Acc: 76.01%
Post-Pruning Training Epoch [8/10]: Loss: 0.2328, Train Acc: 91.80%, Test Acc: 74.81%
Post-Pruning Training Epoch [9/10]: Loss: 0.1919, Train Acc: 93.36%, Test Acc: 76.30%
Post-Pruning Training Epoch [10/10]: Loss: 0.1553, Train Acc: 94.57%, Test Acc: 75.07%
Post-Pruned Baseline Model Accuracy: 75.55%
Post-Pruned Low Forgetting Model Accuracy: 74.65%
Post-Pruned High Forgetting Model Accuracy: 75.07%
Accuracy results saved to results/resnet18/CIFAR10/dr0.1/pr0.0/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.1/pr0.0/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 5000 highest-forgetting and top 5000 lowest-forgetting samples.
Highest forgetting subset size: 5000, Lowest forgetting subset size: 5000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.8869, Accuracy: 32.58%
Epoch [2/10] complete: Loss: 1.4853, Accuracy: 45.80%
Epoch [3/10] complete: Loss: 1.2957, Accuracy: 53.14%
Epoch [4/10] complete: Loss: 1.1419, Accuracy: 59.70%
Epoch [5/10] complete: Loss: 0.9857, Accuracy: 65.20%
Epoch [6/10] complete: Loss: 0.7823, Accuracy: 73.32%
Epoch [7/10] complete: Loss: 0.6725, Accuracy: 77.70%
Epoch [8/10] complete: Loss: 0.5516, Accuracy: 80.84%
Epoch [9/10] complete: Loss: 0.4376, Accuracy: 85.36%
Epoch [10/10] complete: Loss: 0.4354, Accuracy: 85.26%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.9239, Accuracy: 32.34%
Epoch [2/10] complete: Loss: 1.5059, Accuracy: 45.30%
Epoch [3/10] complete: Loss: 1.3353, Accuracy: 52.20%
Epoch [4/10] complete: Loss: 1.1826, Accuracy: 57.66%
Epoch [5/10] complete: Loss: 0.9756, Accuracy: 64.90%
Epoch [6/10] complete: Loss: 0.8482, Accuracy: 69.96%
Epoch [7/10] complete: Loss: 0.7789, Accuracy: 72.56%
Epoch [8/10] complete: Loss: 0.5655, Accuracy: 80.46%
Epoch [9/10] complete: Loss: 0.5082, Accuracy: 83.12%
Epoch [10/10] complete: Loss: 0.4053, Accuracy: 85.66%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 50.88%
High Forgetting Model Accuracy: 50.07%
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.1/pr0.2/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 70.58%
Pruned Low Forgetting Model Accuracy: 50.64%
Pruned High Forgetting Model Accuracy: 50.19%
Post-Pruning Retraining...
Initial Test Accuracy: 70.58%
Post-Pruning Training Epoch [1/10]: Loss: 0.8863, Train Acc: 69.44%, Test Acc: 70.92%
Post-Pruning Training Epoch [2/10]: Loss: 0.6111, Train Acc: 78.46%, Test Acc: 73.07%
Post-Pruning Training Epoch [3/10]: Loss: 0.4760, Train Acc: 83.43%, Test Acc: 74.28%
Post-Pruning Training Epoch [4/10]: Loss: 0.3711, Train Acc: 87.04%, Test Acc: 74.51%
Post-Pruning Training Epoch [5/10]: Loss: 0.2724, Train Acc: 90.41%, Test Acc: 75.98%
Post-Pruning Training Epoch [6/10]: Loss: 0.2111, Train Acc: 92.60%, Test Acc: 75.14%
Post-Pruning Training Epoch [7/10]: Loss: 0.1673, Train Acc: 94.17%, Test Acc: 74.25%
Post-Pruning Training Epoch [8/10]: Loss: 0.1387, Train Acc: 95.24%, Test Acc: 74.69%
Post-Pruning Training Epoch [9/10]: Loss: 0.1175, Train Acc: 95.88%, Test Acc: 74.22%
Post-Pruning Training Epoch [10/10]: Loss: 0.1004, Train Acc: 96.47%, Test Acc: 75.10%
Initial Test Accuracy: 50.64%
Post-Pruning Training Epoch [1/10]: Loss: 1.0840, Train Acc: 62.20%, Test Acc: 64.41%
Post-Pruning Training Epoch [2/10]: Loss: 0.8371, Train Acc: 70.84%, Test Acc: 69.13%
Post-Pruning Training Epoch [3/10]: Loss: 0.6835, Train Acc: 76.19%, Test Acc: 74.37%
Post-Pruning Training Epoch [4/10]: Loss: 0.5683, Train Acc: 80.07%, Test Acc: 73.97%
Post-Pruning Training Epoch [5/10]: Loss: 0.4640, Train Acc: 83.87%, Test Acc: 74.52%
Post-Pruning Training Epoch [6/10]: Loss: 0.3782, Train Acc: 86.82%, Test Acc: 76.02%
Post-Pruning Training Epoch [7/10]: Loss: 0.3069, Train Acc: 89.34%, Test Acc: 76.18%
Post-Pruning Training Epoch [8/10]: Loss: 0.2429, Train Acc: 91.49%, Test Acc: 76.42%
Post-Pruning Training Epoch [9/10]: Loss: 0.2054, Train Acc: 92.76%, Test Acc: 76.65%
Post-Pruning Training Epoch [10/10]: Loss: 0.1616, Train Acc: 94.33%, Test Acc: 75.78%
Initial Test Accuracy: 50.19%
Post-Pruning Training Epoch [1/10]: Loss: 1.0900, Train Acc: 61.87%, Test Acc: 65.56%
Post-Pruning Training Epoch [2/10]: Loss: 0.8262, Train Acc: 71.29%, Test Acc: 69.25%
Post-Pruning Training Epoch [3/10]: Loss: 0.6837, Train Acc: 76.30%, Test Acc: 73.46%
Post-Pruning Training Epoch [4/10]: Loss: 0.5644, Train Acc: 80.53%, Test Acc: 73.39%
Post-Pruning Training Epoch [5/10]: Loss: 0.4641, Train Acc: 84.01%, Test Acc: 74.49%
Post-Pruning Training Epoch [6/10]: Loss: 0.3704, Train Acc: 87.05%, Test Acc: 74.64%
Post-Pruning Training Epoch [7/10]: Loss: 0.2990, Train Acc: 89.57%, Test Acc: 74.97%
Post-Pruning Training Epoch [8/10]: Loss: 0.2389, Train Acc: 91.62%, Test Acc: 75.63%
Post-Pruning Training Epoch [9/10]: Loss: 0.1885, Train Acc: 93.46%, Test Acc: 74.87%
Post-Pruning Training Epoch [10/10]: Loss: 0.1616, Train Acc: 94.29%, Test Acc: 74.79%
Post-Pruned Baseline Model Accuracy: 75.10%
Post-Pruned Low Forgetting Model Accuracy: 75.78%
Post-Pruned High Forgetting Model Accuracy: 74.79%
Accuracy results saved to results/resnet18/CIFAR10/dr0.1/pr0.2/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.1/pr0.2/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 5000 highest-forgetting and top 5000 lowest-forgetting samples.
Highest forgetting subset size: 5000, Lowest forgetting subset size: 5000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.9045, Accuracy: 32.04%
Epoch [2/10] complete: Loss: 1.5108, Accuracy: 44.60%
Epoch [3/10] complete: Loss: 1.3201, Accuracy: 52.62%
Epoch [4/10] complete: Loss: 1.1382, Accuracy: 58.86%
Epoch [5/10] complete: Loss: 1.0074, Accuracy: 64.18%
Epoch [6/10] complete: Loss: 0.8121, Accuracy: 71.54%
Epoch [7/10] complete: Loss: 0.6945, Accuracy: 75.66%
Epoch [8/10] complete: Loss: 0.5713, Accuracy: 79.82%
Epoch [9/10] complete: Loss: 0.5216, Accuracy: 82.34%
Epoch [10/10] complete: Loss: 0.3992, Accuracy: 86.82%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.8965, Accuracy: 32.58%
Epoch [2/10] complete: Loss: 1.5154, Accuracy: 44.78%
Epoch [3/10] complete: Loss: 1.3579, Accuracy: 51.62%
Epoch [4/10] complete: Loss: 1.1765, Accuracy: 57.66%
Epoch [5/10] complete: Loss: 0.9933, Accuracy: 65.04%
Epoch [6/10] complete: Loss: 0.8585, Accuracy: 69.88%
Epoch [7/10] complete: Loss: 0.7334, Accuracy: 74.56%
Epoch [8/10] complete: Loss: 0.6511, Accuracy: 77.16%
Epoch [9/10] complete: Loss: 0.4621, Accuracy: 84.52%
Epoch [10/10] complete: Loss: 0.4548, Accuracy: 83.88%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 52.85%
High Forgetting Model Accuracy: 53.25%
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.1/pr0.4/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 69.78%
Pruned Low Forgetting Model Accuracy: 50.02%
Pruned High Forgetting Model Accuracy: 48.66%
Post-Pruning Retraining...
Initial Test Accuracy: 69.78%
Post-Pruning Training Epoch [1/10]: Loss: 0.8882, Train Acc: 69.33%, Test Acc: 70.94%
Post-Pruning Training Epoch [2/10]: Loss: 0.6101, Train Acc: 78.75%, Test Acc: 72.40%
Post-Pruning Training Epoch [3/10]: Loss: 0.4822, Train Acc: 83.17%, Test Acc: 74.35%
Post-Pruning Training Epoch [4/10]: Loss: 0.3708, Train Acc: 86.97%, Test Acc: 74.64%
Post-Pruning Training Epoch [5/10]: Loss: 0.2728, Train Acc: 90.50%, Test Acc: 75.57%
Post-Pruning Training Epoch [6/10]: Loss: 0.2131, Train Acc: 92.57%, Test Acc: 75.14%
Post-Pruning Training Epoch [7/10]: Loss: 0.1672, Train Acc: 94.14%, Test Acc: 74.64%
Post-Pruning Training Epoch [8/10]: Loss: 0.1377, Train Acc: 95.25%, Test Acc: 74.94%
Post-Pruning Training Epoch [9/10]: Loss: 0.1194, Train Acc: 95.84%, Test Acc: 75.28%
Post-Pruning Training Epoch [10/10]: Loss: 0.1080, Train Acc: 96.22%, Test Acc: 75.09%
Initial Test Accuracy: 50.02%
Post-Pruning Training Epoch [1/10]: Loss: 1.1061, Train Acc: 61.17%, Test Acc: 63.18%
Post-Pruning Training Epoch [2/10]: Loss: 0.8508, Train Acc: 70.26%, Test Acc: 69.37%
Post-Pruning Training Epoch [3/10]: Loss: 0.6949, Train Acc: 76.03%, Test Acc: 73.35%
Post-Pruning Training Epoch [4/10]: Loss: 0.5776, Train Acc: 79.83%, Test Acc: 72.97%
Post-Pruning Training Epoch [5/10]: Loss: 0.4764, Train Acc: 83.33%, Test Acc: 73.22%
Post-Pruning Training Epoch [6/10]: Loss: 0.3828, Train Acc: 86.54%, Test Acc: 74.52%
Post-Pruning Training Epoch [7/10]: Loss: 0.3037, Train Acc: 89.37%, Test Acc: 75.38%
Post-Pruning Training Epoch [8/10]: Loss: 0.2474, Train Acc: 91.44%, Test Acc: 75.63%
Post-Pruning Training Epoch [9/10]: Loss: 0.1946, Train Acc: 93.15%, Test Acc: 75.64%
Post-Pruning Training Epoch [10/10]: Loss: 0.1626, Train Acc: 94.41%, Test Acc: 75.35%
Initial Test Accuracy: 48.66%
Post-Pruning Training Epoch [1/10]: Loss: 1.0996, Train Acc: 61.31%, Test Acc: 61.44%
Post-Pruning Training Epoch [2/10]: Loss: 0.8373, Train Acc: 70.81%, Test Acc: 68.90%
Post-Pruning Training Epoch [3/10]: Loss: 0.6879, Train Acc: 75.89%, Test Acc: 71.96%
Post-Pruning Training Epoch [4/10]: Loss: 0.5734, Train Acc: 80.06%, Test Acc: 73.46%
Post-Pruning Training Epoch [5/10]: Loss: 0.4675, Train Acc: 83.83%, Test Acc: 71.75%
Post-Pruning Training Epoch [6/10]: Loss: 0.3761, Train Acc: 86.80%, Test Acc: 73.99%
Post-Pruning Training Epoch [7/10]: Loss: 0.2946, Train Acc: 89.68%, Test Acc: 75.25%
Post-Pruning Training Epoch [8/10]: Loss: 0.2351, Train Acc: 91.75%, Test Acc: 75.32%
Post-Pruning Training Epoch [9/10]: Loss: 0.1920, Train Acc: 93.26%, Test Acc: 75.08%
Post-Pruning Training Epoch [10/10]: Loss: 0.1633, Train Acc: 94.35%, Test Acc: 75.35%
Post-Pruned Baseline Model Accuracy: 75.09%
Post-Pruned Low Forgetting Model Accuracy: 75.35%
Post-Pruned High Forgetting Model Accuracy: 75.35%
Accuracy results saved to results/resnet18/CIFAR10/dr0.1/pr0.4/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.1/pr0.4/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 5000 highest-forgetting and top 5000 lowest-forgetting samples.
Highest forgetting subset size: 5000, Lowest forgetting subset size: 5000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.8887, Accuracy: 32.50%
Epoch [2/10] complete: Loss: 1.4806, Accuracy: 45.98%
Epoch [3/10] complete: Loss: 1.3074, Accuracy: 52.60%
Epoch [4/10] complete: Loss: 1.1102, Accuracy: 60.64%
Epoch [5/10] complete: Loss: 0.9575, Accuracy: 66.14%
Epoch [6/10] complete: Loss: 0.7661, Accuracy: 72.80%
Epoch [7/10] complete: Loss: 0.6922, Accuracy: 76.26%
Epoch [8/10] complete: Loss: 0.5457, Accuracy: 81.20%
Epoch [9/10] complete: Loss: 0.5200, Accuracy: 82.46%
Epoch [10/10] complete: Loss: 0.3826, Accuracy: 87.14%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.9052, Accuracy: 32.44%
Epoch [2/10] complete: Loss: 1.4874, Accuracy: 45.28%
Epoch [3/10] complete: Loss: 1.3368, Accuracy: 52.00%
Epoch [4/10] complete: Loss: 1.1631, Accuracy: 58.62%
Epoch [5/10] complete: Loss: 0.9721, Accuracy: 65.14%
Epoch [6/10] complete: Loss: 0.8436, Accuracy: 70.00%
Epoch [7/10] complete: Loss: 0.6977, Accuracy: 75.06%
Epoch [8/10] complete: Loss: 0.6177, Accuracy: 78.40%
Epoch [9/10] complete: Loss: 0.5053, Accuracy: 82.00%
Epoch [10/10] complete: Loss: 0.3752, Accuracy: 87.04%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 50.12%
High Forgetting Model Accuracy: 52.88%
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.1/pr0.6/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 63.76%
Pruned Low Forgetting Model Accuracy: 32.39%
Pruned High Forgetting Model Accuracy: 35.06%
Post-Pruning Retraining...
Initial Test Accuracy: 63.76%
Post-Pruning Training Epoch [1/10]: Loss: 0.9035, Train Acc: 68.53%, Test Acc: 70.10%
Post-Pruning Training Epoch [2/10]: Loss: 0.6259, Train Acc: 78.24%, Test Acc: 72.52%
Post-Pruning Training Epoch [3/10]: Loss: 0.4932, Train Acc: 82.83%, Test Acc: 73.89%
Post-Pruning Training Epoch [4/10]: Loss: 0.3806, Train Acc: 86.63%, Test Acc: 74.20%
Post-Pruning Training Epoch [5/10]: Loss: 0.2883, Train Acc: 89.79%, Test Acc: 75.47%
Post-Pruning Training Epoch [6/10]: Loss: 0.2197, Train Acc: 92.28%, Test Acc: 75.08%
Post-Pruning Training Epoch [7/10]: Loss: 0.1744, Train Acc: 93.75%, Test Acc: 75.59%
Post-Pruning Training Epoch [8/10]: Loss: 0.1442, Train Acc: 94.94%, Test Acc: 74.78%
Post-Pruning Training Epoch [9/10]: Loss: 0.1208, Train Acc: 95.73%, Test Acc: 75.13%
Post-Pruning Training Epoch [10/10]: Loss: 0.1099, Train Acc: 96.14%, Test Acc: 76.02%
Initial Test Accuracy: 32.39%
Post-Pruning Training Epoch [1/10]: Loss: 1.1216, Train Acc: 60.61%, Test Acc: 62.51%
Post-Pruning Training Epoch [2/10]: Loss: 0.8521, Train Acc: 70.39%, Test Acc: 70.04%
Post-Pruning Training Epoch [3/10]: Loss: 0.6931, Train Acc: 76.02%, Test Acc: 72.97%
Post-Pruning Training Epoch [4/10]: Loss: 0.5753, Train Acc: 80.07%, Test Acc: 72.98%
Post-Pruning Training Epoch [5/10]: Loss: 0.4761, Train Acc: 83.47%, Test Acc: 73.51%
Post-Pruning Training Epoch [6/10]: Loss: 0.3789, Train Acc: 86.91%, Test Acc: 75.68%
Post-Pruning Training Epoch [7/10]: Loss: 0.3044, Train Acc: 89.39%, Test Acc: 75.69%
Post-Pruning Training Epoch [8/10]: Loss: 0.2412, Train Acc: 91.63%, Test Acc: 74.44%
Post-Pruning Training Epoch [9/10]: Loss: 0.2038, Train Acc: 92.87%, Test Acc: 75.41%
Post-Pruning Training Epoch [10/10]: Loss: 0.1568, Train Acc: 94.50%, Test Acc: 76.24%
Initial Test Accuracy: 35.06%
Post-Pruning Training Epoch [1/10]: Loss: 1.1148, Train Acc: 60.86%, Test Acc: 64.43%
Post-Pruning Training Epoch [2/10]: Loss: 0.8404, Train Acc: 70.73%, Test Acc: 68.99%
Post-Pruning Training Epoch [3/10]: Loss: 0.6965, Train Acc: 75.82%, Test Acc: 71.65%
Post-Pruning Training Epoch [4/10]: Loss: 0.5846, Train Acc: 79.86%, Test Acc: 73.34%
Post-Pruning Training Epoch [5/10]: Loss: 0.4786, Train Acc: 83.37%, Test Acc: 74.53%
Post-Pruning Training Epoch [6/10]: Loss: 0.3915, Train Acc: 86.28%, Test Acc: 75.61%
Post-Pruning Training Epoch [7/10]: Loss: 0.3122, Train Acc: 89.09%, Test Acc: 75.39%
Post-Pruning Training Epoch [8/10]: Loss: 0.2500, Train Acc: 91.24%, Test Acc: 74.92%
Post-Pruning Training Epoch [9/10]: Loss: 0.2009, Train Acc: 92.95%, Test Acc: 75.53%
Post-Pruning Training Epoch [10/10]: Loss: 0.1614, Train Acc: 94.37%, Test Acc: 75.48%
Post-Pruned Baseline Model Accuracy: 76.02%
Post-Pruned Low Forgetting Model Accuracy: 76.24%
Post-Pruned High Forgetting Model Accuracy: 75.48%
Accuracy results saved to results/resnet18/CIFAR10/dr0.1/pr0.6/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.1/pr0.6/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 5000 highest-forgetting and top 5000 lowest-forgetting samples.
Highest forgetting subset size: 5000, Lowest forgetting subset size: 5000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.9013, Accuracy: 31.72%
Epoch [2/10] complete: Loss: 1.5086, Accuracy: 44.48%
Epoch [3/10] complete: Loss: 1.2975, Accuracy: 53.14%
Epoch [4/10] complete: Loss: 1.1677, Accuracy: 58.48%
Epoch [5/10] complete: Loss: 1.0190, Accuracy: 64.30%
Epoch [6/10] complete: Loss: 0.8360, Accuracy: 70.28%
Epoch [7/10] complete: Loss: 0.6937, Accuracy: 75.82%
Epoch [8/10] complete: Loss: 0.5852, Accuracy: 79.86%
Epoch [9/10] complete: Loss: 0.5817, Accuracy: 79.38%
Epoch [10/10] complete: Loss: 0.3586, Accuracy: 87.92%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.9126, Accuracy: 32.42%
Epoch [2/10] complete: Loss: 1.4878, Accuracy: 45.52%
Epoch [3/10] complete: Loss: 1.3245, Accuracy: 52.46%
Epoch [4/10] complete: Loss: 1.1692, Accuracy: 58.26%
Epoch [5/10] complete: Loss: 1.0160, Accuracy: 63.18%
Epoch [6/10] complete: Loss: 0.8628, Accuracy: 69.94%
Epoch [7/10] complete: Loss: 0.7194, Accuracy: 74.14%
Epoch [8/10] complete: Loss: 0.5783, Accuracy: 79.54%
Epoch [9/10] complete: Loss: 0.5214, Accuracy: 81.86%
Epoch [10/10] complete: Loss: 0.3882, Accuracy: 86.98%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 51.34%
High Forgetting Model Accuracy: 50.38%
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.1/pr0.8/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 27.92%
Pruned Low Forgetting Model Accuracy: 12.21%
Pruned High Forgetting Model Accuracy: 12.38%
Post-Pruning Retraining...
Initial Test Accuracy: 27.92%
Post-Pruning Training Epoch [1/10]: Loss: 0.9853, Train Acc: 65.71%, Test Acc: 70.34%
Post-Pruning Training Epoch [2/10]: Loss: 0.6712, Train Acc: 76.51%, Test Acc: 72.88%
Post-Pruning Training Epoch [3/10]: Loss: 0.5353, Train Acc: 81.30%, Test Acc: 73.31%
Post-Pruning Training Epoch [4/10]: Loss: 0.4280, Train Acc: 85.03%, Test Acc: 75.30%
Post-Pruning Training Epoch [5/10]: Loss: 0.3296, Train Acc: 88.52%, Test Acc: 75.29%
Post-Pruning Training Epoch [6/10]: Loss: 0.2596, Train Acc: 90.73%, Test Acc: 76.38%
Post-Pruning Training Epoch [7/10]: Loss: 0.1991, Train Acc: 93.11%, Test Acc: 75.21%
Post-Pruning Training Epoch [8/10]: Loss: 0.1633, Train Acc: 94.24%, Test Acc: 75.48%
Post-Pruning Training Epoch [9/10]: Loss: 0.1354, Train Acc: 95.23%, Test Acc: 75.01%
Post-Pruning Training Epoch [10/10]: Loss: 0.1168, Train Acc: 96.00%, Test Acc: 75.87%
Initial Test Accuracy: 12.21%
Post-Pruning Training Epoch [1/10]: Loss: 1.1592, Train Acc: 58.84%, Test Acc: 65.28%
Post-Pruning Training Epoch [2/10]: Loss: 0.8668, Train Acc: 69.72%, Test Acc: 69.03%
Post-Pruning Training Epoch [3/10]: Loss: 0.7071, Train Acc: 75.64%, Test Acc: 74.90%
Post-Pruning Training Epoch [4/10]: Loss: 0.5898, Train Acc: 79.38%, Test Acc: 74.70%
Post-Pruning Training Epoch [5/10]: Loss: 0.4895, Train Acc: 82.96%, Test Acc: 75.20%
Post-Pruning Training Epoch [6/10]: Loss: 0.3988, Train Acc: 86.10%, Test Acc: 76.94%
Post-Pruning Training Epoch [7/10]: Loss: 0.3231, Train Acc: 88.62%, Test Acc: 76.48%
Post-Pruning Training Epoch [8/10]: Loss: 0.2523, Train Acc: 91.10%, Test Acc: 76.19%
Post-Pruning Training Epoch [9/10]: Loss: 0.2072, Train Acc: 92.75%, Test Acc: 75.72%
Post-Pruning Training Epoch [10/10]: Loss: 0.1674, Train Acc: 94.14%, Test Acc: 76.71%
Initial Test Accuracy: 12.38%
Post-Pruning Training Epoch [1/10]: Loss: 1.1649, Train Acc: 58.75%, Test Acc: 64.77%
Post-Pruning Training Epoch [2/10]: Loss: 0.8684, Train Acc: 69.73%, Test Acc: 70.36%
Post-Pruning Training Epoch [3/10]: Loss: 0.7138, Train Acc: 75.11%, Test Acc: 71.43%
Post-Pruning Training Epoch [4/10]: Loss: 0.5989, Train Acc: 79.15%, Test Acc: 72.86%
Post-Pruning Training Epoch [5/10]: Loss: 0.4952, Train Acc: 82.93%, Test Acc: 73.77%
Post-Pruning Training Epoch [6/10]: Loss: 0.4049, Train Acc: 85.87%, Test Acc: 74.23%
Post-Pruning Training Epoch [7/10]: Loss: 0.3224, Train Acc: 88.77%, Test Acc: 75.56%
Post-Pruning Training Epoch [8/10]: Loss: 0.2594, Train Acc: 90.89%, Test Acc: 76.36%
Post-Pruning Training Epoch [9/10]: Loss: 0.2036, Train Acc: 92.93%, Test Acc: 75.41%
Post-Pruning Training Epoch [10/10]: Loss: 0.1774, Train Acc: 93.80%, Test Acc: 77.17%
Post-Pruned Baseline Model Accuracy: 75.87%
Post-Pruned Low Forgetting Model Accuracy: 76.71%
Post-Pruned High Forgetting Model Accuracy: 77.17%
Accuracy results saved to results/resnet18/CIFAR10/dr0.1/pr0.8/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.1/pr0.8/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 10000 highest-forgetting and top 10000 lowest-forgetting samples.
Highest forgetting subset size: 10000, Lowest forgetting subset size: 10000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.7431, Accuracy: 36.76%
Epoch [2/10] complete: Loss: 1.3905, Accuracy: 49.80%
Epoch [3/10] complete: Loss: 1.1927, Accuracy: 57.08%
Epoch [4/10] complete: Loss: 1.0267, Accuracy: 63.75%
Epoch [5/10] complete: Loss: 0.8971, Accuracy: 67.99%
Epoch [6/10] complete: Loss: 0.7466, Accuracy: 73.83%
Epoch [7/10] complete: Loss: 0.6419, Accuracy: 77.57%
Epoch [8/10] complete: Loss: 0.5128, Accuracy: 82.23%
Epoch [9/10] complete: Loss: 0.4162, Accuracy: 85.11%
Epoch [10/10] complete: Loss: 0.3471, Accuracy: 87.73%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.7536, Accuracy: 37.06%
Epoch [2/10] complete: Loss: 1.3951, Accuracy: 49.36%
Epoch [3/10] complete: Loss: 1.2068, Accuracy: 56.86%
Epoch [4/10] complete: Loss: 1.0336, Accuracy: 63.62%
Epoch [5/10] complete: Loss: 0.8953, Accuracy: 68.62%
Epoch [6/10] complete: Loss: 0.7752, Accuracy: 72.60%
Epoch [7/10] complete: Loss: 0.6561, Accuracy: 77.22%
Epoch [8/10] complete: Loss: 0.5130, Accuracy: 82.20%
Epoch [9/10] complete: Loss: 0.4155, Accuracy: 85.58%
Epoch [10/10] complete: Loss: 0.3380, Accuracy: 88.37%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 58.55%
High Forgetting Model Accuracy: 58.93%
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.2/pr0.0/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 70.69%
Pruned Low Forgetting Model Accuracy: 58.55%
Pruned High Forgetting Model Accuracy: 58.93%
Post-Pruning Retraining...
Initial Test Accuracy: 70.69%
Post-Pruning Training Epoch [1/10]: Loss: 0.8856, Train Acc: 69.45%, Test Acc: 71.97%
Post-Pruning Training Epoch [2/10]: Loss: 0.6141, Train Acc: 78.19%, Test Acc: 72.86%
Post-Pruning Training Epoch [3/10]: Loss: 0.4856, Train Acc: 83.09%, Test Acc: 73.87%
Post-Pruning Training Epoch [4/10]: Loss: 0.3783, Train Acc: 86.79%, Test Acc: 74.43%
Post-Pruning Training Epoch [5/10]: Loss: 0.2858, Train Acc: 89.90%, Test Acc: 75.69%
Post-Pruning Training Epoch [6/10]: Loss: 0.2137, Train Acc: 92.54%, Test Acc: 74.76%
Post-Pruning Training Epoch [7/10]: Loss: 0.1754, Train Acc: 93.91%, Test Acc: 74.47%
Post-Pruning Training Epoch [8/10]: Loss: 0.1421, Train Acc: 94.92%, Test Acc: 75.00%
Post-Pruning Training Epoch [9/10]: Loss: 0.1183, Train Acc: 95.85%, Test Acc: 74.96%
Post-Pruning Training Epoch [10/10]: Loss: 0.1111, Train Acc: 96.10%, Test Acc: 74.84%
Initial Test Accuracy: 58.55%
Post-Pruning Training Epoch [1/10]: Loss: 0.9243, Train Acc: 67.90%, Test Acc: 67.55%
Post-Pruning Training Epoch [2/10]: Loss: 0.7325, Train Acc: 74.79%, Test Acc: 70.93%
Post-Pruning Training Epoch [3/10]: Loss: 0.6023, Train Acc: 79.16%, Test Acc: 74.43%
Post-Pruning Training Epoch [4/10]: Loss: 0.4902, Train Acc: 82.87%, Test Acc: 73.62%
Post-Pruning Training Epoch [5/10]: Loss: 0.3964, Train Acc: 86.04%, Test Acc: 74.66%
Post-Pruning Training Epoch [6/10]: Loss: 0.3114, Train Acc: 89.26%, Test Acc: 74.82%
Post-Pruning Training Epoch [7/10]: Loss: 0.2524, Train Acc: 91.23%, Test Acc: 74.99%
Post-Pruning Training Epoch [8/10]: Loss: 0.2031, Train Acc: 92.88%, Test Acc: 75.57%
Post-Pruning Training Epoch [9/10]: Loss: 0.1663, Train Acc: 94.20%, Test Acc: 74.33%
Post-Pruning Training Epoch [10/10]: Loss: 0.1517, Train Acc: 94.79%, Test Acc: 74.12%
Initial Test Accuracy: 58.93%
Post-Pruning Training Epoch [1/10]: Loss: 0.9250, Train Acc: 68.14%, Test Acc: 68.45%
Post-Pruning Training Epoch [2/10]: Loss: 0.7177, Train Acc: 75.31%, Test Acc: 70.98%
Post-Pruning Training Epoch [3/10]: Loss: 0.5895, Train Acc: 79.54%, Test Acc: 73.49%
Post-Pruning Training Epoch [4/10]: Loss: 0.4854, Train Acc: 83.14%, Test Acc: 73.31%
Post-Pruning Training Epoch [5/10]: Loss: 0.3894, Train Acc: 86.49%, Test Acc: 74.12%
Post-Pruning Training Epoch [6/10]: Loss: 0.3109, Train Acc: 89.03%, Test Acc: 74.18%
Post-Pruning Training Epoch [7/10]: Loss: 0.2487, Train Acc: 91.31%, Test Acc: 74.52%
Post-Pruning Training Epoch [8/10]: Loss: 0.1994, Train Acc: 93.00%, Test Acc: 74.40%
Post-Pruning Training Epoch [9/10]: Loss: 0.1683, Train Acc: 94.14%, Test Acc: 74.35%
Post-Pruning Training Epoch [10/10]: Loss: 0.1414, Train Acc: 95.09%, Test Acc: 75.22%
Post-Pruned Baseline Model Accuracy: 74.84%
Post-Pruned Low Forgetting Model Accuracy: 74.12%
Post-Pruned High Forgetting Model Accuracy: 75.22%
Accuracy results saved to results/resnet18/CIFAR10/dr0.2/pr0.0/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.2/pr0.0/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 10000 highest-forgetting and top 10000 lowest-forgetting samples.
Highest forgetting subset size: 10000, Lowest forgetting subset size: 10000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.7436, Accuracy: 36.99%
Epoch [2/10] complete: Loss: 1.4003, Accuracy: 49.69%
Epoch [3/10] complete: Loss: 1.2024, Accuracy: 56.72%
Epoch [4/10] complete: Loss: 1.0414, Accuracy: 63.90%
Epoch [5/10] complete: Loss: 0.9168, Accuracy: 67.41%
Epoch [6/10] complete: Loss: 0.7490, Accuracy: 73.83%
Epoch [7/10] complete: Loss: 0.6354, Accuracy: 77.66%
Epoch [8/10] complete: Loss: 0.5434, Accuracy: 81.06%
Epoch [9/10] complete: Loss: 0.4133, Accuracy: 85.52%
Epoch [10/10] complete: Loss: 0.3339, Accuracy: 88.35%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.7556, Accuracy: 36.66%
Epoch [2/10] complete: Loss: 1.4048, Accuracy: 48.96%
Epoch [3/10] complete: Loss: 1.2162, Accuracy: 56.51%
Epoch [4/10] complete: Loss: 1.0353, Accuracy: 63.29%
Epoch [5/10] complete: Loss: 0.8864, Accuracy: 69.13%
Epoch [6/10] complete: Loss: 0.7486, Accuracy: 73.14%
Epoch [7/10] complete: Loss: 0.6207, Accuracy: 78.28%
Epoch [8/10] complete: Loss: 0.4995, Accuracy: 82.26%
Epoch [9/10] complete: Loss: 0.4112, Accuracy: 85.82%
Epoch [10/10] complete: Loss: 0.3303, Accuracy: 88.62%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 59.22%
High Forgetting Model Accuracy: 58.38%
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.2/pr0.2/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 70.58%
Pruned Low Forgetting Model Accuracy: 59.18%
Pruned High Forgetting Model Accuracy: 58.41%
Post-Pruning Retraining...
Initial Test Accuracy: 70.58%
Post-Pruning Training Epoch [1/10]: Loss: 0.8995, Train Acc: 68.71%, Test Acc: 71.69%
Post-Pruning Training Epoch [2/10]: Loss: 0.6207, Train Acc: 78.24%, Test Acc: 72.21%
Post-Pruning Training Epoch [3/10]: Loss: 0.4908, Train Acc: 82.80%, Test Acc: 73.49%
Post-Pruning Training Epoch [4/10]: Loss: 0.3781, Train Acc: 86.73%, Test Acc: 74.43%
Post-Pruning Training Epoch [5/10]: Loss: 0.2809, Train Acc: 90.11%, Test Acc: 74.99%
Post-Pruning Training Epoch [6/10]: Loss: 0.2169, Train Acc: 92.43%, Test Acc: 74.04%
Post-Pruning Training Epoch [7/10]: Loss: 0.1658, Train Acc: 94.24%, Test Acc: 75.26%
Post-Pruning Training Epoch [8/10]: Loss: 0.1425, Train Acc: 95.02%, Test Acc: 74.52%
Post-Pruning Training Epoch [9/10]: Loss: 0.1184, Train Acc: 95.83%, Test Acc: 74.33%
Post-Pruning Training Epoch [10/10]: Loss: 0.1125, Train Acc: 96.01%, Test Acc: 75.02%
Initial Test Accuracy: 59.18%
Post-Pruning Training Epoch [1/10]: Loss: 0.9321, Train Acc: 67.93%, Test Acc: 66.54%
Post-Pruning Training Epoch [2/10]: Loss: 0.7324, Train Acc: 74.84%, Test Acc: 69.36%
Post-Pruning Training Epoch [3/10]: Loss: 0.6018, Train Acc: 79.27%, Test Acc: 72.27%
Post-Pruning Training Epoch [4/10]: Loss: 0.4890, Train Acc: 82.77%, Test Acc: 74.58%
Post-Pruning Training Epoch [5/10]: Loss: 0.3957, Train Acc: 86.15%, Test Acc: 74.45%
Post-Pruning Training Epoch [6/10]: Loss: 0.3110, Train Acc: 89.08%, Test Acc: 74.38%
Post-Pruning Training Epoch [7/10]: Loss: 0.2485, Train Acc: 91.27%, Test Acc: 75.50%
Post-Pruning Training Epoch [8/10]: Loss: 0.1993, Train Acc: 93.01%, Test Acc: 75.07%
Post-Pruning Training Epoch [9/10]: Loss: 0.1672, Train Acc: 94.17%, Test Acc: 74.97%
Post-Pruning Training Epoch [10/10]: Loss: 0.1480, Train Acc: 94.79%, Test Acc: 73.89%
Initial Test Accuracy: 58.41%
Post-Pruning Training Epoch [1/10]: Loss: 0.9323, Train Acc: 67.94%, Test Acc: 67.84%
Post-Pruning Training Epoch [2/10]: Loss: 0.7265, Train Acc: 74.77%, Test Acc: 71.19%
Post-Pruning Training Epoch [3/10]: Loss: 0.5942, Train Acc: 79.32%, Test Acc: 73.69%
Post-Pruning Training Epoch [4/10]: Loss: 0.4911, Train Acc: 82.95%, Test Acc: 73.20%
Post-Pruning Training Epoch [5/10]: Loss: 0.3930, Train Acc: 86.31%, Test Acc: 74.83%
Post-Pruning Training Epoch [6/10]: Loss: 0.3088, Train Acc: 89.11%, Test Acc: 74.32%
Post-Pruning Training Epoch [7/10]: Loss: 0.2495, Train Acc: 91.18%, Test Acc: 75.19%
Post-Pruning Training Epoch [8/10]: Loss: 0.1922, Train Acc: 93.22%, Test Acc: 75.24%
Post-Pruning Training Epoch [9/10]: Loss: 0.1769, Train Acc: 93.93%, Test Acc: 74.98%
Post-Pruning Training Epoch [10/10]: Loss: 0.1362, Train Acc: 95.21%, Test Acc: 74.85%
Post-Pruned Baseline Model Accuracy: 75.02%
Post-Pruned Low Forgetting Model Accuracy: 73.89%
Post-Pruned High Forgetting Model Accuracy: 74.85%
Accuracy results saved to results/resnet18/CIFAR10/dr0.2/pr0.2/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.2/pr0.2/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 10000 highest-forgetting and top 10000 lowest-forgetting samples.
Highest forgetting subset size: 10000, Lowest forgetting subset size: 10000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.7348, Accuracy: 37.23%
Epoch [2/10] complete: Loss: 1.3831, Accuracy: 49.77%
Epoch [3/10] complete: Loss: 1.1952, Accuracy: 57.27%
Epoch [4/10] complete: Loss: 1.0338, Accuracy: 63.20%
Epoch [5/10] complete: Loss: 0.9063, Accuracy: 68.17%
Epoch [6/10] complete: Loss: 0.7558, Accuracy: 73.66%
Epoch [7/10] complete: Loss: 0.6358, Accuracy: 77.99%
Epoch [8/10] complete: Loss: 0.5329, Accuracy: 81.43%
Epoch [9/10] complete: Loss: 0.4315, Accuracy: 84.88%
Epoch [10/10] complete: Loss: 0.3335, Accuracy: 88.55%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.7616, Accuracy: 37.10%
Epoch [2/10] complete: Loss: 1.4016, Accuracy: 49.60%
Epoch [3/10] complete: Loss: 1.2047, Accuracy: 56.98%
Epoch [4/10] complete: Loss: 1.0349, Accuracy: 63.52%
Epoch [5/10] complete: Loss: 0.8948, Accuracy: 68.70%
Epoch [6/10] complete: Loss: 0.7536, Accuracy: 73.46%
Epoch [7/10] complete: Loss: 0.6245, Accuracy: 78.31%
Epoch [8/10] complete: Loss: 0.5156, Accuracy: 82.26%
Epoch [9/10] complete: Loss: 0.4227, Accuracy: 85.16%
Epoch [10/10] complete: Loss: 0.3310, Accuracy: 88.47%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 59.91%
High Forgetting Model Accuracy: 59.96%
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.2/pr0.4/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 69.78%
Pruned Low Forgetting Model Accuracy: 56.72%
Pruned High Forgetting Model Accuracy: 59.49%
Post-Pruning Retraining...
Initial Test Accuracy: 69.78%
Post-Pruning Training Epoch [1/10]: Loss: 0.8939, Train Acc: 69.08%, Test Acc: 72.34%
Post-Pruning Training Epoch [2/10]: Loss: 0.6153, Train Acc: 78.59%, Test Acc: 73.37%
Post-Pruning Training Epoch [3/10]: Loss: 0.4833, Train Acc: 82.94%, Test Acc: 74.66%
Post-Pruning Training Epoch [4/10]: Loss: 0.3717, Train Acc: 87.07%, Test Acc: 75.23%
Post-Pruning Training Epoch [5/10]: Loss: 0.2784, Train Acc: 90.14%, Test Acc: 75.61%
Post-Pruning Training Epoch [6/10]: Loss: 0.2136, Train Acc: 92.46%, Test Acc: 75.17%
Post-Pruning Training Epoch [7/10]: Loss: 0.1703, Train Acc: 94.10%, Test Acc: 75.20%
Post-Pruning Training Epoch [8/10]: Loss: 0.1387, Train Acc: 95.11%, Test Acc: 74.85%
Post-Pruning Training Epoch [9/10]: Loss: 0.1153, Train Acc: 95.94%, Test Acc: 74.93%
Post-Pruning Training Epoch [10/10]: Loss: 0.1093, Train Acc: 96.20%, Test Acc: 75.08%
Initial Test Accuracy: 56.72%
Post-Pruning Training Epoch [1/10]: Loss: 0.9457, Train Acc: 67.45%, Test Acc: 67.52%
Post-Pruning Training Epoch [2/10]: Loss: 0.7360, Train Acc: 74.49%, Test Acc: 71.19%
Post-Pruning Training Epoch [3/10]: Loss: 0.6043, Train Acc: 79.27%, Test Acc: 73.64%
Post-Pruning Training Epoch [4/10]: Loss: 0.4994, Train Acc: 82.74%, Test Acc: 73.98%
Post-Pruning Training Epoch [5/10]: Loss: 0.3986, Train Acc: 86.01%, Test Acc: 74.97%
Post-Pruning Training Epoch [6/10]: Loss: 0.3253, Train Acc: 88.69%, Test Acc: 75.08%
Post-Pruning Training Epoch [7/10]: Loss: 0.2527, Train Acc: 91.26%, Test Acc: 74.96%
Post-Pruning Training Epoch [8/10]: Loss: 0.2052, Train Acc: 92.84%, Test Acc: 74.50%
Post-Pruning Training Epoch [9/10]: Loss: 0.1665, Train Acc: 94.19%, Test Acc: 75.63%
Post-Pruning Training Epoch [10/10]: Loss: 0.1421, Train Acc: 95.01%, Test Acc: 74.81%
Initial Test Accuracy: 59.49%
Post-Pruning Training Epoch [1/10]: Loss: 0.9348, Train Acc: 67.71%, Test Acc: 66.91%
Post-Pruning Training Epoch [2/10]: Loss: 0.7352, Train Acc: 74.80%, Test Acc: 72.17%
Post-Pruning Training Epoch [3/10]: Loss: 0.6043, Train Acc: 79.11%, Test Acc: 73.24%
Post-Pruning Training Epoch [4/10]: Loss: 0.4963, Train Acc: 82.74%, Test Acc: 73.23%
Post-Pruning Training Epoch [5/10]: Loss: 0.4000, Train Acc: 86.24%, Test Acc: 74.39%
Post-Pruning Training Epoch [6/10]: Loss: 0.3119, Train Acc: 89.08%, Test Acc: 75.07%
Post-Pruning Training Epoch [7/10]: Loss: 0.2513, Train Acc: 91.16%, Test Acc: 74.76%
Post-Pruning Training Epoch [8/10]: Loss: 0.2023, Train Acc: 92.88%, Test Acc: 74.63%
Post-Pruning Training Epoch [9/10]: Loss: 0.1693, Train Acc: 94.05%, Test Acc: 74.01%
Post-Pruning Training Epoch [10/10]: Loss: 0.1475, Train Acc: 94.86%, Test Acc: 74.98%
Post-Pruned Baseline Model Accuracy: 75.08%
Post-Pruned Low Forgetting Model Accuracy: 74.81%
Post-Pruned High Forgetting Model Accuracy: 74.98%
Accuracy results saved to results/resnet18/CIFAR10/dr0.2/pr0.4/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.2/pr0.4/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 10000 highest-forgetting and top 10000 lowest-forgetting samples.
Highest forgetting subset size: 10000, Lowest forgetting subset size: 10000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.7475, Accuracy: 37.02%
Epoch [2/10] complete: Loss: 1.4097, Accuracy: 49.03%
Epoch [3/10] complete: Loss: 1.2048, Accuracy: 57.18%
Epoch [4/10] complete: Loss: 1.0531, Accuracy: 62.57%
Epoch [5/10] complete: Loss: 0.9137, Accuracy: 67.67%
Epoch [6/10] complete: Loss: 0.7733, Accuracy: 72.61%
Epoch [7/10] complete: Loss: 0.6607, Accuracy: 76.86%
Epoch [8/10] complete: Loss: 0.5391, Accuracy: 81.45%
Epoch [9/10] complete: Loss: 0.4163, Accuracy: 85.62%
Epoch [10/10] complete: Loss: 0.3284, Accuracy: 88.56%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.7502, Accuracy: 37.27%
Epoch [2/10] complete: Loss: 1.4001, Accuracy: 49.52%
Epoch [3/10] complete: Loss: 1.2105, Accuracy: 56.65%
Epoch [4/10] complete: Loss: 1.0575, Accuracy: 62.87%
Epoch [5/10] complete: Loss: 0.9075, Accuracy: 68.20%
Epoch [6/10] complete: Loss: 0.7841, Accuracy: 72.15%
Epoch [7/10] complete: Loss: 0.6349, Accuracy: 78.08%
Epoch [8/10] complete: Loss: 0.5133, Accuracy: 81.61%
Epoch [9/10] complete: Loss: 0.4206, Accuracy: 85.53%
Epoch [10/10] complete: Loss: 0.3332, Accuracy: 88.72%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 58.74%
High Forgetting Model Accuracy: 60.58%
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.2/pr0.6/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 63.76%
Pruned Low Forgetting Model Accuracy: 31.62%
Pruned High Forgetting Model Accuracy: 40.42%
Post-Pruning Retraining...
Initial Test Accuracy: 63.76%
Post-Pruning Training Epoch [1/10]: Loss: 0.9080, Train Acc: 68.61%, Test Acc: 71.89%
Post-Pruning Training Epoch [2/10]: Loss: 0.6278, Train Acc: 78.09%, Test Acc: 72.32%
Post-Pruning Training Epoch [3/10]: Loss: 0.4924, Train Acc: 82.75%, Test Acc: 73.83%
Post-Pruning Training Epoch [4/10]: Loss: 0.3840, Train Acc: 86.62%, Test Acc: 74.24%
Post-Pruning Training Epoch [5/10]: Loss: 0.2919, Train Acc: 89.70%, Test Acc: 75.88%
Post-Pruning Training Epoch [6/10]: Loss: 0.2189, Train Acc: 92.25%, Test Acc: 75.50%
Post-Pruning Training Epoch [7/10]: Loss: 0.1756, Train Acc: 93.87%, Test Acc: 75.09%
Post-Pruning Training Epoch [8/10]: Loss: 0.1458, Train Acc: 94.98%, Test Acc: 74.48%
Post-Pruning Training Epoch [9/10]: Loss: 0.1187, Train Acc: 95.86%, Test Acc: 75.03%
Post-Pruning Training Epoch [10/10]: Loss: 0.1071, Train Acc: 96.23%, Test Acc: 75.74%
Initial Test Accuracy: 31.62%
Post-Pruning Training Epoch [1/10]: Loss: 0.9599, Train Acc: 66.75%, Test Acc: 67.61%
Post-Pruning Training Epoch [2/10]: Loss: 0.7500, Train Acc: 73.96%, Test Acc: 69.15%
Post-Pruning Training Epoch [3/10]: Loss: 0.6141, Train Acc: 78.83%, Test Acc: 74.18%
Post-Pruning Training Epoch [4/10]: Loss: 0.5024, Train Acc: 82.58%, Test Acc: 73.98%
Post-Pruning Training Epoch [5/10]: Loss: 0.4052, Train Acc: 85.89%, Test Acc: 75.32%
Post-Pruning Training Epoch [6/10]: Loss: 0.3257, Train Acc: 88.78%, Test Acc: 76.39%
Post-Pruning Training Epoch [7/10]: Loss: 0.2586, Train Acc: 90.94%, Test Acc: 75.20%
Post-Pruning Training Epoch [8/10]: Loss: 0.2079, Train Acc: 92.75%, Test Acc: 74.62%
Post-Pruning Training Epoch [9/10]: Loss: 0.1707, Train Acc: 94.07%, Test Acc: 74.64%
Post-Pruning Training Epoch [10/10]: Loss: 0.1460, Train Acc: 94.92%, Test Acc: 75.98%
Initial Test Accuracy: 40.42%
Post-Pruning Training Epoch [1/10]: Loss: 0.9696, Train Acc: 66.43%, Test Acc: 67.84%
Post-Pruning Training Epoch [2/10]: Loss: 0.7453, Train Acc: 74.31%, Test Acc: 71.58%
Post-Pruning Training Epoch [3/10]: Loss: 0.6128, Train Acc: 78.77%, Test Acc: 72.40%
Post-Pruning Training Epoch [4/10]: Loss: 0.5068, Train Acc: 82.36%, Test Acc: 72.66%
Post-Pruning Training Epoch [5/10]: Loss: 0.4084, Train Acc: 86.04%, Test Acc: 74.67%
Post-Pruning Training Epoch [6/10]: Loss: 0.3259, Train Acc: 88.67%, Test Acc: 75.03%
Post-Pruning Training Epoch [7/10]: Loss: 0.2510, Train Acc: 91.33%, Test Acc: 74.24%
Post-Pruning Training Epoch [8/10]: Loss: 0.2107, Train Acc: 92.52%, Test Acc: 74.83%
Post-Pruning Training Epoch [9/10]: Loss: 0.1736, Train Acc: 94.04%, Test Acc: 74.46%
Post-Pruning Training Epoch [10/10]: Loss: 0.1491, Train Acc: 94.79%, Test Acc: 75.54%
Post-Pruned Baseline Model Accuracy: 75.74%
Post-Pruned Low Forgetting Model Accuracy: 75.98%
Post-Pruned High Forgetting Model Accuracy: 75.54%
Accuracy results saved to results/resnet18/CIFAR10/dr0.2/pr0.6/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.2/pr0.6/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 10000 highest-forgetting and top 10000 lowest-forgetting samples.
Highest forgetting subset size: 10000, Lowest forgetting subset size: 10000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.7418, Accuracy: 37.05%
Epoch [2/10] complete: Loss: 1.3910, Accuracy: 49.67%
Epoch [3/10] complete: Loss: 1.1886, Accuracy: 57.15%
Epoch [4/10] complete: Loss: 1.0262, Accuracy: 63.54%
Epoch [5/10] complete: Loss: 0.8957, Accuracy: 68.61%
Epoch [6/10] complete: Loss: 0.7506, Accuracy: 73.03%
Epoch [7/10] complete: Loss: 0.6156, Accuracy: 78.49%
Epoch [8/10] complete: Loss: 0.5191, Accuracy: 82.06%
Epoch [9/10] complete: Loss: 0.3982, Accuracy: 86.17%
Epoch [10/10] complete: Loss: 0.3352, Accuracy: 88.61%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.7405, Accuracy: 37.35%
Epoch [2/10] complete: Loss: 1.3966, Accuracy: 49.57%
Epoch [3/10] complete: Loss: 1.2123, Accuracy: 56.96%
Epoch [4/10] complete: Loss: 1.0436, Accuracy: 62.95%
Epoch [5/10] complete: Loss: 0.9045, Accuracy: 67.82%
Epoch [6/10] complete: Loss: 0.7756, Accuracy: 72.33%
Epoch [7/10] complete: Loss: 0.6403, Accuracy: 77.26%
Epoch [8/10] complete: Loss: 0.5099, Accuracy: 82.11%
Epoch [9/10] complete: Loss: 0.4193, Accuracy: 85.58%
Epoch [10/10] complete: Loss: 0.3212, Accuracy: 88.87%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 58.96%
High Forgetting Model Accuracy: 61.02%
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.2/pr0.8/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 27.92%
Pruned Low Forgetting Model Accuracy: 10.04%
Pruned High Forgetting Model Accuracy: 11.59%
Post-Pruning Retraining...
Initial Test Accuracy: 27.92%
Post-Pruning Training Epoch [1/10]: Loss: 0.9842, Train Acc: 65.54%, Test Acc: 70.61%
Post-Pruning Training Epoch [2/10]: Loss: 0.6705, Train Acc: 76.48%, Test Acc: 72.45%
Post-Pruning Training Epoch [3/10]: Loss: 0.5391, Train Acc: 81.21%, Test Acc: 72.70%
Post-Pruning Training Epoch [4/10]: Loss: 0.4303, Train Acc: 85.04%, Test Acc: 75.23%
Post-Pruning Training Epoch [5/10]: Loss: 0.3335, Train Acc: 88.25%, Test Acc: 76.09%
Post-Pruning Training Epoch [6/10]: Loss: 0.2566, Train Acc: 90.96%, Test Acc: 75.38%
Post-Pruning Training Epoch [7/10]: Loss: 0.2003, Train Acc: 92.98%, Test Acc: 74.80%
Post-Pruning Training Epoch [8/10]: Loss: 0.1598, Train Acc: 94.51%, Test Acc: 75.81%
Post-Pruning Training Epoch [9/10]: Loss: 0.1309, Train Acc: 95.34%, Test Acc: 74.68%
Post-Pruning Training Epoch [10/10]: Loss: 0.1170, Train Acc: 95.85%, Test Acc: 75.25%
Initial Test Accuracy: 10.04%
Post-Pruning Training Epoch [1/10]: Loss: 1.0379, Train Acc: 63.74%, Test Acc: 66.45%
Post-Pruning Training Epoch [2/10]: Loss: 0.7893, Train Acc: 72.57%, Test Acc: 69.32%
Post-Pruning Training Epoch [3/10]: Loss: 0.6451, Train Acc: 77.53%, Test Acc: 74.56%
Post-Pruning Training Epoch [4/10]: Loss: 0.5299, Train Acc: 81.54%, Test Acc: 75.20%
Post-Pruning Training Epoch [5/10]: Loss: 0.4316, Train Acc: 85.11%, Test Acc: 74.94%
Post-Pruning Training Epoch [6/10]: Loss: 0.3453, Train Acc: 87.85%, Test Acc: 75.67%
Post-Pruning Training Epoch [7/10]: Loss: 0.2713, Train Acc: 90.51%, Test Acc: 75.90%
Post-Pruning Training Epoch [8/10]: Loss: 0.2227, Train Acc: 92.22%, Test Acc: 75.40%
Post-Pruning Training Epoch [9/10]: Loss: 0.1763, Train Acc: 93.77%, Test Acc: 76.00%
Post-Pruning Training Epoch [10/10]: Loss: 0.1494, Train Acc: 94.77%, Test Acc: 75.35%
Initial Test Accuracy: 11.59%
Post-Pruning Training Epoch [1/10]: Loss: 1.0263, Train Acc: 64.30%, Test Acc: 63.53%
Post-Pruning Training Epoch [2/10]: Loss: 0.7754, Train Acc: 73.27%, Test Acc: 69.93%
Post-Pruning Training Epoch [3/10]: Loss: 0.6396, Train Acc: 77.81%, Test Acc: 74.38%
Post-Pruning Training Epoch [4/10]: Loss: 0.5323, Train Acc: 81.57%, Test Acc: 74.01%
Post-Pruning Training Epoch [5/10]: Loss: 0.4321, Train Acc: 84.93%, Test Acc: 73.43%
Post-Pruning Training Epoch [6/10]: Loss: 0.3478, Train Acc: 87.79%, Test Acc: 74.42%
Post-Pruning Training Epoch [7/10]: Loss: 0.2748, Train Acc: 90.29%, Test Acc: 75.86%
Post-Pruning Training Epoch [8/10]: Loss: 0.2267, Train Acc: 91.99%, Test Acc: 76.85%
Post-Pruning Training Epoch [9/10]: Loss: 0.1781, Train Acc: 93.76%, Test Acc: 75.50%
Post-Pruning Training Epoch [10/10]: Loss: 0.1485, Train Acc: 94.81%, Test Acc: 75.66%
Post-Pruned Baseline Model Accuracy: 75.25%
Post-Pruned Low Forgetting Model Accuracy: 75.35%
Post-Pruned High Forgetting Model Accuracy: 75.66%
Accuracy results saved to results/resnet18/CIFAR10/dr0.2/pr0.8/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.2/pr0.8/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 15000 highest-forgetting and top 15000 lowest-forgetting samples.
Highest forgetting subset size: 15000, Lowest forgetting subset size: 15000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6357, Accuracy: 40.73%
Epoch [2/10] complete: Loss: 1.2780, Accuracy: 53.62%
Epoch [3/10] complete: Loss: 1.0830, Accuracy: 61.69%
Epoch [4/10] complete: Loss: 0.9269, Accuracy: 67.35%
Epoch [5/10] complete: Loss: 0.8070, Accuracy: 71.86%
Epoch [6/10] complete: Loss: 0.6774, Accuracy: 76.33%
Epoch [7/10] complete: Loss: 0.5719, Accuracy: 79.81%
Epoch [8/10] complete: Loss: 0.4609, Accuracy: 83.56%
Epoch [9/10] complete: Loss: 0.3848, Accuracy: 86.70%
Epoch [10/10] complete: Loss: 0.3016, Accuracy: 89.71%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6837, Accuracy: 39.85%
Epoch [2/10] complete: Loss: 1.3346, Accuracy: 52.05%
Epoch [3/10] complete: Loss: 1.1261, Accuracy: 60.25%
Epoch [4/10] complete: Loss: 0.9463, Accuracy: 66.41%
Epoch [5/10] complete: Loss: 0.8240, Accuracy: 71.23%
Epoch [6/10] complete: Loss: 0.6770, Accuracy: 76.43%
Epoch [7/10] complete: Loss: 0.5705, Accuracy: 80.05%
Epoch [8/10] complete: Loss: 0.4709, Accuracy: 83.45%
Epoch [9/10] complete: Loss: 0.3762, Accuracy: 87.13%
Epoch [10/10] complete: Loss: 0.2987, Accuracy: 89.74%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 65.74%
High Forgetting Model Accuracy: 63.98%
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.3/pr0.0/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 70.69%
Pruned Low Forgetting Model Accuracy: 65.74%
Pruned High Forgetting Model Accuracy: 63.98%
Post-Pruning Retraining...
Initial Test Accuracy: 70.69%
Post-Pruning Training Epoch [1/10]: Loss: 0.8819, Train Acc: 69.61%, Test Acc: 71.17%
Post-Pruning Training Epoch [2/10]: Loss: 0.6076, Train Acc: 78.84%, Test Acc: 72.77%
Post-Pruning Training Epoch [3/10]: Loss: 0.4737, Train Acc: 83.53%, Test Acc: 74.17%
Post-Pruning Training Epoch [4/10]: Loss: 0.3664, Train Acc: 86.99%, Test Acc: 75.04%
Post-Pruning Training Epoch [5/10]: Loss: 0.2747, Train Acc: 90.25%, Test Acc: 74.02%
Post-Pruning Training Epoch [6/10]: Loss: 0.2049, Train Acc: 92.76%, Test Acc: 75.36%
Post-Pruning Training Epoch [7/10]: Loss: 0.1613, Train Acc: 94.35%, Test Acc: 74.53%
Post-Pruning Training Epoch [8/10]: Loss: 0.1368, Train Acc: 95.25%, Test Acc: 75.75%
Post-Pruning Training Epoch [9/10]: Loss: 0.1173, Train Acc: 95.94%, Test Acc: 74.82%
Post-Pruning Training Epoch [10/10]: Loss: 0.1048, Train Acc: 96.23%, Test Acc: 75.39%
Initial Test Accuracy: 65.74%
Post-Pruning Training Epoch [1/10]: Loss: 0.8018, Train Acc: 72.72%, Test Acc: 70.52%
Post-Pruning Training Epoch [2/10]: Loss: 0.6314, Train Acc: 78.43%, Test Acc: 72.38%
Post-Pruning Training Epoch [3/10]: Loss: 0.5118, Train Acc: 82.45%, Test Acc: 74.41%
Post-Pruning Training Epoch [4/10]: Loss: 0.4107, Train Acc: 85.87%, Test Acc: 73.85%
Post-Pruning Training Epoch [5/10]: Loss: 0.3237, Train Acc: 88.69%, Test Acc: 74.34%
Post-Pruning Training Epoch [6/10]: Loss: 0.2577, Train Acc: 91.07%, Test Acc: 74.74%
Post-Pruning Training Epoch [7/10]: Loss: 0.2157, Train Acc: 92.62%, Test Acc: 74.64%
Post-Pruning Training Epoch [8/10]: Loss: 0.1655, Train Acc: 94.31%, Test Acc: 74.77%
Post-Pruning Training Epoch [9/10]: Loss: 0.1436, Train Acc: 95.01%, Test Acc: 74.94%
Post-Pruning Training Epoch [10/10]: Loss: 0.1270, Train Acc: 95.51%, Test Acc: 74.63%
Initial Test Accuracy: 63.98%
Post-Pruning Training Epoch [1/10]: Loss: 0.7917, Train Acc: 73.31%, Test Acc: 69.38%
Post-Pruning Training Epoch [2/10]: Loss: 0.6222, Train Acc: 78.65%, Test Acc: 72.35%
Post-Pruning Training Epoch [3/10]: Loss: 0.5004, Train Acc: 82.61%, Test Acc: 73.80%
Post-Pruning Training Epoch [4/10]: Loss: 0.4010, Train Acc: 86.16%, Test Acc: 73.73%
Post-Pruning Training Epoch [5/10]: Loss: 0.3196, Train Acc: 88.98%, Test Acc: 73.08%
Post-Pruning Training Epoch [6/10]: Loss: 0.2506, Train Acc: 91.17%, Test Acc: 74.12%
Post-Pruning Training Epoch [7/10]: Loss: 0.2041, Train Acc: 92.87%, Test Acc: 73.77%
Post-Pruning Training Epoch [8/10]: Loss: 0.1705, Train Acc: 94.06%, Test Acc: 74.71%
Post-Pruning Training Epoch [9/10]: Loss: 0.1382, Train Acc: 95.18%, Test Acc: 74.81%
Post-Pruning Training Epoch [10/10]: Loss: 0.1287, Train Acc: 95.44%, Test Acc: 74.51%
Post-Pruned Baseline Model Accuracy: 75.39%
Post-Pruned Low Forgetting Model Accuracy: 74.63%
Post-Pruned High Forgetting Model Accuracy: 74.51%
Accuracy results saved to results/resnet18/CIFAR10/dr0.3/pr0.0/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.3/pr0.0/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 15000 highest-forgetting and top 15000 lowest-forgetting samples.
Highest forgetting subset size: 15000, Lowest forgetting subset size: 15000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6647, Accuracy: 39.25%
Epoch [2/10] complete: Loss: 1.2950, Accuracy: 53.28%
Epoch [3/10] complete: Loss: 1.1088, Accuracy: 61.14%
Epoch [4/10] complete: Loss: 0.9384, Accuracy: 67.15%
Epoch [5/10] complete: Loss: 0.8152, Accuracy: 71.27%
Epoch [6/10] complete: Loss: 0.6912, Accuracy: 75.61%
Epoch [7/10] complete: Loss: 0.5596, Accuracy: 80.07%
Epoch [8/10] complete: Loss: 0.4729, Accuracy: 83.29%
Epoch [9/10] complete: Loss: 0.3750, Accuracy: 86.73%
Epoch [10/10] complete: Loss: 0.3120, Accuracy: 88.99%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6741, Accuracy: 40.21%
Epoch [2/10] complete: Loss: 1.3365, Accuracy: 51.75%
Epoch [3/10] complete: Loss: 1.1251, Accuracy: 59.97%
Epoch [4/10] complete: Loss: 0.9605, Accuracy: 65.79%
Epoch [5/10] complete: Loss: 0.8399, Accuracy: 70.58%
Epoch [6/10] complete: Loss: 0.7064, Accuracy: 75.25%
Epoch [7/10] complete: Loss: 0.5746, Accuracy: 79.89%
Epoch [8/10] complete: Loss: 0.4799, Accuracy: 83.27%
Epoch [9/10] complete: Loss: 0.3742, Accuracy: 86.96%
Epoch [10/10] complete: Loss: 0.3062, Accuracy: 89.13%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 65.97%
High Forgetting Model Accuracy: 62.92%
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.3/pr0.2/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 70.58%
Pruned Low Forgetting Model Accuracy: 66.42%
Pruned High Forgetting Model Accuracy: 63.21%
Post-Pruning Retraining...
Initial Test Accuracy: 70.58%
Post-Pruning Training Epoch [1/10]: Loss: 0.8965, Train Acc: 69.05%, Test Acc: 70.70%
Post-Pruning Training Epoch [2/10]: Loss: 0.6209, Train Acc: 78.13%, Test Acc: 72.62%
Post-Pruning Training Epoch [3/10]: Loss: 0.4913, Train Acc: 82.84%, Test Acc: 75.12%
Post-Pruning Training Epoch [4/10]: Loss: 0.3771, Train Acc: 86.82%, Test Acc: 74.89%
Post-Pruning Training Epoch [5/10]: Loss: 0.2806, Train Acc: 90.15%, Test Acc: 75.06%
Post-Pruning Training Epoch [6/10]: Loss: 0.2190, Train Acc: 92.27%, Test Acc: 75.50%
Post-Pruning Training Epoch [7/10]: Loss: 0.1717, Train Acc: 93.93%, Test Acc: 75.10%
Post-Pruning Training Epoch [8/10]: Loss: 0.1383, Train Acc: 95.17%, Test Acc: 75.00%
Post-Pruning Training Epoch [9/10]: Loss: 0.1162, Train Acc: 95.92%, Test Acc: 75.07%
Post-Pruning Training Epoch [10/10]: Loss: 0.1093, Train Acc: 96.23%, Test Acc: 75.91%
Initial Test Accuracy: 66.42%
Post-Pruning Training Epoch [1/10]: Loss: 0.8051, Train Acc: 72.73%, Test Acc: 68.40%
Post-Pruning Training Epoch [2/10]: Loss: 0.6403, Train Acc: 78.10%, Test Acc: 69.69%
Post-Pruning Training Epoch [3/10]: Loss: 0.5180, Train Acc: 82.20%, Test Acc: 74.49%
Post-Pruning Training Epoch [4/10]: Loss: 0.4132, Train Acc: 85.72%, Test Acc: 74.45%
Post-Pruning Training Epoch [5/10]: Loss: 0.3184, Train Acc: 88.93%, Test Acc: 74.05%
Post-Pruning Training Epoch [6/10]: Loss: 0.2585, Train Acc: 90.98%, Test Acc: 73.29%
Post-Pruning Training Epoch [7/10]: Loss: 0.2021, Train Acc: 92.92%, Test Acc: 74.31%
Post-Pruning Training Epoch [8/10]: Loss: 0.1682, Train Acc: 94.05%, Test Acc: 74.02%
Post-Pruning Training Epoch [9/10]: Loss: 0.1469, Train Acc: 95.00%, Test Acc: 75.41%
Post-Pruning Training Epoch [10/10]: Loss: 0.1265, Train Acc: 95.55%, Test Acc: 74.34%
Initial Test Accuracy: 63.21%
Post-Pruning Training Epoch [1/10]: Loss: 0.7956, Train Acc: 73.21%, Test Acc: 70.76%
Post-Pruning Training Epoch [2/10]: Loss: 0.6210, Train Acc: 78.86%, Test Acc: 72.05%
Post-Pruning Training Epoch [3/10]: Loss: 0.5053, Train Acc: 82.52%, Test Acc: 73.38%
Post-Pruning Training Epoch [4/10]: Loss: 0.4055, Train Acc: 85.99%, Test Acc: 74.02%
Post-Pruning Training Epoch [5/10]: Loss: 0.3238, Train Acc: 89.05%, Test Acc: 73.97%
Post-Pruning Training Epoch [6/10]: Loss: 0.2521, Train Acc: 91.24%, Test Acc: 73.99%
Post-Pruning Training Epoch [7/10]: Loss: 0.1983, Train Acc: 93.15%, Test Acc: 74.23%
Post-Pruning Training Epoch [8/10]: Loss: 0.1695, Train Acc: 94.10%, Test Acc: 74.64%
Post-Pruning Training Epoch [9/10]: Loss: 0.1442, Train Acc: 95.01%, Test Acc: 75.41%
Post-Pruning Training Epoch [10/10]: Loss: 0.1221, Train Acc: 95.85%, Test Acc: 75.11%
Post-Pruned Baseline Model Accuracy: 75.91%
Post-Pruned Low Forgetting Model Accuracy: 74.34%
Post-Pruned High Forgetting Model Accuracy: 75.11%
Accuracy results saved to results/resnet18/CIFAR10/dr0.3/pr0.2/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.3/pr0.2/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 15000 highest-forgetting and top 15000 lowest-forgetting samples.
Highest forgetting subset size: 15000, Lowest forgetting subset size: 15000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6660, Accuracy: 39.25%
Epoch [2/10] complete: Loss: 1.3008, Accuracy: 52.81%
Epoch [3/10] complete: Loss: 1.0986, Accuracy: 60.81%
Epoch [4/10] complete: Loss: 0.9518, Accuracy: 66.53%
Epoch [5/10] complete: Loss: 0.8289, Accuracy: 71.06%
Epoch [6/10] complete: Loss: 0.6962, Accuracy: 75.63%
Epoch [7/10] complete: Loss: 0.5792, Accuracy: 79.63%
Epoch [8/10] complete: Loss: 0.4663, Accuracy: 83.66%
Epoch [9/10] complete: Loss: 0.3828, Accuracy: 86.58%
Epoch [10/10] complete: Loss: 0.3072, Accuracy: 89.33%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6655, Accuracy: 39.96%
Epoch [2/10] complete: Loss: 1.3091, Accuracy: 52.74%
Epoch [3/10] complete: Loss: 1.1156, Accuracy: 59.96%
Epoch [4/10] complete: Loss: 0.9498, Accuracy: 66.85%
Epoch [5/10] complete: Loss: 0.8293, Accuracy: 70.73%
Epoch [6/10] complete: Loss: 0.7031, Accuracy: 75.34%
Epoch [7/10] complete: Loss: 0.5737, Accuracy: 80.15%
Epoch [8/10] complete: Loss: 0.4656, Accuracy: 83.53%
Epoch [9/10] complete: Loss: 0.3733, Accuracy: 87.09%
Epoch [10/10] complete: Loss: 0.3096, Accuracy: 89.15%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 63.27%
High Forgetting Model Accuracy: 65.33%
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.3/pr0.4/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 69.78%
Pruned Low Forgetting Model Accuracy: 60.34%
Pruned High Forgetting Model Accuracy: 62.68%
Post-Pruning Retraining...
Initial Test Accuracy: 69.78%
Post-Pruning Training Epoch [1/10]: Loss: 0.8930, Train Acc: 69.26%, Test Acc: 71.35%
Post-Pruning Training Epoch [2/10]: Loss: 0.6138, Train Acc: 78.42%, Test Acc: 71.68%
Post-Pruning Training Epoch [3/10]: Loss: 0.4819, Train Acc: 83.28%, Test Acc: 74.71%
Post-Pruning Training Epoch [4/10]: Loss: 0.3672, Train Acc: 87.05%, Test Acc: 74.64%
Post-Pruning Training Epoch [5/10]: Loss: 0.2806, Train Acc: 90.10%, Test Acc: 74.65%
Post-Pruning Training Epoch [6/10]: Loss: 0.2072, Train Acc: 92.65%, Test Acc: 75.18%
Post-Pruning Training Epoch [7/10]: Loss: 0.1678, Train Acc: 94.17%, Test Acc: 74.33%
Post-Pruning Training Epoch [8/10]: Loss: 0.1434, Train Acc: 94.86%, Test Acc: 74.75%
Post-Pruning Training Epoch [9/10]: Loss: 0.1181, Train Acc: 95.89%, Test Acc: 74.65%
Post-Pruning Training Epoch [10/10]: Loss: 0.1052, Train Acc: 96.35%, Test Acc: 74.32%
Initial Test Accuracy: 60.34%
Post-Pruning Training Epoch [1/10]: Loss: 0.8112, Train Acc: 72.39%, Test Acc: 69.09%
Post-Pruning Training Epoch [2/10]: Loss: 0.6403, Train Acc: 78.21%, Test Acc: 72.21%
Post-Pruning Training Epoch [3/10]: Loss: 0.5112, Train Acc: 82.44%, Test Acc: 73.66%
Post-Pruning Training Epoch [4/10]: Loss: 0.4110, Train Acc: 85.85%, Test Acc: 73.16%
Post-Pruning Training Epoch [5/10]: Loss: 0.3211, Train Acc: 88.92%, Test Acc: 74.13%
Post-Pruning Training Epoch [6/10]: Loss: 0.2575, Train Acc: 91.14%, Test Acc: 75.18%
Post-Pruning Training Epoch [7/10]: Loss: 0.2014, Train Acc: 92.94%, Test Acc: 74.41%
Post-Pruning Training Epoch [8/10]: Loss: 0.1758, Train Acc: 94.01%, Test Acc: 74.54%
Post-Pruning Training Epoch [9/10]: Loss: 0.1440, Train Acc: 95.13%, Test Acc: 74.08%
Post-Pruning Training Epoch [10/10]: Loss: 0.1301, Train Acc: 95.42%, Test Acc: 75.04%
Initial Test Accuracy: 62.68%
Post-Pruning Training Epoch [1/10]: Loss: 0.8028, Train Acc: 72.90%, Test Acc: 69.71%
Post-Pruning Training Epoch [2/10]: Loss: 0.6279, Train Acc: 78.45%, Test Acc: 71.45%
Post-Pruning Training Epoch [3/10]: Loss: 0.5052, Train Acc: 82.70%, Test Acc: 72.16%
Post-Pruning Training Epoch [4/10]: Loss: 0.4049, Train Acc: 85.92%, Test Acc: 73.62%
Post-Pruning Training Epoch [5/10]: Loss: 0.3250, Train Acc: 88.72%, Test Acc: 73.73%
Post-Pruning Training Epoch [6/10]: Loss: 0.2490, Train Acc: 91.29%, Test Acc: 74.07%
Post-Pruning Training Epoch [7/10]: Loss: 0.2050, Train Acc: 92.94%, Test Acc: 74.19%
Post-Pruning Training Epoch [8/10]: Loss: 0.1715, Train Acc: 93.96%, Test Acc: 75.02%
Post-Pruning Training Epoch [9/10]: Loss: 0.1472, Train Acc: 94.73%, Test Acc: 74.38%
Post-Pruning Training Epoch [10/10]: Loss: 0.1239, Train Acc: 95.65%, Test Acc: 74.11%
Post-Pruned Baseline Model Accuracy: 74.32%
Post-Pruned Low Forgetting Model Accuracy: 75.04%
Post-Pruned High Forgetting Model Accuracy: 74.11%
Accuracy results saved to results/resnet18/CIFAR10/dr0.3/pr0.4/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.3/pr0.4/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 15000 highest-forgetting and top 15000 lowest-forgetting samples.
Highest forgetting subset size: 15000, Lowest forgetting subset size: 15000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6639, Accuracy: 39.90%
Epoch [2/10] complete: Loss: 1.3009, Accuracy: 52.91%
Epoch [3/10] complete: Loss: 1.1006, Accuracy: 60.99%
Epoch [4/10] complete: Loss: 0.9474, Accuracy: 66.45%
Epoch [5/10] complete: Loss: 0.8249, Accuracy: 71.01%
Epoch [6/10] complete: Loss: 0.6899, Accuracy: 75.66%
Epoch [7/10] complete: Loss: 0.5811, Accuracy: 79.71%
Epoch [8/10] complete: Loss: 0.4763, Accuracy: 83.00%
Epoch [9/10] complete: Loss: 0.3836, Accuracy: 86.71%
Epoch [10/10] complete: Loss: 0.3162, Accuracy: 88.89%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6774, Accuracy: 39.93%
Epoch [2/10] complete: Loss: 1.3185, Accuracy: 52.44%
Epoch [3/10] complete: Loss: 1.1124, Accuracy: 60.57%
Epoch [4/10] complete: Loss: 0.9451, Accuracy: 66.25%
Epoch [5/10] complete: Loss: 0.8180, Accuracy: 71.27%
Epoch [6/10] complete: Loss: 0.6874, Accuracy: 75.71%
Epoch [7/10] complete: Loss: 0.5681, Accuracy: 80.45%
Epoch [8/10] complete: Loss: 0.4715, Accuracy: 83.51%
Epoch [9/10] complete: Loss: 0.3773, Accuracy: 86.99%
Epoch [10/10] complete: Loss: 0.3238, Accuracy: 88.52%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 65.22%
High Forgetting Model Accuracy: 63.93%
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.3/pr0.6/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 63.76%
Pruned Low Forgetting Model Accuracy: 47.00%
Pruned High Forgetting Model Accuracy: 47.91%
Post-Pruning Retraining...
Initial Test Accuracy: 63.76%
Post-Pruning Training Epoch [1/10]: Loss: 0.9070, Train Acc: 68.57%, Test Acc: 71.01%
Post-Pruning Training Epoch [2/10]: Loss: 0.6234, Train Acc: 78.13%, Test Acc: 72.06%
Post-Pruning Training Epoch [3/10]: Loss: 0.4899, Train Acc: 82.85%, Test Acc: 73.67%
Post-Pruning Training Epoch [4/10]: Loss: 0.3722, Train Acc: 86.99%, Test Acc: 75.30%
Post-Pruning Training Epoch [5/10]: Loss: 0.2863, Train Acc: 89.97%, Test Acc: 75.08%
Post-Pruning Training Epoch [6/10]: Loss: 0.2177, Train Acc: 92.39%, Test Acc: 75.41%
Post-Pruning Training Epoch [7/10]: Loss: 0.1720, Train Acc: 93.90%, Test Acc: 75.19%
Post-Pruning Training Epoch [8/10]: Loss: 0.1427, Train Acc: 94.92%, Test Acc: 74.84%
Post-Pruning Training Epoch [9/10]: Loss: 0.1231, Train Acc: 95.69%, Test Acc: 75.03%
Post-Pruning Training Epoch [10/10]: Loss: 0.1091, Train Acc: 96.17%, Test Acc: 75.13%
Initial Test Accuracy: 47.00%
Post-Pruning Training Epoch [1/10]: Loss: 0.8361, Train Acc: 71.45%, Test Acc: 70.28%
Post-Pruning Training Epoch [2/10]: Loss: 0.6548, Train Acc: 77.56%, Test Acc: 71.63%
Post-Pruning Training Epoch [3/10]: Loss: 0.5277, Train Acc: 81.94%, Test Acc: 74.60%
Post-Pruning Training Epoch [4/10]: Loss: 0.4292, Train Acc: 85.18%, Test Acc: 73.88%
Post-Pruning Training Epoch [5/10]: Loss: 0.3389, Train Acc: 88.19%, Test Acc: 74.94%
Post-Pruning Training Epoch [6/10]: Loss: 0.2674, Train Acc: 90.75%, Test Acc: 75.15%
Post-Pruning Training Epoch [7/10]: Loss: 0.2155, Train Acc: 92.50%, Test Acc: 74.58%
Post-Pruning Training Epoch [8/10]: Loss: 0.1766, Train Acc: 93.86%, Test Acc: 75.02%
Post-Pruning Training Epoch [9/10]: Loss: 0.1485, Train Acc: 94.87%, Test Acc: 73.95%
Post-Pruning Training Epoch [10/10]: Loss: 0.1394, Train Acc: 95.16%, Test Acc: 75.83%
Initial Test Accuracy: 47.91%
Post-Pruning Training Epoch [1/10]: Loss: 0.8367, Train Acc: 71.37%, Test Acc: 69.42%
Post-Pruning Training Epoch [2/10]: Loss: 0.6535, Train Acc: 77.42%, Test Acc: 72.14%
Post-Pruning Training Epoch [3/10]: Loss: 0.5247, Train Acc: 81.75%, Test Acc: 74.45%
Post-Pruning Training Epoch [4/10]: Loss: 0.4281, Train Acc: 85.19%, Test Acc: 73.34%
Post-Pruning Training Epoch [5/10]: Loss: 0.3428, Train Acc: 88.01%, Test Acc: 74.64%
Post-Pruning Training Epoch [6/10]: Loss: 0.2662, Train Acc: 90.76%, Test Acc: 74.16%
Post-Pruning Training Epoch [7/10]: Loss: 0.2150, Train Acc: 92.53%, Test Acc: 74.91%
Post-Pruning Training Epoch [8/10]: Loss: 0.1788, Train Acc: 93.86%, Test Acc: 75.52%
Post-Pruning Training Epoch [9/10]: Loss: 0.1542, Train Acc: 94.61%, Test Acc: 75.75%
Post-Pruning Training Epoch [10/10]: Loss: 0.1281, Train Acc: 95.46%, Test Acc: 74.51%
Post-Pruned Baseline Model Accuracy: 75.13%
Post-Pruned Low Forgetting Model Accuracy: 75.83%
Post-Pruned High Forgetting Model Accuracy: 74.51%
Accuracy results saved to results/resnet18/CIFAR10/dr0.3/pr0.6/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.3/pr0.6/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 15000 highest-forgetting and top 15000 lowest-forgetting samples.
Highest forgetting subset size: 15000, Lowest forgetting subset size: 15000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6451, Accuracy: 40.65%
Epoch [2/10] complete: Loss: 1.2754, Accuracy: 54.05%
Epoch [3/10] complete: Loss: 1.0725, Accuracy: 62.46%
Epoch [4/10] complete: Loss: 0.9231, Accuracy: 67.45%
Epoch [5/10] complete: Loss: 0.8156, Accuracy: 71.64%
Epoch [6/10] complete: Loss: 0.6779, Accuracy: 76.16%
Epoch [7/10] complete: Loss: 0.5617, Accuracy: 80.31%
Epoch [8/10] complete: Loss: 0.4576, Accuracy: 83.84%
Epoch [9/10] complete: Loss: 0.3846, Accuracy: 86.39%
Epoch [10/10] complete: Loss: 0.3072, Accuracy: 89.42%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6732, Accuracy: 40.31%
Epoch [2/10] complete: Loss: 1.3352, Accuracy: 52.03%
Epoch [3/10] complete: Loss: 1.1262, Accuracy: 59.86%
Epoch [4/10] complete: Loss: 0.9535, Accuracy: 66.15%
Epoch [5/10] complete: Loss: 0.8295, Accuracy: 70.67%
Epoch [6/10] complete: Loss: 0.7062, Accuracy: 75.22%
Epoch [7/10] complete: Loss: 0.5642, Accuracy: 80.71%
Epoch [8/10] complete: Loss: 0.4785, Accuracy: 83.09%
Epoch [9/10] complete: Loss: 0.3762, Accuracy: 86.81%
Epoch [10/10] complete: Loss: 0.3092, Accuracy: 89.17%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 65.07%
High Forgetting Model Accuracy: 64.02%
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.3/pr0.8/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 27.92%
Pruned Low Forgetting Model Accuracy: 12.23%
Pruned High Forgetting Model Accuracy: 19.74%
Post-Pruning Retraining...
Initial Test Accuracy: 27.92%
Post-Pruning Training Epoch [1/10]: Loss: 0.9865, Train Acc: 65.56%, Test Acc: 71.45%
Post-Pruning Training Epoch [2/10]: Loss: 0.6757, Train Acc: 76.42%, Test Acc: 73.13%
Post-Pruning Training Epoch [3/10]: Loss: 0.5396, Train Acc: 81.09%, Test Acc: 74.12%
Post-Pruning Training Epoch [4/10]: Loss: 0.4292, Train Acc: 85.04%, Test Acc: 75.28%
Post-Pruning Training Epoch [5/10]: Loss: 0.3364, Train Acc: 88.17%, Test Acc: 76.33%
Post-Pruning Training Epoch [6/10]: Loss: 0.2539, Train Acc: 91.00%, Test Acc: 75.66%
Post-Pruning Training Epoch [7/10]: Loss: 0.1995, Train Acc: 93.01%, Test Acc: 75.10%
Post-Pruning Training Epoch [8/10]: Loss: 0.1683, Train Acc: 94.03%, Test Acc: 75.30%
Post-Pruning Training Epoch [9/10]: Loss: 0.1326, Train Acc: 95.40%, Test Acc: 75.13%
Post-Pruning Training Epoch [10/10]: Loss: 0.1192, Train Acc: 95.95%, Test Acc: 76.47%
Initial Test Accuracy: 12.23%
Post-Pruning Training Epoch [1/10]: Loss: 0.9216, Train Acc: 68.13%, Test Acc: 68.49%
Post-Pruning Training Epoch [2/10]: Loss: 0.7047, Train Acc: 75.68%, Test Acc: 72.52%
Post-Pruning Training Epoch [3/10]: Loss: 0.5766, Train Acc: 80.26%, Test Acc: 74.63%
Post-Pruning Training Epoch [4/10]: Loss: 0.4687, Train Acc: 83.91%, Test Acc: 73.72%
Post-Pruning Training Epoch [5/10]: Loss: 0.3793, Train Acc: 86.98%, Test Acc: 75.28%
Post-Pruning Training Epoch [6/10]: Loss: 0.3048, Train Acc: 89.43%, Test Acc: 75.31%
Post-Pruning Training Epoch [7/10]: Loss: 0.2392, Train Acc: 91.70%, Test Acc: 76.34%
Post-Pruning Training Epoch [8/10]: Loss: 0.1929, Train Acc: 93.27%, Test Acc: 75.28%
Post-Pruning Training Epoch [9/10]: Loss: 0.1620, Train Acc: 94.32%, Test Acc: 75.52%
Post-Pruning Training Epoch [10/10]: Loss: 0.1429, Train Acc: 95.07%, Test Acc: 75.17%
Initial Test Accuracy: 19.74%
Post-Pruning Training Epoch [1/10]: Loss: 0.9232, Train Acc: 67.99%, Test Acc: 69.19%
Post-Pruning Training Epoch [2/10]: Loss: 0.7079, Train Acc: 75.64%, Test Acc: 72.19%
Post-Pruning Training Epoch [3/10]: Loss: 0.5796, Train Acc: 79.88%, Test Acc: 75.14%
Post-Pruning Training Epoch [4/10]: Loss: 0.4728, Train Acc: 83.54%, Test Acc: 73.71%
Post-Pruning Training Epoch [5/10]: Loss: 0.3843, Train Acc: 86.63%, Test Acc: 75.38%
Post-Pruning Training Epoch [6/10]: Loss: 0.3020, Train Acc: 89.46%, Test Acc: 75.56%
Post-Pruning Training Epoch [7/10]: Loss: 0.2404, Train Acc: 91.61%, Test Acc: 75.81%
Post-Pruning Training Epoch [8/10]: Loss: 0.1958, Train Acc: 93.06%, Test Acc: 76.01%
Post-Pruning Training Epoch [9/10]: Loss: 0.1635, Train Acc: 94.29%, Test Acc: 75.46%
Post-Pruning Training Epoch [10/10]: Loss: 0.1385, Train Acc: 95.06%, Test Acc: 75.99%
Post-Pruned Baseline Model Accuracy: 76.47%
Post-Pruned Low Forgetting Model Accuracy: 75.17%
Post-Pruned High Forgetting Model Accuracy: 75.99%
Accuracy results saved to results/resnet18/CIFAR10/dr0.3/pr0.8/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.3/pr0.8/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 20000 highest-forgetting and top 20000 lowest-forgetting samples.
Highest forgetting subset size: 20000, Lowest forgetting subset size: 20000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5941, Accuracy: 42.70%
Epoch [2/10] complete: Loss: 1.2188, Accuracy: 56.45%
Epoch [3/10] complete: Loss: 1.0205, Accuracy: 64.11%
Epoch [4/10] complete: Loss: 0.8826, Accuracy: 69.16%
Epoch [5/10] complete: Loss: 0.7619, Accuracy: 73.53%
Epoch [6/10] complete: Loss: 0.6416, Accuracy: 77.73%
Epoch [7/10] complete: Loss: 0.5469, Accuracy: 81.00%
Epoch [8/10] complete: Loss: 0.4335, Accuracy: 84.81%
Epoch [9/10] complete: Loss: 0.3473, Accuracy: 87.88%
Epoch [10/10] complete: Loss: 0.2886, Accuracy: 90.05%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5908, Accuracy: 42.88%
Epoch [2/10] complete: Loss: 1.2455, Accuracy: 55.10%
Epoch [3/10] complete: Loss: 1.0457, Accuracy: 62.98%
Epoch [4/10] complete: Loss: 0.8959, Accuracy: 68.47%
Epoch [5/10] complete: Loss: 0.7584, Accuracy: 73.19%
Epoch [6/10] complete: Loss: 0.6501, Accuracy: 77.08%
Epoch [7/10] complete: Loss: 0.5255, Accuracy: 81.42%
Epoch [8/10] complete: Loss: 0.4337, Accuracy: 84.75%
Epoch [9/10] complete: Loss: 0.3570, Accuracy: 87.29%
Epoch [10/10] complete: Loss: 0.2816, Accuracy: 90.09%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 67.49%
High Forgetting Model Accuracy: 67.96%
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.4/pr0.0/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 70.69%
Pruned Low Forgetting Model Accuracy: 67.49%
Pruned High Forgetting Model Accuracy: 67.96%
Post-Pruning Retraining...
Initial Test Accuracy: 70.69%
Post-Pruning Training Epoch [1/10]: Loss: 0.8871, Train Acc: 69.29%, Test Acc: 71.89%
Post-Pruning Training Epoch [2/10]: Loss: 0.6089, Train Acc: 78.65%, Test Acc: 71.77%
Post-Pruning Training Epoch [3/10]: Loss: 0.4800, Train Acc: 83.22%, Test Acc: 74.13%
Post-Pruning Training Epoch [4/10]: Loss: 0.3706, Train Acc: 87.16%, Test Acc: 74.58%
Post-Pruning Training Epoch [5/10]: Loss: 0.2697, Train Acc: 90.57%, Test Acc: 75.22%
Post-Pruning Training Epoch [6/10]: Loss: 0.2113, Train Acc: 92.63%, Test Acc: 75.17%
Post-Pruning Training Epoch [7/10]: Loss: 0.1647, Train Acc: 94.26%, Test Acc: 75.17%
Post-Pruning Training Epoch [8/10]: Loss: 0.1376, Train Acc: 95.13%, Test Acc: 74.58%
Post-Pruning Training Epoch [9/10]: Loss: 0.1165, Train Acc: 95.92%, Test Acc: 75.00%
Post-Pruning Training Epoch [10/10]: Loss: 0.1100, Train Acc: 96.22%, Test Acc: 75.17%
Initial Test Accuracy: 67.49%
Post-Pruning Training Epoch [1/10]: Loss: 0.6865, Train Acc: 77.09%, Test Acc: 71.50%
Post-Pruning Training Epoch [2/10]: Loss: 0.5370, Train Acc: 81.83%, Test Acc: 74.04%
Post-Pruning Training Epoch [3/10]: Loss: 0.4280, Train Acc: 85.62%, Test Acc: 75.07%
Post-Pruning Training Epoch [4/10]: Loss: 0.3387, Train Acc: 88.27%, Test Acc: 74.46%
Post-Pruning Training Epoch [5/10]: Loss: 0.2620, Train Acc: 90.84%, Test Acc: 75.43%
Post-Pruning Training Epoch [6/10]: Loss: 0.2130, Train Acc: 92.79%, Test Acc: 74.81%
Post-Pruning Training Epoch [7/10]: Loss: 0.1733, Train Acc: 93.99%, Test Acc: 74.60%
Post-Pruning Training Epoch [8/10]: Loss: 0.1548, Train Acc: 94.70%, Test Acc: 75.31%
Post-Pruning Training Epoch [9/10]: Loss: 0.1245, Train Acc: 95.71%, Test Acc: 75.17%
Post-Pruning Training Epoch [10/10]: Loss: 0.1273, Train Acc: 95.71%, Test Acc: 75.92%
Initial Test Accuracy: 67.96%
Post-Pruning Training Epoch [1/10]: Loss: 0.6905, Train Acc: 77.00%, Test Acc: 71.72%
Post-Pruning Training Epoch [2/10]: Loss: 0.5369, Train Acc: 81.93%, Test Acc: 73.09%
Post-Pruning Training Epoch [3/10]: Loss: 0.4238, Train Acc: 85.50%, Test Acc: 74.30%
Post-Pruning Training Epoch [4/10]: Loss: 0.3381, Train Acc: 88.41%, Test Acc: 74.45%
Post-Pruning Training Epoch [5/10]: Loss: 0.2691, Train Acc: 90.80%, Test Acc: 72.66%
Post-Pruning Training Epoch [6/10]: Loss: 0.2145, Train Acc: 92.44%, Test Acc: 75.14%
Post-Pruning Training Epoch [7/10]: Loss: 0.1755, Train Acc: 93.94%, Test Acc: 75.61%
Post-Pruning Training Epoch [8/10]: Loss: 0.1450, Train Acc: 94.98%, Test Acc: 75.62%
Post-Pruning Training Epoch [9/10]: Loss: 0.1368, Train Acc: 95.20%, Test Acc: 75.78%
Post-Pruning Training Epoch [10/10]: Loss: 0.1146, Train Acc: 95.99%, Test Acc: 74.74%
Post-Pruned Baseline Model Accuracy: 75.17%
Post-Pruned Low Forgetting Model Accuracy: 75.92%
Post-Pruned High Forgetting Model Accuracy: 74.74%
Accuracy results saved to results/resnet18/CIFAR10/dr0.4/pr0.0/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.4/pr0.0/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 20000 highest-forgetting and top 20000 lowest-forgetting samples.
Highest forgetting subset size: 20000, Lowest forgetting subset size: 20000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5988, Accuracy: 42.24%
Epoch [2/10] complete: Loss: 1.2156, Accuracy: 56.74%
Epoch [3/10] complete: Loss: 1.0256, Accuracy: 63.70%
Epoch [4/10] complete: Loss: 0.8747, Accuracy: 69.03%
Epoch [5/10] complete: Loss: 0.7592, Accuracy: 73.48%
Epoch [6/10] complete: Loss: 0.6420, Accuracy: 77.57%
Epoch [7/10] complete: Loss: 0.5446, Accuracy: 81.02%
Epoch [8/10] complete: Loss: 0.4283, Accuracy: 85.27%
Epoch [9/10] complete: Loss: 0.3419, Accuracy: 88.06%
Epoch [10/10] complete: Loss: 0.2889, Accuracy: 89.90%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5926, Accuracy: 42.95%
Epoch [2/10] complete: Loss: 1.2486, Accuracy: 55.26%
Epoch [3/10] complete: Loss: 1.0419, Accuracy: 63.22%
Epoch [4/10] complete: Loss: 0.8987, Accuracy: 68.56%
Epoch [5/10] complete: Loss: 0.7651, Accuracy: 72.94%
Epoch [6/10] complete: Loss: 0.6473, Accuracy: 77.41%
Epoch [7/10] complete: Loss: 0.5406, Accuracy: 80.93%
Epoch [8/10] complete: Loss: 0.4417, Accuracy: 84.17%
Epoch [9/10] complete: Loss: 0.3584, Accuracy: 87.30%
Epoch [10/10] complete: Loss: 0.2751, Accuracy: 90.34%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 67.78%
High Forgetting Model Accuracy: 67.16%
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.4/pr0.2/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 70.58%
Pruned Low Forgetting Model Accuracy: 67.91%
Pruned High Forgetting Model Accuracy: 66.66%
Post-Pruning Retraining...
Initial Test Accuracy: 70.58%
Post-Pruning Training Epoch [1/10]: Loss: 0.8944, Train Acc: 69.18%, Test Acc: 72.11%
Post-Pruning Training Epoch [2/10]: Loss: 0.6121, Train Acc: 78.51%, Test Acc: 72.28%
Post-Pruning Training Epoch [3/10]: Loss: 0.4892, Train Acc: 82.95%, Test Acc: 73.88%
Post-Pruning Training Epoch [4/10]: Loss: 0.3772, Train Acc: 86.69%, Test Acc: 75.04%
Post-Pruning Training Epoch [5/10]: Loss: 0.2888, Train Acc: 89.84%, Test Acc: 75.37%
Post-Pruning Training Epoch [6/10]: Loss: 0.2144, Train Acc: 92.54%, Test Acc: 75.22%
Post-Pruning Training Epoch [7/10]: Loss: 0.1693, Train Acc: 94.04%, Test Acc: 74.54%
Post-Pruning Training Epoch [8/10]: Loss: 0.1422, Train Acc: 95.07%, Test Acc: 75.36%
Post-Pruning Training Epoch [9/10]: Loss: 0.1181, Train Acc: 95.89%, Test Acc: 74.75%
Post-Pruning Training Epoch [10/10]: Loss: 0.1061, Train Acc: 96.23%, Test Acc: 75.00%
Initial Test Accuracy: 67.91%
Post-Pruning Training Epoch [1/10]: Loss: 0.6912, Train Acc: 76.92%, Test Acc: 71.68%
Post-Pruning Training Epoch [2/10]: Loss: 0.5411, Train Acc: 81.65%, Test Acc: 73.56%
Post-Pruning Training Epoch [3/10]: Loss: 0.4303, Train Acc: 85.33%, Test Acc: 74.43%
Post-Pruning Training Epoch [4/10]: Loss: 0.3385, Train Acc: 88.38%, Test Acc: 74.48%
Post-Pruning Training Epoch [5/10]: Loss: 0.2625, Train Acc: 90.88%, Test Acc: 73.84%
Post-Pruning Training Epoch [6/10]: Loss: 0.2078, Train Acc: 92.73%, Test Acc: 75.58%
Post-Pruning Training Epoch [7/10]: Loss: 0.1776, Train Acc: 93.75%, Test Acc: 74.60%
Post-Pruning Training Epoch [8/10]: Loss: 0.1505, Train Acc: 94.73%, Test Acc: 74.53%
Post-Pruning Training Epoch [9/10]: Loss: 0.1267, Train Acc: 95.57%, Test Acc: 74.50%
Post-Pruning Training Epoch [10/10]: Loss: 0.1189, Train Acc: 95.91%, Test Acc: 74.30%
Initial Test Accuracy: 66.66%
Post-Pruning Training Epoch [1/10]: Loss: 0.6960, Train Acc: 76.80%, Test Acc: 72.19%
Post-Pruning Training Epoch [2/10]: Loss: 0.5379, Train Acc: 81.71%, Test Acc: 72.78%
Post-Pruning Training Epoch [3/10]: Loss: 0.4352, Train Acc: 85.11%, Test Acc: 74.35%
Post-Pruning Training Epoch [4/10]: Loss: 0.3439, Train Acc: 88.23%, Test Acc: 73.63%
Post-Pruning Training Epoch [5/10]: Loss: 0.2649, Train Acc: 90.76%, Test Acc: 75.31%
Post-Pruning Training Epoch [6/10]: Loss: 0.2155, Train Acc: 92.51%, Test Acc: 74.43%
Post-Pruning Training Epoch [7/10]: Loss: 0.1808, Train Acc: 93.59%, Test Acc: 74.91%
Post-Pruning Training Epoch [8/10]: Loss: 0.1469, Train Acc: 94.94%, Test Acc: 74.99%
Post-Pruning Training Epoch [9/10]: Loss: 0.1288, Train Acc: 95.52%, Test Acc: 75.52%
Post-Pruning Training Epoch [10/10]: Loss: 0.1130, Train Acc: 96.11%, Test Acc: 74.06%
Post-Pruned Baseline Model Accuracy: 75.00%
Post-Pruned Low Forgetting Model Accuracy: 74.30%
Post-Pruned High Forgetting Model Accuracy: 74.06%
Accuracy results saved to results/resnet18/CIFAR10/dr0.4/pr0.2/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.4/pr0.2/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 20000 highest-forgetting and top 20000 lowest-forgetting samples.
Highest forgetting subset size: 20000, Lowest forgetting subset size: 20000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6019, Accuracy: 41.95%
Epoch [2/10] complete: Loss: 1.2324, Accuracy: 56.21%
Epoch [3/10] complete: Loss: 1.0348, Accuracy: 63.62%
Epoch [4/10] complete: Loss: 0.8885, Accuracy: 69.08%
Epoch [5/10] complete: Loss: 0.7651, Accuracy: 73.41%
Epoch [6/10] complete: Loss: 0.6540, Accuracy: 77.02%
Epoch [7/10] complete: Loss: 0.5489, Accuracy: 80.69%
Epoch [8/10] complete: Loss: 0.4492, Accuracy: 84.17%
Epoch [9/10] complete: Loss: 0.3555, Accuracy: 87.67%
Epoch [10/10] complete: Loss: 0.2905, Accuracy: 89.81%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6049, Accuracy: 42.15%
Epoch [2/10] complete: Loss: 1.2465, Accuracy: 55.37%
Epoch [3/10] complete: Loss: 1.0458, Accuracy: 63.34%
Epoch [4/10] complete: Loss: 0.9008, Accuracy: 68.80%
Epoch [5/10] complete: Loss: 0.7552, Accuracy: 73.29%
Epoch [6/10] complete: Loss: 0.6320, Accuracy: 77.64%
Epoch [7/10] complete: Loss: 0.5211, Accuracy: 81.76%
Epoch [8/10] complete: Loss: 0.4280, Accuracy: 84.92%
Epoch [9/10] complete: Loss: 0.3491, Accuracy: 87.59%
Epoch [10/10] complete: Loss: 0.2745, Accuracy: 90.51%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 66.99%
High Forgetting Model Accuracy: 68.23%
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.4/pr0.4/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 69.78%
Pruned Low Forgetting Model Accuracy: 65.80%
Pruned High Forgetting Model Accuracy: 64.65%
Post-Pruning Retraining...
Initial Test Accuracy: 69.78%
Post-Pruning Training Epoch [1/10]: Loss: 0.8961, Train Acc: 69.03%, Test Acc: 71.59%
Post-Pruning Training Epoch [2/10]: Loss: 0.6137, Train Acc: 78.53%, Test Acc: 72.77%
Post-Pruning Training Epoch [3/10]: Loss: 0.4839, Train Acc: 83.20%, Test Acc: 74.38%
Post-Pruning Training Epoch [4/10]: Loss: 0.3725, Train Acc: 87.00%, Test Acc: 74.81%
Post-Pruning Training Epoch [5/10]: Loss: 0.2782, Train Acc: 90.16%, Test Acc: 75.27%
Post-Pruning Training Epoch [6/10]: Loss: 0.2126, Train Acc: 92.46%, Test Acc: 74.56%
Post-Pruning Training Epoch [7/10]: Loss: 0.1692, Train Acc: 93.99%, Test Acc: 74.47%
Post-Pruning Training Epoch [8/10]: Loss: 0.1384, Train Acc: 95.17%, Test Acc: 75.30%
Post-Pruning Training Epoch [9/10]: Loss: 0.1192, Train Acc: 95.83%, Test Acc: 75.06%
Post-Pruning Training Epoch [10/10]: Loss: 0.1077, Train Acc: 96.16%, Test Acc: 74.58%
Initial Test Accuracy: 65.80%
Post-Pruning Training Epoch [1/10]: Loss: 0.6963, Train Acc: 76.71%, Test Acc: 72.53%
Post-Pruning Training Epoch [2/10]: Loss: 0.5459, Train Acc: 81.61%, Test Acc: 73.91%
Post-Pruning Training Epoch [3/10]: Loss: 0.4335, Train Acc: 85.13%, Test Acc: 74.51%
Post-Pruning Training Epoch [4/10]: Loss: 0.3412, Train Acc: 88.31%, Test Acc: 75.71%
Post-Pruning Training Epoch [5/10]: Loss: 0.2677, Train Acc: 90.85%, Test Acc: 74.34%
Post-Pruning Training Epoch [6/10]: Loss: 0.2169, Train Acc: 92.50%, Test Acc: 74.95%
Post-Pruning Training Epoch [7/10]: Loss: 0.1786, Train Acc: 93.80%, Test Acc: 74.79%
Post-Pruning Training Epoch [8/10]: Loss: 0.1435, Train Acc: 95.07%, Test Acc: 74.35%
Post-Pruning Training Epoch [9/10]: Loss: 0.1336, Train Acc: 95.37%, Test Acc: 74.62%
Post-Pruning Training Epoch [10/10]: Loss: 0.1154, Train Acc: 95.97%, Test Acc: 75.30%
Initial Test Accuracy: 64.65%
Post-Pruning Training Epoch [1/10]: Loss: 0.7050, Train Acc: 76.43%, Test Acc: 72.62%
Post-Pruning Training Epoch [2/10]: Loss: 0.5538, Train Acc: 81.31%, Test Acc: 72.70%
Post-Pruning Training Epoch [3/10]: Loss: 0.4392, Train Acc: 84.81%, Test Acc: 73.97%
Post-Pruning Training Epoch [4/10]: Loss: 0.3522, Train Acc: 87.79%, Test Acc: 74.84%
Post-Pruning Training Epoch [5/10]: Loss: 0.2755, Train Acc: 90.50%, Test Acc: 74.39%
Post-Pruning Training Epoch [6/10]: Loss: 0.2259, Train Acc: 92.25%, Test Acc: 74.68%
Post-Pruning Training Epoch [7/10]: Loss: 0.1764, Train Acc: 93.82%, Test Acc: 74.70%
Post-Pruning Training Epoch [8/10]: Loss: 0.1567, Train Acc: 94.49%, Test Acc: 74.71%
Post-Pruning Training Epoch [9/10]: Loss: 0.1353, Train Acc: 95.28%, Test Acc: 74.37%
Post-Pruning Training Epoch [10/10]: Loss: 0.1235, Train Acc: 95.71%, Test Acc: 73.39%
Post-Pruned Baseline Model Accuracy: 74.58%
Post-Pruned Low Forgetting Model Accuracy: 75.30%
Post-Pruned High Forgetting Model Accuracy: 73.39%
Accuracy results saved to results/resnet18/CIFAR10/dr0.4/pr0.4/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.4/pr0.4/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 20000 highest-forgetting and top 20000 lowest-forgetting samples.
Highest forgetting subset size: 20000, Lowest forgetting subset size: 20000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.6010, Accuracy: 41.92%
Epoch [2/10] complete: Loss: 1.2385, Accuracy: 55.63%
Epoch [3/10] complete: Loss: 1.0436, Accuracy: 63.10%
Epoch [4/10] complete: Loss: 0.8908, Accuracy: 68.67%
Epoch [5/10] complete: Loss: 0.7644, Accuracy: 72.77%
Epoch [6/10] complete: Loss: 0.6412, Accuracy: 77.44%
Epoch [7/10] complete: Loss: 0.5414, Accuracy: 81.05%
Epoch [8/10] complete: Loss: 0.4289, Accuracy: 85.03%
Epoch [9/10] complete: Loss: 0.3390, Accuracy: 88.10%
Epoch [10/10] complete: Loss: 0.2824, Accuracy: 90.17%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5889, Accuracy: 42.76%
Epoch [2/10] complete: Loss: 1.2458, Accuracy: 55.49%
Epoch [3/10] complete: Loss: 1.0409, Accuracy: 63.37%
Epoch [4/10] complete: Loss: 0.8968, Accuracy: 68.53%
Epoch [5/10] complete: Loss: 0.7547, Accuracy: 73.38%
Epoch [6/10] complete: Loss: 0.6398, Accuracy: 77.86%
Epoch [7/10] complete: Loss: 0.5200, Accuracy: 81.56%
Epoch [8/10] complete: Loss: 0.4382, Accuracy: 84.43%
Epoch [9/10] complete: Loss: 0.3429, Accuracy: 88.00%
Epoch [10/10] complete: Loss: 0.2830, Accuracy: 90.00%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 66.52%
High Forgetting Model Accuracy: 68.11%
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.4/pr0.6/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 63.76%
Pruned Low Forgetting Model Accuracy: 57.61%
Pruned High Forgetting Model Accuracy: 50.32%
Post-Pruning Retraining...
Initial Test Accuracy: 63.76%
Post-Pruning Training Epoch [1/10]: Loss: 0.9049, Train Acc: 68.59%, Test Acc: 69.75%
Post-Pruning Training Epoch [2/10]: Loss: 0.6264, Train Acc: 78.04%, Test Acc: 72.90%
Post-Pruning Training Epoch [3/10]: Loss: 0.4989, Train Acc: 82.49%, Test Acc: 74.48%
Post-Pruning Training Epoch [4/10]: Loss: 0.3853, Train Acc: 86.51%, Test Acc: 75.20%
Post-Pruning Training Epoch [5/10]: Loss: 0.2944, Train Acc: 89.61%, Test Acc: 75.41%
Post-Pruning Training Epoch [6/10]: Loss: 0.2229, Train Acc: 92.17%, Test Acc: 75.72%
Post-Pruning Training Epoch [7/10]: Loss: 0.1721, Train Acc: 93.88%, Test Acc: 75.14%
Post-Pruning Training Epoch [8/10]: Loss: 0.1459, Train Acc: 94.88%, Test Acc: 75.01%
Post-Pruning Training Epoch [9/10]: Loss: 0.1221, Train Acc: 95.82%, Test Acc: 75.13%
Post-Pruning Training Epoch [10/10]: Loss: 0.1166, Train Acc: 95.90%, Test Acc: 75.63%
Initial Test Accuracy: 57.61%
Post-Pruning Training Epoch [1/10]: Loss: 0.7276, Train Acc: 75.40%, Test Acc: 72.47%
Post-Pruning Training Epoch [2/10]: Loss: 0.5661, Train Acc: 80.60%, Test Acc: 72.37%
Post-Pruning Training Epoch [3/10]: Loss: 0.4493, Train Acc: 84.61%, Test Acc: 75.76%
Post-Pruning Training Epoch [4/10]: Loss: 0.3581, Train Acc: 87.81%, Test Acc: 74.02%
Post-Pruning Training Epoch [5/10]: Loss: 0.2793, Train Acc: 90.21%, Test Acc: 74.55%
Post-Pruning Training Epoch [6/10]: Loss: 0.2210, Train Acc: 92.36%, Test Acc: 74.75%
Post-Pruning Training Epoch [7/10]: Loss: 0.1824, Train Acc: 93.74%, Test Acc: 74.15%
Post-Pruning Training Epoch [8/10]: Loss: 0.1544, Train Acc: 94.58%, Test Acc: 74.47%
Post-Pruning Training Epoch [9/10]: Loss: 0.1382, Train Acc: 95.15%, Test Acc: 75.64%
Post-Pruning Training Epoch [10/10]: Loss: 0.1114, Train Acc: 96.09%, Test Acc: 75.63%
Initial Test Accuracy: 50.32%
Post-Pruning Training Epoch [1/10]: Loss: 0.7409, Train Acc: 75.02%, Test Acc: 71.04%
Post-Pruning Training Epoch [2/10]: Loss: 0.5668, Train Acc: 80.78%, Test Acc: 74.02%
Post-Pruning Training Epoch [3/10]: Loss: 0.4560, Train Acc: 84.35%, Test Acc: 73.43%
Post-Pruning Training Epoch [4/10]: Loss: 0.3627, Train Acc: 87.48%, Test Acc: 73.56%
Post-Pruning Training Epoch [5/10]: Loss: 0.2816, Train Acc: 90.31%, Test Acc: 74.80%
Post-Pruning Training Epoch [6/10]: Loss: 0.2263, Train Acc: 92.06%, Test Acc: 74.12%
Post-Pruning Training Epoch [7/10]: Loss: 0.1791, Train Acc: 93.70%, Test Acc: 74.68%
Post-Pruning Training Epoch [8/10]: Loss: 0.1501, Train Acc: 94.78%, Test Acc: 75.09%
Post-Pruning Training Epoch [9/10]: Loss: 0.1393, Train Acc: 95.18%, Test Acc: 74.61%
Post-Pruning Training Epoch [10/10]: Loss: 0.1139, Train Acc: 96.05%, Test Acc: 74.68%
Post-Pruned Baseline Model Accuracy: 75.63%
Post-Pruned Low Forgetting Model Accuracy: 75.63%
Post-Pruned High Forgetting Model Accuracy: 74.68%
Accuracy results saved to results/resnet18/CIFAR10/dr0.4/pr0.6/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.4/pr0.6/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 20000 highest-forgetting and top 20000 lowest-forgetting samples.
Highest forgetting subset size: 20000, Lowest forgetting subset size: 20000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5992, Accuracy: 41.99%
Epoch [2/10] complete: Loss: 1.2305, Accuracy: 56.16%
Epoch [3/10] complete: Loss: 1.0331, Accuracy: 63.81%
Epoch [4/10] complete: Loss: 0.8901, Accuracy: 68.76%
Epoch [5/10] complete: Loss: 0.7683, Accuracy: 73.18%
Epoch [6/10] complete: Loss: 0.6606, Accuracy: 76.53%
Epoch [7/10] complete: Loss: 0.5531, Accuracy: 80.42%
Epoch [8/10] complete: Loss: 0.4408, Accuracy: 84.75%
Epoch [9/10] complete: Loss: 0.3449, Accuracy: 87.98%
Epoch [10/10] complete: Loss: 0.2783, Accuracy: 90.39%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5972, Accuracy: 42.13%
Epoch [2/10] complete: Loss: 1.2577, Accuracy: 55.16%
Epoch [3/10] complete: Loss: 1.0630, Accuracy: 62.48%
Epoch [4/10] complete: Loss: 0.9160, Accuracy: 67.72%
Epoch [5/10] complete: Loss: 0.7725, Accuracy: 72.77%
Epoch [6/10] complete: Loss: 0.6481, Accuracy: 77.67%
Epoch [7/10] complete: Loss: 0.5395, Accuracy: 80.94%
Epoch [8/10] complete: Loss: 0.4501, Accuracy: 83.94%
Epoch [9/10] complete: Loss: 0.3664, Accuracy: 87.00%
Epoch [10/10] complete: Loss: 0.2984, Accuracy: 89.61%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 67.32%
High Forgetting Model Accuracy: 66.70%
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.4/pr0.8/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 27.92%
Pruned Low Forgetting Model Accuracy: 14.30%
Pruned High Forgetting Model Accuracy: 16.88%
Post-Pruning Retraining...
Initial Test Accuracy: 27.92%
Post-Pruning Training Epoch [1/10]: Loss: 0.9842, Train Acc: 65.68%, Test Acc: 70.13%
Post-Pruning Training Epoch [2/10]: Loss: 0.6744, Train Acc: 76.43%, Test Acc: 73.39%
Post-Pruning Training Epoch [3/10]: Loss: 0.5395, Train Acc: 81.09%, Test Acc: 74.62%
Post-Pruning Training Epoch [4/10]: Loss: 0.4314, Train Acc: 85.01%, Test Acc: 74.93%
Post-Pruning Training Epoch [5/10]: Loss: 0.3335, Train Acc: 88.34%, Test Acc: 75.67%
Post-Pruning Training Epoch [6/10]: Loss: 0.2579, Train Acc: 91.05%, Test Acc: 76.30%
Post-Pruning Training Epoch [7/10]: Loss: 0.2008, Train Acc: 93.07%, Test Acc: 75.20%
Post-Pruning Training Epoch [8/10]: Loss: 0.1610, Train Acc: 94.37%, Test Acc: 75.77%
Post-Pruning Training Epoch [9/10]: Loss: 0.1309, Train Acc: 95.45%, Test Acc: 75.71%
Post-Pruning Training Epoch [10/10]: Loss: 0.1194, Train Acc: 95.81%, Test Acc: 75.12%
Initial Test Accuracy: 14.30%
Post-Pruning Training Epoch [1/10]: Loss: 0.8392, Train Acc: 70.86%, Test Acc: 70.11%
Post-Pruning Training Epoch [2/10]: Loss: 0.6422, Train Acc: 77.92%, Test Acc: 71.05%
Post-Pruning Training Epoch [3/10]: Loss: 0.5243, Train Acc: 81.85%, Test Acc: 75.03%
Post-Pruning Training Epoch [4/10]: Loss: 0.4167, Train Acc: 85.46%, Test Acc: 74.41%
Post-Pruning Training Epoch [5/10]: Loss: 0.3306, Train Acc: 88.44%, Test Acc: 74.61%
Post-Pruning Training Epoch [6/10]: Loss: 0.2658, Train Acc: 90.71%, Test Acc: 75.93%
Post-Pruning Training Epoch [7/10]: Loss: 0.2150, Train Acc: 92.34%, Test Acc: 73.40%
Post-Pruning Training Epoch [8/10]: Loss: 0.1698, Train Acc: 94.03%, Test Acc: 75.34%
Post-Pruning Training Epoch [9/10]: Loss: 0.1486, Train Acc: 94.71%, Test Acc: 75.25%
Post-Pruning Training Epoch [10/10]: Loss: 0.1272, Train Acc: 95.43%, Test Acc: 75.76%
Initial Test Accuracy: 16.88%
Post-Pruning Training Epoch [1/10]: Loss: 0.8453, Train Acc: 70.83%, Test Acc: 70.29%
Post-Pruning Training Epoch [2/10]: Loss: 0.6409, Train Acc: 77.75%, Test Acc: 74.14%
Post-Pruning Training Epoch [3/10]: Loss: 0.5154, Train Acc: 82.13%, Test Acc: 74.78%
Post-Pruning Training Epoch [4/10]: Loss: 0.4205, Train Acc: 85.47%, Test Acc: 74.01%
Post-Pruning Training Epoch [5/10]: Loss: 0.3318, Train Acc: 88.45%, Test Acc: 74.33%
Post-Pruning Training Epoch [6/10]: Loss: 0.2614, Train Acc: 90.74%, Test Acc: 74.45%
Post-Pruning Training Epoch [7/10]: Loss: 0.2102, Train Acc: 92.60%, Test Acc: 75.17%
Post-Pruning Training Epoch [8/10]: Loss: 0.1699, Train Acc: 93.99%, Test Acc: 76.11%
Post-Pruning Training Epoch [9/10]: Loss: 0.1495, Train Acc: 94.70%, Test Acc: 75.22%
Post-Pruning Training Epoch [10/10]: Loss: 0.1375, Train Acc: 95.16%, Test Acc: 74.57%
Post-Pruned Baseline Model Accuracy: 75.12%
Post-Pruned Low Forgetting Model Accuracy: 75.76%
Post-Pruned High Forgetting Model Accuracy: 74.57%
Accuracy results saved to results/resnet18/CIFAR10/dr0.4/pr0.8/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.4/pr0.8/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 25000 highest-forgetting and top 25000 lowest-forgetting samples.
Highest forgetting subset size: 25000, Lowest forgetting subset size: 25000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5439, Accuracy: 43.90%
Epoch [2/10] complete: Loss: 1.1797, Accuracy: 58.44%
Epoch [3/10] complete: Loss: 0.9841, Accuracy: 65.18%
Epoch [4/10] complete: Loss: 0.8361, Accuracy: 70.35%
Epoch [5/10] complete: Loss: 0.7055, Accuracy: 75.15%
Epoch [6/10] complete: Loss: 0.6009, Accuracy: 79.08%
Epoch [7/10] complete: Loss: 0.4909, Accuracy: 82.71%
Epoch [8/10] complete: Loss: 0.4164, Accuracy: 85.22%
Epoch [9/10] complete: Loss: 0.3194, Accuracy: 88.88%
Epoch [10/10] complete: Loss: 0.2593, Accuracy: 90.92%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5441, Accuracy: 44.60%
Epoch [2/10] complete: Loss: 1.1866, Accuracy: 58.17%
Epoch [3/10] complete: Loss: 0.9889, Accuracy: 65.16%
Epoch [4/10] complete: Loss: 0.8403, Accuracy: 70.54%
Epoch [5/10] complete: Loss: 0.7091, Accuracy: 75.51%
Epoch [6/10] complete: Loss: 0.6017, Accuracy: 79.18%
Epoch [7/10] complete: Loss: 0.5062, Accuracy: 82.14%
Epoch [8/10] complete: Loss: 0.4171, Accuracy: 85.50%
Epoch [9/10] complete: Loss: 0.3327, Accuracy: 88.23%
Epoch [10/10] complete: Loss: 0.2650, Accuracy: 90.63%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 69.44%
High Forgetting Model Accuracy: 70.37%
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Applying pruning with ratio 0.0...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.5/pr0.0/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 70.69%
Pruned Low Forgetting Model Accuracy: 69.44%
Pruned High Forgetting Model Accuracy: 70.37%
Post-Pruning Retraining...
Initial Test Accuracy: 70.69%
Post-Pruning Training Epoch [1/10]: Loss: 0.8877, Train Acc: 69.39%, Test Acc: 71.11%
Post-Pruning Training Epoch [2/10]: Loss: 0.6134, Train Acc: 78.57%, Test Acc: 72.44%
Post-Pruning Training Epoch [3/10]: Loss: 0.4843, Train Acc: 82.92%, Test Acc: 74.04%
Post-Pruning Training Epoch [4/10]: Loss: 0.3683, Train Acc: 87.07%, Test Acc: 75.10%
Post-Pruning Training Epoch [5/10]: Loss: 0.2747, Train Acc: 90.26%, Test Acc: 75.44%
Post-Pruning Training Epoch [6/10]: Loss: 0.2125, Train Acc: 92.52%, Test Acc: 75.28%
Post-Pruning Training Epoch [7/10]: Loss: 0.1684, Train Acc: 93.99%, Test Acc: 74.79%
Post-Pruning Training Epoch [8/10]: Loss: 0.1416, Train Acc: 95.07%, Test Acc: 74.69%
Post-Pruning Training Epoch [9/10]: Loss: 0.1196, Train Acc: 95.78%, Test Acc: 74.49%
Post-Pruning Training Epoch [10/10]: Loss: 0.1063, Train Acc: 96.25%, Test Acc: 75.30%
Initial Test Accuracy: 69.44%
Post-Pruning Training Epoch [1/10]: Loss: 0.5996, Train Acc: 80.42%, Test Acc: 73.14%
Post-Pruning Training Epoch [2/10]: Loss: 0.4650, Train Acc: 84.33%, Test Acc: 72.99%
Post-Pruning Training Epoch [3/10]: Loss: 0.3631, Train Acc: 87.69%, Test Acc: 75.67%
Post-Pruning Training Epoch [4/10]: Loss: 0.2836, Train Acc: 90.21%, Test Acc: 75.41%
Post-Pruning Training Epoch [5/10]: Loss: 0.2250, Train Acc: 92.22%, Test Acc: 75.21%
Post-Pruning Training Epoch [6/10]: Loss: 0.1784, Train Acc: 93.77%, Test Acc: 74.33%
Post-Pruning Training Epoch [7/10]: Loss: 0.1545, Train Acc: 94.58%, Test Acc: 75.40%
Post-Pruning Training Epoch [8/10]: Loss: 0.1344, Train Acc: 95.37%, Test Acc: 74.64%
Post-Pruning Training Epoch [9/10]: Loss: 0.1209, Train Acc: 95.81%, Test Acc: 75.66%
Post-Pruning Training Epoch [10/10]: Loss: 0.1043, Train Acc: 96.39%, Test Acc: 75.21%
Initial Test Accuracy: 70.37%
Post-Pruning Training Epoch [1/10]: Loss: 0.5979, Train Acc: 80.56%, Test Acc: 72.93%
Post-Pruning Training Epoch [2/10]: Loss: 0.4571, Train Acc: 84.56%, Test Acc: 74.93%
Post-Pruning Training Epoch [3/10]: Loss: 0.3588, Train Acc: 87.80%, Test Acc: 74.98%
Post-Pruning Training Epoch [4/10]: Loss: 0.2838, Train Acc: 90.34%, Test Acc: 75.59%
Post-Pruning Training Epoch [5/10]: Loss: 0.2211, Train Acc: 92.40%, Test Acc: 74.48%
Post-Pruning Training Epoch [6/10]: Loss: 0.1782, Train Acc: 93.74%, Test Acc: 74.49%
Post-Pruning Training Epoch [7/10]: Loss: 0.1572, Train Acc: 94.57%, Test Acc: 75.89%
Post-Pruning Training Epoch [8/10]: Loss: 0.1330, Train Acc: 95.39%, Test Acc: 75.09%
Post-Pruning Training Epoch [9/10]: Loss: 0.1178, Train Acc: 96.03%, Test Acc: 75.46%
Post-Pruning Training Epoch [10/10]: Loss: 0.1015, Train Acc: 96.45%, Test Acc: 75.62%
Post-Pruned Baseline Model Accuracy: 75.30%
Post-Pruned Low Forgetting Model Accuracy: 75.21%
Post-Pruned High Forgetting Model Accuracy: 75.62%
Accuracy results saved to results/resnet18/CIFAR10/dr0.5/pr0.0/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.5/pr0.0/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 25000 highest-forgetting and top 25000 lowest-forgetting samples.
Highest forgetting subset size: 25000, Lowest forgetting subset size: 25000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5481, Accuracy: 43.99%
Epoch [2/10] complete: Loss: 1.1843, Accuracy: 57.80%
Epoch [3/10] complete: Loss: 0.9857, Accuracy: 64.90%
Epoch [4/10] complete: Loss: 0.8445, Accuracy: 70.20%
Epoch [5/10] complete: Loss: 0.7163, Accuracy: 75.05%
Epoch [6/10] complete: Loss: 0.6121, Accuracy: 78.43%
Epoch [7/10] complete: Loss: 0.5071, Accuracy: 82.12%
Epoch [8/10] complete: Loss: 0.4271, Accuracy: 85.11%
Epoch [9/10] complete: Loss: 0.3344, Accuracy: 88.14%
Epoch [10/10] complete: Loss: 0.2683, Accuracy: 90.42%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5599, Accuracy: 44.18%
Epoch [2/10] complete: Loss: 1.1931, Accuracy: 57.60%
Epoch [3/10] complete: Loss: 0.9966, Accuracy: 64.97%
Epoch [4/10] complete: Loss: 0.8429, Accuracy: 70.47%
Epoch [5/10] complete: Loss: 0.7153, Accuracy: 75.19%
Epoch [6/10] complete: Loss: 0.6015, Accuracy: 78.95%
Epoch [7/10] complete: Loss: 0.5006, Accuracy: 82.37%
Epoch [8/10] complete: Loss: 0.4130, Accuracy: 85.69%
Epoch [9/10] complete: Loss: 0.3309, Accuracy: 88.45%
Epoch [10/10] complete: Loss: 0.2743, Accuracy: 90.52%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 70.55%
High Forgetting Model Accuracy: 69.32%
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Applying pruning with ratio 0.2...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.5/pr0.2/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 70.58%
Pruned Low Forgetting Model Accuracy: 70.16%
Pruned High Forgetting Model Accuracy: 69.36%
Post-Pruning Retraining...
Initial Test Accuracy: 70.58%
Post-Pruning Training Epoch [1/10]: Loss: 0.8926, Train Acc: 69.27%, Test Acc: 72.25%
Post-Pruning Training Epoch [2/10]: Loss: 0.6183, Train Acc: 78.32%, Test Acc: 71.93%
Post-Pruning Training Epoch [3/10]: Loss: 0.4906, Train Acc: 82.65%, Test Acc: 73.67%
Post-Pruning Training Epoch [4/10]: Loss: 0.3731, Train Acc: 86.96%, Test Acc: 74.31%
Post-Pruning Training Epoch [5/10]: Loss: 0.2778, Train Acc: 90.08%, Test Acc: 74.70%
Post-Pruning Training Epoch [6/10]: Loss: 0.2096, Train Acc: 92.61%, Test Acc: 74.99%
Post-Pruning Training Epoch [7/10]: Loss: 0.1671, Train Acc: 94.12%, Test Acc: 74.70%
Post-Pruning Training Epoch [8/10]: Loss: 0.1400, Train Acc: 95.06%, Test Acc: 74.42%
Post-Pruning Training Epoch [9/10]: Loss: 0.1182, Train Acc: 95.84%, Test Acc: 75.16%
Post-Pruning Training Epoch [10/10]: Loss: 0.1011, Train Acc: 96.47%, Test Acc: 75.40%
Initial Test Accuracy: 70.16%
Post-Pruning Training Epoch [1/10]: Loss: 0.5975, Train Acc: 80.23%, Test Acc: 73.25%
Post-Pruning Training Epoch [2/10]: Loss: 0.4585, Train Acc: 84.61%, Test Acc: 73.60%
Post-Pruning Training Epoch [3/10]: Loss: 0.3623, Train Acc: 87.70%, Test Acc: 75.25%
Post-Pruning Training Epoch [4/10]: Loss: 0.2782, Train Acc: 90.41%, Test Acc: 74.04%
Post-Pruning Training Epoch [5/10]: Loss: 0.2209, Train Acc: 92.46%, Test Acc: 75.25%
Post-Pruning Training Epoch [6/10]: Loss: 0.1781, Train Acc: 93.74%, Test Acc: 75.92%
Post-Pruning Training Epoch [7/10]: Loss: 0.1483, Train Acc: 94.84%, Test Acc: 75.97%
Post-Pruning Training Epoch [8/10]: Loss: 0.1330, Train Acc: 95.35%, Test Acc: 74.74%
Post-Pruning Training Epoch [9/10]: Loss: 0.1162, Train Acc: 95.90%, Test Acc: 74.97%
Post-Pruning Training Epoch [10/10]: Loss: 0.1049, Train Acc: 96.30%, Test Acc: 75.83%
Initial Test Accuracy: 69.36%
Post-Pruning Training Epoch [1/10]: Loss: 0.6041, Train Acc: 80.13%, Test Acc: 72.88%
Post-Pruning Training Epoch [2/10]: Loss: 0.4625, Train Acc: 84.33%, Test Acc: 74.16%
Post-Pruning Training Epoch [3/10]: Loss: 0.3577, Train Acc: 87.78%, Test Acc: 74.46%
Post-Pruning Training Epoch [4/10]: Loss: 0.2843, Train Acc: 90.14%, Test Acc: 74.57%
Post-Pruning Training Epoch [5/10]: Loss: 0.2212, Train Acc: 92.40%, Test Acc: 74.72%
Post-Pruning Training Epoch [6/10]: Loss: 0.1822, Train Acc: 93.70%, Test Acc: 74.41%
Post-Pruning Training Epoch [7/10]: Loss: 0.1527, Train Acc: 94.69%, Test Acc: 74.88%
Post-Pruning Training Epoch [8/10]: Loss: 0.1312, Train Acc: 95.43%, Test Acc: 73.66%
Post-Pruning Training Epoch [9/10]: Loss: 0.1141, Train Acc: 96.11%, Test Acc: 75.19%
Post-Pruning Training Epoch [10/10]: Loss: 0.1030, Train Acc: 96.47%, Test Acc: 75.80%
Post-Pruned Baseline Model Accuracy: 75.40%
Post-Pruned Low Forgetting Model Accuracy: 75.83%
Post-Pruned High Forgetting Model Accuracy: 75.80%
Accuracy results saved to results/resnet18/CIFAR10/dr0.5/pr0.2/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.5/pr0.2/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 25000 highest-forgetting and top 25000 lowest-forgetting samples.
Highest forgetting subset size: 25000, Lowest forgetting subset size: 25000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5400, Accuracy: 44.37%
Epoch [2/10] complete: Loss: 1.1736, Accuracy: 58.53%
Epoch [3/10] complete: Loss: 0.9799, Accuracy: 65.46%
Epoch [4/10] complete: Loss: 0.8358, Accuracy: 70.75%
Epoch [5/10] complete: Loss: 0.7085, Accuracy: 74.77%
Epoch [6/10] complete: Loss: 0.5999, Accuracy: 79.10%
Epoch [7/10] complete: Loss: 0.4961, Accuracy: 82.59%
Epoch [8/10] complete: Loss: 0.4147, Accuracy: 85.54%
Epoch [9/10] complete: Loss: 0.3224, Accuracy: 88.71%
Epoch [10/10] complete: Loss: 0.2584, Accuracy: 90.91%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5477, Accuracy: 44.28%
Epoch [2/10] complete: Loss: 1.1859, Accuracy: 58.29%
Epoch [3/10] complete: Loss: 0.9944, Accuracy: 64.66%
Epoch [4/10] complete: Loss: 0.8448, Accuracy: 70.36%
Epoch [5/10] complete: Loss: 0.7118, Accuracy: 75.12%
Epoch [6/10] complete: Loss: 0.6073, Accuracy: 78.85%
Epoch [7/10] complete: Loss: 0.5052, Accuracy: 82.19%
Epoch [8/10] complete: Loss: 0.4270, Accuracy: 85.10%
Epoch [9/10] complete: Loss: 0.3354, Accuracy: 88.41%
Epoch [10/10] complete: Loss: 0.2741, Accuracy: 90.50%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 70.03%
High Forgetting Model Accuracy: 70.22%
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Applying pruning with ratio 0.4...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.5/pr0.4/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 69.78%
Pruned Low Forgetting Model Accuracy: 68.64%
Pruned High Forgetting Model Accuracy: 67.96%
Post-Pruning Retraining...
Initial Test Accuracy: 69.78%
Post-Pruning Training Epoch [1/10]: Loss: 0.9014, Train Acc: 68.92%, Test Acc: 72.36%
Post-Pruning Training Epoch [2/10]: Loss: 0.6225, Train Acc: 78.30%, Test Acc: 73.25%
Post-Pruning Training Epoch [3/10]: Loss: 0.4934, Train Acc: 82.81%, Test Acc: 73.52%
Post-Pruning Training Epoch [4/10]: Loss: 0.3810, Train Acc: 86.72%, Test Acc: 74.09%
Post-Pruning Training Epoch [5/10]: Loss: 0.2837, Train Acc: 89.98%, Test Acc: 74.32%
Post-Pruning Training Epoch [6/10]: Loss: 0.2150, Train Acc: 92.54%, Test Acc: 74.76%
Post-Pruning Training Epoch [7/10]: Loss: 0.1739, Train Acc: 93.87%, Test Acc: 74.87%
Post-Pruning Training Epoch [8/10]: Loss: 0.1418, Train Acc: 95.08%, Test Acc: 74.96%
Post-Pruning Training Epoch [9/10]: Loss: 0.1167, Train Acc: 95.91%, Test Acc: 74.37%
Post-Pruning Training Epoch [10/10]: Loss: 0.1082, Train Acc: 96.22%, Test Acc: 75.07%
Initial Test Accuracy: 68.64%
Post-Pruning Training Epoch [1/10]: Loss: 0.6102, Train Acc: 79.93%, Test Acc: 73.37%
Post-Pruning Training Epoch [2/10]: Loss: 0.4727, Train Acc: 84.11%, Test Acc: 73.91%
Post-Pruning Training Epoch [3/10]: Loss: 0.3668, Train Acc: 87.82%, Test Acc: 74.46%
Post-Pruning Training Epoch [4/10]: Loss: 0.2930, Train Acc: 89.90%, Test Acc: 73.87%
Post-Pruning Training Epoch [5/10]: Loss: 0.2260, Train Acc: 92.21%, Test Acc: 74.79%
Post-Pruning Training Epoch [6/10]: Loss: 0.1889, Train Acc: 93.46%, Test Acc: 75.39%
Post-Pruning Training Epoch [7/10]: Loss: 0.1474, Train Acc: 94.85%, Test Acc: 73.84%
Post-Pruning Training Epoch [8/10]: Loss: 0.1370, Train Acc: 95.20%, Test Acc: 75.33%
Post-Pruning Training Epoch [9/10]: Loss: 0.1170, Train Acc: 95.95%, Test Acc: 74.53%
Post-Pruning Training Epoch [10/10]: Loss: 0.1053, Train Acc: 96.43%, Test Acc: 75.75%
Initial Test Accuracy: 67.96%
Post-Pruning Training Epoch [1/10]: Loss: 0.6071, Train Acc: 79.98%, Test Acc: 73.67%
Post-Pruning Training Epoch [2/10]: Loss: 0.4634, Train Acc: 84.53%, Test Acc: 73.04%
Post-Pruning Training Epoch [3/10]: Loss: 0.3651, Train Acc: 87.59%, Test Acc: 75.08%
Post-Pruning Training Epoch [4/10]: Loss: 0.2903, Train Acc: 90.09%, Test Acc: 75.15%
Post-Pruning Training Epoch [5/10]: Loss: 0.2257, Train Acc: 92.15%, Test Acc: 73.77%
Post-Pruning Training Epoch [6/10]: Loss: 0.1856, Train Acc: 93.55%, Test Acc: 74.61%
Post-Pruning Training Epoch [7/10]: Loss: 0.1571, Train Acc: 94.63%, Test Acc: 75.64%
Post-Pruning Training Epoch [8/10]: Loss: 0.1341, Train Acc: 95.32%, Test Acc: 75.43%
Post-Pruning Training Epoch [9/10]: Loss: 0.1161, Train Acc: 95.93%, Test Acc: 75.28%
Post-Pruning Training Epoch [10/10]: Loss: 0.1115, Train Acc: 96.12%, Test Acc: 74.80%
Post-Pruned Baseline Model Accuracy: 75.07%
Post-Pruned Low Forgetting Model Accuracy: 75.75%
Post-Pruned High Forgetting Model Accuracy: 74.80%
Accuracy results saved to results/resnet18/CIFAR10/dr0.5/pr0.4/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.5/pr0.4/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 25000 highest-forgetting and top 25000 lowest-forgetting samples.
Highest forgetting subset size: 25000, Lowest forgetting subset size: 25000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5494, Accuracy: 44.32%
Epoch [2/10] complete: Loss: 1.1794, Accuracy: 58.54%
Epoch [3/10] complete: Loss: 0.9786, Accuracy: 65.56%
Epoch [4/10] complete: Loss: 0.8313, Accuracy: 70.65%
Epoch [5/10] complete: Loss: 0.7066, Accuracy: 75.21%
Epoch [6/10] complete: Loss: 0.5938, Accuracy: 79.00%
Epoch [7/10] complete: Loss: 0.4929, Accuracy: 82.66%
Epoch [8/10] complete: Loss: 0.4052, Accuracy: 85.81%
Epoch [9/10] complete: Loss: 0.3221, Accuracy: 88.76%
Epoch [10/10] complete: Loss: 0.2544, Accuracy: 91.14%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5440, Accuracy: 44.46%
Epoch [2/10] complete: Loss: 1.1810, Accuracy: 58.23%
Epoch [3/10] complete: Loss: 0.9863, Accuracy: 65.30%
Epoch [4/10] complete: Loss: 0.8364, Accuracy: 70.59%
Epoch [5/10] complete: Loss: 0.7089, Accuracy: 75.32%
Epoch [6/10] complete: Loss: 0.6041, Accuracy: 78.67%
Epoch [7/10] complete: Loss: 0.4967, Accuracy: 82.32%
Epoch [8/10] complete: Loss: 0.4160, Accuracy: 85.24%
Epoch [9/10] complete: Loss: 0.3329, Accuracy: 88.31%
Epoch [10/10] complete: Loss: 0.2643, Accuracy: 90.66%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 70.19%
High Forgetting Model Accuracy: 71.12%
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Applying pruning with ratio 0.6...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.5/pr0.6/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 63.76%
Pruned Low Forgetting Model Accuracy: 49.54%
Pruned High Forgetting Model Accuracy: 49.22%
Post-Pruning Retraining...
Initial Test Accuracy: 63.76%
Post-Pruning Training Epoch [1/10]: Loss: 0.9069, Train Acc: 68.55%, Test Acc: 70.69%
Post-Pruning Training Epoch [2/10]: Loss: 0.6267, Train Acc: 78.04%, Test Acc: 73.16%
Post-Pruning Training Epoch [3/10]: Loss: 0.4875, Train Acc: 82.70%, Test Acc: 73.88%
Post-Pruning Training Epoch [4/10]: Loss: 0.3773, Train Acc: 86.90%, Test Acc: 74.98%
Post-Pruning Training Epoch [5/10]: Loss: 0.2846, Train Acc: 90.09%, Test Acc: 75.49%
Post-Pruning Training Epoch [6/10]: Loss: 0.2184, Train Acc: 92.28%, Test Acc: 75.02%
Post-Pruning Training Epoch [7/10]: Loss: 0.1728, Train Acc: 93.89%, Test Acc: 74.44%
Post-Pruning Training Epoch [8/10]: Loss: 0.1433, Train Acc: 95.04%, Test Acc: 74.49%
Post-Pruning Training Epoch [9/10]: Loss: 0.1165, Train Acc: 95.97%, Test Acc: 74.90%
Post-Pruning Training Epoch [10/10]: Loss: 0.1066, Train Acc: 96.28%, Test Acc: 74.82%
Initial Test Accuracy: 49.54%
Post-Pruning Training Epoch [1/10]: Loss: 0.6455, Train Acc: 78.34%, Test Acc: 72.55%
Post-Pruning Training Epoch [2/10]: Loss: 0.5005, Train Acc: 82.98%, Test Acc: 73.90%
Post-Pruning Training Epoch [3/10]: Loss: 0.3907, Train Acc: 86.57%, Test Acc: 74.33%
Post-Pruning Training Epoch [4/10]: Loss: 0.3107, Train Acc: 89.22%, Test Acc: 74.42%
Post-Pruning Training Epoch [5/10]: Loss: 0.2434, Train Acc: 91.52%, Test Acc: 74.80%
Post-Pruning Training Epoch [6/10]: Loss: 0.1987, Train Acc: 92.96%, Test Acc: 74.79%
Post-Pruning Training Epoch [7/10]: Loss: 0.1681, Train Acc: 94.16%, Test Acc: 74.75%
Post-Pruning Training Epoch [8/10]: Loss: 0.1371, Train Acc: 95.24%, Test Acc: 75.26%
Post-Pruning Training Epoch [9/10]: Loss: 0.1202, Train Acc: 95.84%, Test Acc: 75.80%
Post-Pruning Training Epoch [10/10]: Loss: 0.1141, Train Acc: 95.89%, Test Acc: 75.37%
Initial Test Accuracy: 49.22%
Post-Pruning Training Epoch [1/10]: Loss: 0.6422, Train Acc: 78.56%, Test Acc: 73.46%
Post-Pruning Training Epoch [2/10]: Loss: 0.4905, Train Acc: 83.42%, Test Acc: 74.25%
Post-Pruning Training Epoch [3/10]: Loss: 0.3838, Train Acc: 86.94%, Test Acc: 74.27%
Post-Pruning Training Epoch [4/10]: Loss: 0.3074, Train Acc: 89.45%, Test Acc: 75.29%
Post-Pruning Training Epoch [5/10]: Loss: 0.2432, Train Acc: 91.61%, Test Acc: 74.77%
Post-Pruning Training Epoch [6/10]: Loss: 0.1894, Train Acc: 93.38%, Test Acc: 74.73%
Post-Pruning Training Epoch [7/10]: Loss: 0.1625, Train Acc: 94.32%, Test Acc: 73.97%
Post-Pruning Training Epoch [8/10]: Loss: 0.1390, Train Acc: 95.19%, Test Acc: 74.87%
Post-Pruning Training Epoch [9/10]: Loss: 0.1215, Train Acc: 95.80%, Test Acc: 75.17%
Post-Pruning Training Epoch [10/10]: Loss: 0.1132, Train Acc: 96.02%, Test Acc: 75.52%
Post-Pruned Baseline Model Accuracy: 74.82%
Post-Pruned Low Forgetting Model Accuracy: 75.37%
Post-Pruned High Forgetting Model Accuracy: 75.52%
Accuracy results saved to results/resnet18/CIFAR10/dr0.5/pr0.6/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.5/pr0.6/post_pruning_accuracy.png.
=============================================================================================================
Files already downloaded and verified
Files already downloaded and verified
Loading precomputed forgetting scores and baseline model...
Baseline model and forgetting scores loaded.
Selected top 25000 highest-forgetting and top 25000 lowest-forgetting samples.
Highest forgetting subset size: 25000, Lowest forgetting subset size: 25000
Training model on high-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5444, Accuracy: 44.10%
Epoch [2/10] complete: Loss: 1.1850, Accuracy: 58.03%
Epoch [3/10] complete: Loss: 0.9879, Accuracy: 65.08%
Epoch [4/10] complete: Loss: 0.8497, Accuracy: 69.84%
Epoch [5/10] complete: Loss: 0.7175, Accuracy: 74.84%
Epoch [6/10] complete: Loss: 0.6014, Accuracy: 78.73%
Epoch [7/10] complete: Loss: 0.5026, Accuracy: 82.37%
Epoch [8/10] complete: Loss: 0.4189, Accuracy: 85.21%
Epoch [9/10] complete: Loss: 0.3321, Accuracy: 88.50%
Epoch [10/10] complete: Loss: 0.2671, Accuracy: 90.57%
Training completed.
Training model on low-forgetting subset...
Starting training for 10 epochs...
Epoch [1/10] complete: Loss: 1.5587, Accuracy: 43.76%
Epoch [2/10] complete: Loss: 1.1861, Accuracy: 57.93%
Epoch [3/10] complete: Loss: 0.9937, Accuracy: 65.27%
Epoch [4/10] complete: Loss: 0.8393, Accuracy: 70.57%
Epoch [5/10] complete: Loss: 0.7147, Accuracy: 75.02%
Epoch [6/10] complete: Loss: 0.6030, Accuracy: 79.11%
Epoch [7/10] complete: Loss: 0.5033, Accuracy: 82.28%
Epoch [8/10] complete: Loss: 0.4111, Accuracy: 85.66%
Epoch [9/10] complete: Loss: 0.3311, Accuracy: 88.28%
Epoch [10/10] complete: Loss: 0.2656, Accuracy: 90.74%
Training completed.
Baseline Model Accuracy: 70.69%
Low Forgetting Model Accuracy: 70.12%
High Forgetting Model Accuracy: 70.51%
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Applying pruning with ratio 0.8...
Pruning completed.
Pruning accuracy comparison bar plot saved to results/resnet18/CIFAR10/dr0.5/pr0.8/pruning_accuracy_comparison.png.
Pruned Baseline Model Accuracy: 27.92%
Pruned Low Forgetting Model Accuracy: 15.88%
Pruned High Forgetting Model Accuracy: 12.70%
Post-Pruning Retraining...
Initial Test Accuracy: 27.92%
Post-Pruning Training Epoch [1/10]: Loss: 0.9872, Train Acc: 65.31%, Test Acc: 69.96%
Post-Pruning Training Epoch [2/10]: Loss: 0.6774, Train Acc: 76.31%, Test Acc: 72.70%
Post-Pruning Training Epoch [3/10]: Loss: 0.5427, Train Acc: 81.12%, Test Acc: 74.30%
Post-Pruning Training Epoch [4/10]: Loss: 0.4303, Train Acc: 85.00%, Test Acc: 74.47%
Post-Pruning Training Epoch [5/10]: Loss: 0.3310, Train Acc: 88.35%, Test Acc: 76.55%
Post-Pruning Training Epoch [6/10]: Loss: 0.2610, Train Acc: 90.91%, Test Acc: 75.89%
Post-Pruning Training Epoch [7/10]: Loss: 0.2031, Train Acc: 92.90%, Test Acc: 75.68%
Post-Pruning Training Epoch [8/10]: Loss: 0.1578, Train Acc: 94.47%, Test Acc: 75.90%
Post-Pruning Training Epoch [9/10]: Loss: 0.1336, Train Acc: 95.33%, Test Acc: 74.93%
Post-Pruning Training Epoch [10/10]: Loss: 0.1172, Train Acc: 95.87%, Test Acc: 75.51%
Initial Test Accuracy: 15.88%
Post-Pruning Training Epoch [1/10]: Loss: 0.7577, Train Acc: 73.94%, Test Acc: 71.01%
Post-Pruning Training Epoch [2/10]: Loss: 0.5712, Train Acc: 80.47%, Test Acc: 73.51%
Post-Pruning Training Epoch [3/10]: Loss: 0.4562, Train Acc: 84.29%, Test Acc: 76.04%
Post-Pruning Training Epoch [4/10]: Loss: 0.3619, Train Acc: 87.37%, Test Acc: 75.66%
Post-Pruning Training Epoch [5/10]: Loss: 0.2807, Train Acc: 90.21%, Test Acc: 75.47%
Post-Pruning Training Epoch [6/10]: Loss: 0.2250, Train Acc: 92.16%, Test Acc: 76.25%
Post-Pruning Training Epoch [7/10]: Loss: 0.1803, Train Acc: 93.73%, Test Acc: 76.00%
Post-Pruning Training Epoch [8/10]: Loss: 0.1580, Train Acc: 94.42%, Test Acc: 76.43%
Post-Pruning Training Epoch [9/10]: Loss: 0.1302, Train Acc: 95.44%, Test Acc: 76.14%
Post-Pruning Training Epoch [10/10]: Loss: 0.1175, Train Acc: 95.90%, Test Acc: 75.75%
Initial Test Accuracy: 12.70%
Post-Pruning Training Epoch [1/10]: Loss: 0.7661, Train Acc: 73.61%, Test Acc: 71.46%
Post-Pruning Training Epoch [2/10]: Loss: 0.5700, Train Acc: 80.32%, Test Acc: 74.06%
Post-Pruning Training Epoch [3/10]: Loss: 0.4569, Train Acc: 84.20%, Test Acc: 75.76%
Post-Pruning Training Epoch [4/10]: Loss: 0.3636, Train Acc: 87.33%, Test Acc: 74.81%
Post-Pruning Training Epoch [5/10]: Loss: 0.2892, Train Acc: 89.89%, Test Acc: 74.87%
Post-Pruning Training Epoch [6/10]: Loss: 0.2265, Train Acc: 92.11%, Test Acc: 74.90%
Post-Pruning Training Epoch [7/10]: Loss: 0.1907, Train Acc: 93.29%, Test Acc: 75.07%
Post-Pruning Training Epoch [8/10]: Loss: 0.1610, Train Acc: 94.37%, Test Acc: 75.30%
Post-Pruning Training Epoch [9/10]: Loss: 0.1381, Train Acc: 95.08%, Test Acc: 75.22%
Post-Pruning Training Epoch [10/10]: Loss: 0.1213, Train Acc: 95.74%, Test Acc: 74.94%
Post-Pruned Baseline Model Accuracy: 75.51%
Post-Pruned Low Forgetting Model Accuracy: 75.75%
Post-Pruned High Forgetting Model Accuracy: 74.94%
Accuracy results saved to results/resnet18/CIFAR10/dr0.5/pr0.8/accuracies.csv.
Post-pruning accuracy plot saved to results/resnet18/CIFAR10/dr0.5/pr0.8/post_pruning_accuracy.png.
